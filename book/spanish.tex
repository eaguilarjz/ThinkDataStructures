\documentclass[12pt]{book}

\title{Piensa en Estructuras de Datos}
\author{Allen B. Downey}

\renewcommand{\contentsname}{Contenidos}% E. Aguilar, 20190611
\renewcommand{\chaptername}{Capítulo}% E. Aguilar, 20190611
\renewcommand{\figurename}{Figura}% E. Aguilar, 20190612


\newcommand{\thetitle}{Piensa en Estructuras de Datos}
\newcommand{\thesubtitle}{Algoritmos y Recuperación de Información en Java}
\newcommand{\theauthors}{Allen B. Downey}
\newcommand{\theversion}{1.0.1}

%%%% Both LATEX and PLASTEX

\usepackage{graphicx}
\usepackage{hevea}
\usepackage{makeidx}
\usepackage{setspace}
%\usepackage{longtable}
\usepackage{booktabs}

%\usepackage{draftwatermark}
%\SetWatermarkText{DRAFT: Not ready for distribution!}
%\SetWatermarkScale{1}

\makeindex

% automatically index glossary terms
\newcommand{\term}[1]{%
\item[#1:]\index{#1}}

\usepackage{amsmath}
\usepackage{amsthm}

% format end of chapter exercises
\newtheoremstyle{exercise}
  {12pt}        % space above
  {12pt}        % space below
  {}            % body font
  {}            % indent amount
  {\bfseries}   % head font
  {}            % punctuation
  {12pt}        % head space
  {}            % custom head
\theoremstyle{exercise}
\newtheorem{exercise}{Exercise}[chapter]

\newif\ifplastex
\plastexfalse

%%%% PLASTEX ONLY
\ifplastex

\usepackage{localdef}

\usepackage{url}

\newcount\anchorcnt
\newcommand*{\Anchor}[1]{%
  \@bsphack%
    \Hy@GlobalStepCount\anchorcnt%
    \edef\@currentHref{anchor.\the\anchorcnt}%
    \Hy@raisedlink{\hyper@anchorstart{\@currentHref}\hyper@anchorend}%
    \M@gettitle{}\label{#1}%
    \@esphack%
}

% code listing environments:
% we don't need these for plastex because they get replaced
% by preprocess.py
%\newenvironment{code}{\begin{verbatim}}{\end{verbatim}}
%\newenvironment{stdout}{\begin{verbatim}}{\end{verbatim}}

% inline syntax formatting
%\newcommand{\java}{\verb}%}

%%%% LATEX ONLY
\else

\input{latexonly}

\fi

%%%% END OF PREAMBLE
\begin{document}

\frontmatter

%%%% PLASTEX ONLY
\ifplastex

\maketitle

%%%% LATEX ONLY
\else

\begin{latexonly}

%--half title-------------------------------------------------
\thispagestyle{empty}

\begin{flushright}
\vspace*{2.0in}

\begin{spacing}{3}
{\huge \thetitle} \\
{\Large \thesubtitle}
\end{spacing}

\vspace{0.25in}

Versión \theversion

\vfill
\end{flushright}

%--verso------------------------------------------------------
\newpage
\thispagestyle{empty}

\quad

%--title page-------------------------------------------------
\newpage
\thispagestyle{empty}

\begin{flushright}
\vspace*{2.0in}

\begin{spacing}{3}
{\huge \thetitle} \\
{\Large \thesubtitle}
\end{spacing}

\vspace{0.25in}

Versión \theversion

\vspace{1in}

{\Large \theauthors}

{\small Traducido por: Ernesto A. Aguilar}

\vspace{0.5in}

{\Large Green Tea Press}

{\small Needham, Massachusetts}

\vfill
\end{flushright}

%--copyright--------------------------------------------------
\newpage
\thispagestyle{empty}

Copyright \copyright ~2016 \theauthors.

\vspace{0.2in}

\begin{flushleft}
Green Tea Press \\
9 Washburn Ave \\
Needham, MA 02492
\end{flushleft}

Se permite copiar, distribuir, y/o modificar este documento
bajo los términos de la Creative Commons
Attribution-NonCommercial-ShareAlike 3.0 Unported License,
disponible en \url{http://thinkdast.com/cc30}.

El formato original de este libro es código fuente \LaTeX\ . La compilación de este
código tiene el efecto de generar una representación del libro independiente del
dispositivo, que puede convertirse a otros formatos e imprimirse.

El fuente \LaTeX\ de este libro está disponible en
\url{http://thinkdast.com/repo}.

%--table of contents------------------------------------------

\cleardoublepage
\setcounter{tocdepth}{1}
\tableofcontents

\end{latexonly}

%--HTML title page--------------------------------------------

\begin{htmlonly}

\vspace{1em}

{\Large \thetitle: \thesubtitle}

{\large \theauthors}

Versión \theversion

\vspace{1em}

Copyright \copyright ~2016 \theauthors.

Permission is granted to copy, distribute, and/or modify this work
under the terms of the Creative Commons
Attribution-NonCommercial-ShareAlike 3.0 Unported License, which is
available at \url{http://thinkdast.com/cc30}.

\vspace{1em}

\end{htmlonly}

%-------------------------------------------------------------

% END OF THE PART WE SKIP FOR PLASTEX
\fi


\chapter*{Prefacio}
\label{preface}

\markboth{PREFACIO}{PREFACIO}
\addcontentsline{toc}{chapter}{Prefacio}


\section*{La filosofía tras este libro}

Las estructuras de datos y los algoritmos están entre las invenciones más importantes
de los últimos 50 años, y son herramientas fundamentales que los ingenieros de
software necesitan conocer. Pero en mi opinión, la mayoría de los libros sobre
el tema son muy teóricos, muy grandes y muy ``detallados'':

\begin{description}

\item[Muy teóricos]  El análisis matemático de los algoritmos se base en
simplificar supuestos, lo que limita su utilidad en la práctica.
La mayoría de exposiciones sobre el tema apenas cubren las simplificaciones y
se enfocan en la matemática. En este libro presento el subconjunto más práctico
de este material y omito o enfatizo menos el resto.

\item[Muy grandes] La mayoría de libros sobre el tema tienen al menos 500 páginas,
y algunos más de 1000. Al enfocarme en los temas que considero más útiles
para los ingenieros de software, mantuve este libro por debajo de las 200 páginas.

\item[Muy ``detallados''] Muchos libros de estructuras de datos se enfocan más 
en cómo funcionan las estructuras de datos (las implementaciones) y menos
en cómo usarlas (las interfaces). En este libro, proveo una ``visión general'',
al iniciar con las interfaces. Los lectores aprenderán a usar las estructuras del
Java Collections Framework antes de adentrarse en los detalles de cómo funcionan.

\end{description}

Finalmente, algunos libros presentan este material fuera de contexto y sin
motivación alguna: ¡es sólo una estructura de datos tras otra!
Trato de volverlo más ameno al organizar los temas alrededor de una
aplicación -- la búsqueda web -- que usa estructuras de datos
ampliamente, y es una tema interesante e importante por sus propios méritos.

\index{búsqueda web}

Esta aplicación motiva algunos temas que generalmente no se cubren
en una curso introductorio de estructuras de datos, incluyendo estructuras
de datos persistentes con Redis.

\index{Redis}

He tomado algunas decisiones difíciles con relación a qué dejar fuera,
pero he hecho algunas concesiones. Incluyo algunos temas que la
mayoría de los lectores nunca usarán, pero que podría esperarse
que conozcan, posiblemente en una entrevista técnica. Para estos
temas, presento tanto la sabiduría convencional como mis razones
para ser escéptico al respecto.

Este libro también presenta aspectos básicos de la ingeniería de software
en la práctica, incluyendo control de versiones y pruebas unitarias. La mayoría
de los capítulos incluyen un ejercicio que permite a los lectores aplicar lo
que han aprendido. Cada ejercicio provee pruebas automáticas para comprobar
la solución. Y para la mayoría de ejercicios, presento mi solución al principio
del siguiente capítulo.

\index{pruebas unitarias}
\index{control de versiones}


\section{Prerrequisitos}
\label{prerequisites}

Este libro está dirigido a estudiantes de ciencias de la computación
y ramas afines, así como a ingenieros de software profesionales,
personas capacitándose en ingeniería de software y personas
personas preparándose para entrevistas técnicas.

Antes de comenzar este libro, deberías conocer Java bastante bien;
en particular, deberías saber como definir una nueva clase que extienda
una clase existente o implemente una \java{interface}. Si tu Java está
oxidado, aquí están dos libros con los que podrías empezar:

\begin{itemize}

\item Downey and Mayfield, {\it Think Java} (O'Reilly Media, 2016, en inglés),
pensado para personas que nunca antes han programado.

\item Sierra and Bates, {\it Head First Java} (O'Reilly Media, 2005, en inglés),
apropiado para personas que ya conocen otro lenguaje de programación.

\end{itemize}

Si no estás familiarizado con las interfaces en Java, podrías revisar
el tutorial llamado ``What Is an Interface?'' en
\url{http://thinkdast.com/interface}.

\index{interfaz}
\index{interface}

Una nota de vocabulario: la palabra ``interfaz'' (o ``interface'', en inglés) puede resultar
confusa. En el contexto de una {\bf interfaz de programación de aplicaciones} (API, de 
{\bf application programming interface}), se refiere a un conjunto de clases y métodos
que proveen ciertas funcionalidades.

\index{interfaz de programación de aplicaciones}
\index{application programming interface}
\index{API}

En el caso de Java, también se refiere a una característica del lenguaje,
similar a una clase, que especifica un conjunto de métodos. Para evitar
confusiones, usaré ``interfaz'' en un tipo de fuente normal y en español, para la
idea general de una interfaz, e \java{interface} in una fuente monoespaciada y en inglés,
para la característica del lenguaje Java.

También deberías estar familiarizado con los parámetros de tipo y los tipos genéricos.
Por ejemplo, deberías saber cómo crear un objeto con un parámetro de tipo, 
como \java{ArrayList<Integer>}.  Si no, puedes leer sobre los parámetros de tipo
en \url{http://thinkdast.com/types}.

\index{type parameter}

Deberías estar familiarizado con el Java Collections Framework
(JCF), sobre el que puedes leer en
\url{http://thinkdast.com/collections}.
En particular, deberías conocer la \java{interface} \java{List}
y las clases \java{ArrayList} y \java{LinkedList}.

\index{Java Collections Framework}
\index{JCF}

Idealmente deberías estar familiarizado con Apache Ant, una herramienta autormatizada de
de construcción para Java.  Puedes leer más sobre Ant en \url{http://thinkdast.com/anttut}.

\index{Apache Ant}
\index{Ant}

Y deberías estar familiarizado con {\tt JUnit}, un \textit{framework} para Java. Puedes
leer más sobre él en \url{http://thinkdast.com/junit}.

\index{JUnit}


\section*{Trabajando con el código}
\label{code}

El código para este libro está en un repositorio de Git en
\url{http://thinkdast.com/repo}.

\index{Git}
\index{control de versiones}

Git es un ``sistema de control de versiones'' que te permite dar seguimiento a los
archivos que conforman un proyecto. Una colección de archivos bajo el control
de Git es llamada un ``repositorio''.

\index{repositorio}
\index{GitHub}

GitHub es un servicio de alojamiento que provee almacenamiento para repositorios
de Git y una interfaz web conveniente. Provee varias formas de trabajar con el código:

\begin{itemize}

\item Puedes crear una copia del repositorio en GitHub presionando el botón {\sf Fork}. 
Si no tienes una cuenta en GitHub, necesitarás crear una. Tras crear el fork, 
tendrás tu propio repositorio en GitHub que puedes usar para dar seguimiento al código
que escribes. Luego puedes ``clonar'' (``clone'', en inglés) el repositorio, para descargar una
copia de los archivos a tu computadora.

\index{fork}
\index{clone}

\item Alternativamente, puedes clonar el repositorio sin crear un fork. Si eliges esta opción,
no necesitas una cuenta de GitHub, pero no podrás guardar tus cambios en GitHub.

\item Si no quieres usar Git en lo absoluto, puedes descargar el código en un archivo ZIP usando el
botón {\sf Download} en la página de GitHub, o este enlace: \url{http://thinkdast.com/zip}.

\end{itemize}

Después de clonar el repositorio o descomprimir el archivo ZIP, tendrás un directorio llamado {\tt ThinkDataStructures},
que es el título del libro en inglés, con un subdirectorio {\tt code}.

Los ejemplos en este libro fueron desarrollados y probados usando el Java SE
Development Kit 7.  Si estás usando una versión más antigua, algunos ejemplos
no funcionarán. Si estás usando una versión más reciente, todos deberían funcionar.

\index{Java SDK}

\section*{Colaboradores}

Este libro es una adaptación de la currícula que escribí para la
Flatiron School en New York City, que ofrece varias clases en línea
relacionadas con programación y desarrollo web. Ellos ofrecen una
clase basada en este material, que provee un entorno de desarrollo
en línea, ayuda de instructores y otros estudiantes, así como un
certificado de finalización. Puedes encontrar más información en
\url{http://flatironschool.com}.


\begin{itemize}

\item En la Flatiron School, Joe Burgess, Ann John y Charles
  Pletcher brindaron orientación, sugerencias y correcciones desde la
  especificación inicial hasta la implementación y las pruebas. ¡Muchas
  gracias a todos ustedes!

\item Estoy muy agradecido con mis revisores técnicos, Barry Whitman,
  Patrick White y Chris Mayfield, que dieron muchas sugerencias útiles
  y detectaron muchos errores. Por supuesto, ¡cualquier error restante
  es mi responsabilidad, no la de ellos!

\item Gracias a los instructores y estudiantes de Estructuras de Datos y
  Algoritmos en Olin College, que leyeron este libro y brindaron realimentación
  útil.

\item Charles Roumeliotis editó y corrigió el libro para O'Reilly Media
y realizó muchas mejoras.

% ENDCONTRIB

\end{itemize}


% Additional contributors who found one or more typos: coming soon, I'm sure.

Si tienes comentarios o ideas sobre el texto, por favor envíalas a:\linebreak
{\tt feedback@greenteapress.com}.

\mainmatter

\chapter{Interfaces}
\label{cs-lists-programming-to-an-interface-readme}

Este libro presenta tres temas:

\begin{itemize}

\item Estructuras de datos: Iniciando con las estructuras en el Java
Collections Framework (JCF), aprenderás cómo usar estructuras de datos
como listas and mapas y verás cómo trabajan.

\index{estructuras de datos}

\item Análisis de algoritmos: Presento técnicas para analizar código y
predecir qué tan rápido se ejecutará y cuánto espacio (memoria) requerirá.

\index{análisis de algoritmos}

\item Recuperación de información: Para motivar el estudio de los primeros
dos temas y hacer los ejercicios más interesantes, usaremos estructuras de
datos y algoritmos para construir un motor simple de búsqueda en la web.

\index{recuperación de información}
\index{motor de búsqueda}

\end{itemize}

Aquí está una descripción general del orden de los temas:

\begin{itemize}

\item Iniciaremos con la interfaz {\tt List} y escribirás clases que
implementarán esta interfaz de dos formas diferentes. Luego, vamos a
comparar tus implementaciones con las clases de Java {\tt ArrayList} y
{\tt LinkedList}.

\index{List}
\index{ArrayList}
\index{LinkedList}

\item A continuación, introduciré tres estructuras de datos en forma de árbol, y
trabajarás en la primera aplicación: un programa que lea páginas de Wikipedia,
interprete sus contenidos y navegue por el árbol resultante para encontrar enlaces
y otras características. Usaremos estas herramientas para comprobar la conjetura
``Llegar a la Filosofía'' (puedes anticiparte leyendo \url{http://thinkdast.com/getphil}).

\index{árbol}
\index{Llegar a la Filosofía}

\item Aprenderemos sobre la interfaz {\tt Map} y la implementación
{\tt HashMap} de Java. Luego escribiremos clases que implementen
esta interfaz usando una tabla hash y un árbol binario de búsqueda.

\index{Map}
\index{HashMap}
\index{tabla hash}
\index{árbol binario de búsqueda}

\item Finalmente, usarás estas clases (y unas cuantas más que presentaré en
el camino) para implementar un motor de búsqueda en la web, incluyendo: un \textit{rastreador} que
encuentra y lee páginas, un indexador que guarda los contenidos de las páginas Web de forma que puedan
realizarse búsquedas en ellas eficientemente, y un recuperador que toma las consultas de un usuario
y devuelve resultados relevantes.

\index{búsqueda web}
\index{rastreador}
\index{indexador}
\index{recuperador}

\end{itemize}

Comencemos.


\section{¿Por qué hay dos tipos de \java{List}?}
\label{why-are-there-two-kinds-of-list}

Cuando las personas comienzan a trabajar con el Java Collections
Framework, a veces se confunden entre \java{ArrayList} y
\java{LinkedList}.  ¿Por qué Java provee dos implementaciones de
la \java{interface} \java{List}? ¿Y cómo deberías elegir cuál usar?
Responderemos estas preguntas en los siguientes capítulos.

\index{List}
\index{ArrayList}
\index{LinkedList}

Comenzaré por revisar las \java{interface}s y las clases que las
implementan y presentará la idea de ``programar para una interfaz''.

\index{interface}

En los primeros ejercicos a continuación, implementarás clases similares 
a \java{ArrayList} y \java{LinkedList}, para entender cómo funcionan
y veremos que cada una de ellas tiene pros y contras. Algunas operaciones
son más rápidas o usan menos espacio con una \java{ArrayList}; otras
son más rápidas o más pequeñas con una \java{LinkedList}.  Cuál de ellas
es mejor para una aplicación particular depende de las operaciones que
se realizan con más frecuencia.


\section{Interfaces en Java}
\label{interfaces-in-java}

Una \java{interface} de Java especifica un conjunto de métodos; cualquier clase
que implemente esta \java{interface} tiene que proveer estos métodos. Por
ejemplo, aquí está el código fuente para \java{Comparable}, que es una
\java{interface} definida en el paquete \java{java.lang}:

\index{Comparable}

\begin{verbatim}
public interface Comparable<T> {
    public int compareTo(T o);
}
\end{verbatim}

\index{tipo genérico}

Esta definición de \java{interface} usa un parámetro de tipo, \java{T}, lo que
hace a \java{Comparable} un {\bf tipo genérico}.  
Para implementar esta \java{interface}, una clase tiene que

\begin{itemize}

\item Especificar el tipo al que \java{T} se refiere y

\item Proveer un método llamado \java{compareTo} que tome un objeto como
parámetro y devuelva un \java{int}.

\end{itemize}

\index{compareTo}
\index{Integer}

Por ejemplo, aquí está el código fuente para \java{java.lang.Integer}:

\begin{verbatim}
public final class Integer extends Number implements Comparable<Integer> {

    public int compareTo(Integer anotherInteger) {
        int thisVal = this.value;
        int anotherVal = anotherInteger.value;
        return (thisVal<anotherVal ? -1 : (thisVal==anotherVal ? 0 : 1));
    }

    // otros métodos omitidos
}
\end{verbatim}

Esta clase extiende \java{Number}, por lo que hereda los métodos y
variables de instancia de \java{Number}; e implementa
\java{Comparable<Integer>}, así que provee un método con el nombre
\java{compareTo} que toma un \java{Integer} y devuelve
un \java{int}.

\index{Number}
\index{Comparable}

Cuando una clase declara que implementa una \java{interface}, el compilador
verifica que provea todos los métodos definidos por la \java{interface}.

\index{operador ternario}

Al margen, esta implementación de \java{compareTo} usa el
``operador ternario'', que a veces se escribe \java{?:}.  Si no estás
familiarizado con él, puedes leer al respecto en
\url{http://thinkdast.com/ternary}.


\section{La interfaz List}
\label{the-list-interface}

El Java Collections Framework (JCF) define una \java{interface} llamada
\java{List} y provee dos implementaciones, \java{ArrayList} y
\java{LinkedList}.

\index{List}

La \java{interface} define lo que implica ser una \java{List}; cualquier
clase que implemente esta \java{interface} tiene que proveer un
conjunto particular de métodos, que incluyen \java{add}, \java{get},
\java{remove} y alrededor de 20 más.

\java{ArrayList} y \java{LinkedList} proveen estos métodos, así que
ambas pueden ser usadas de forma intercambiable. Un método escrito
para funcionar con una \java{List} funcionará con una \java{ArrayList}, \java{LinkedList},
o cualquier otro objeto que implemente \java{List}.

\index{ArrayList}
\index{LinkedList}

Aquí está un ejemplo artificial para demostrar el punto:

\begin{verbatim}
public class ListClientExample {
    private List list;
    
    public ListClientExample() {
        list = new LinkedList();
    }

    private List getList() {
        return list;        
    }

    public static void main(String[] args) {
        ListClientExample lce = new ListClientExample();
        List list = lce.getList();
        System.out.println(list);
    }
}
\end{verbatim}

\index{ListClientExample}
\index{encapsular}

\java{ListClientExample} no hace nada útil, pero contiene los
elementos esenciales de una clase que {\bf encapsula} una
\java{List}; es decir, contiene una \java{List} como una variable
de instancia. Usaré esta clase para ilustrar un punto y luego
trabajarás con ella en el primer ejercicio.

\index{instanciar}

El constructor \java{ListClientExample} initializa una \java{list} al
{\bf instanciar} (es decir, crear) una nueva \java{LinkedList}; el
método getter \java{getList} devuelve una referencia al objeto
interno \java{List}; y \java{main} contiene unas pocas líneas
de código para probar estos métodos.

Lo importante de este ejemplo es que usa \java{List}
cuando es posible y evita especificar \java{LinkedList} o
\java{ArrayList} a menos que sea necesario. Por ejemplo, la variable
de instancia es declarada como una \java{List} y \java{getList} devuelve
una \java{List}, pero ninguno especifica qué tipo de lista.

Si cambias de opinión y decides usar una \java{ArrayList}, solo tienes
que cambiar el constructor; no tienes que hacer ninguna modificación
adicional.

\index{programación basada en interfaces}
\index{programar para una interfaz}

Este estilo es llamado {\bf programación basada en interfaces},
o de forma más casual, ``programar para una interfaz''
(see \url{http://thinkdast.com/interbaseprog}).
De lo que hablamos es de la idea general de una interfaz, no de
una \java{interface} de Java.

Cuando usas una biblioteca, tu código debería depender únicamente de
la interfaz, como \java{List}.  No debería depender de implementaciones
específicas, como \java{ArrayList}. De esa forma, si la implementación
cambia en el futuro, el código que la usa seguirá funcionando.

Por otro lado, si la interfaz cambia, el código que depende de ella también
tiene que cambiar. Es por eso que los desarrolladores de bibliotecas
evitan cambiar las interfaces a menos que sea absolutemente necesario.


\section{Ejercicio 1}
\label{warming-up}

Dado que este es el primer ejercicio, lo mantendremos simple. Tomarás
el código de la sección anterior e {\bf intercambiarás la implementación};
es decir, reemplazarás la \java{LinkedList} con una \java{ArrayList}.  
Debido a que el código programa para una interfaz, serás capaz de
intercambiar la implementación cambiando una sola línea de código y
agregando una instrucción \java{import}.

Comienza configurando tu entorno de desarrollo. Para todos los
ejercicios, necesitarás poder compilar y ejecutar código de Java.
Desarrollé los ejemplo usando el Java SE Development Kit 7.  Si estás
usando una versión más reciente, todo debería funcionar. Si estás
usando una versión más antigua, puede que encuentres algunas
incompatibilidades.

\index{Java SDK}
\index{entorno de desarrollo integrado}
\index{IDE}

Recomiendo usar un entorno de desarrollo integrado (IDE) que
provea comprobación de sintaxis, autocompletado y refactorización
de código fuente. Estas características te ayudan a prevenir errores o
a encontrarlos rápidamente. Sin embargo, si estás preparándote para
una entrevista técnica, recuerda que no tendrás a tu disposición estas
herramientas durante la entrevista, por lo que podrías querer practicar
escribiendo código sin ellas.

Si aun no has descargado el código para este libro, revisa las
instrucciones en la Sección~\ref{code}.

En el directorio llamado {\tt code}, encontrarás estos archivos y
directorios:

\begin{itemize}
  \item
    \java{build.xml} es un archivo Ant que facilita compilar y
    ejecutar el código.

  \item
    \java{lib} contiene las bibliotecas que necesitarás (para este
    ejercicio, solo JUnit).

  \item
    \java{src} contiene el código fuente.

\end{itemize}

Si navegas a \java{src/com/allendowney/thinkdast},
encontrarás el código fuente para este ejercicio:

\begin{itemize}

  \item
    \java{ListClientExample.java} contiene el código de la sección
    anterior.

  \item
    \java{ListClientExampleTest.java} contiene un test de JUnit para
    \java{ListClientExample}.


\end{itemize}

Revisa \java{ListClientExample} y asegúrate de entender lo que
hace. Luego, compílalo y ejecútalo. Si usas Ant, puedes navegar al
directorio {\tt code} y ejecutar {\tt ant ListClientExample}.

\index{Ant}

Puede ser que obtengas una advertencia como:

\begin{verbatim}
List is a raw type. References to generic type List<E> 
should be parameterized.
\end{verbatim}

Para mantener este ejemplo simple, no me preocupé por especificar el tipo de
los elementos en la lista.  Si esta advertencia te molesta, puedes
arreglarla reemplazando \java{List} o \java{LinkedList} con
\java{List<Integer>} o \java{LinkedList<Integer>}.

\index{raw type}

Revisa \java{ListClientExampleTest}. Ejecuta solo un prueba, que crea un
\java{ListClientExample}, invoca \java{getList}, y luego comprueba
si el resultado es una \java{ArrayList}. Inicialmente, este test fallará
porque el resultado es una \java{LinkedList}, no una
\java{ArrayList}. Ejecuta el test y confirma que falla.

NOTA: Este test tiene sentido para este ejercicio, pero no es un buen
ejemplo de un test. Los buenos tests deberían comprobar si la clase
que está siendo probada satisface los requerimientos de la \emph{interfaz}; 
no deberían depender de los detalles de la \emph{implementación}.

\index{}
\index{interfaz}
\index{implementación}

En la \java{ListClientExample}, reemplaza \java{LinkedList} con
\java{ArrayList}.  Podrías tener que agregar una instrucción \java{import}. 
Compila y ejecuta \java{ListClientExample}. Entonces ejecuta el test
de nuevo. Con este cambio, el test debería pasar.

Para lograr que se pase el test, tuviste que cambiar \java{LinkedList} en
el constructor; no tuviste que cambiar nada en el resto de lugares donde
\java{List} aparece. ¿Qué sucedería si lo haces?  Adelante, reemplaza una
o más apariciones de \java{List} con \java{ArrayList}. El programa
debería seguir funcionando correctamente, pero ahora está
``sobreespecificado''. Si cambias de idea en el futuro y quieres intercambiar
la interfaz de neuvo, tendrías que cambiar más código.

En el constructor de \java{ListClientExample}, ¿qué sucede si reemplazas
\java{ArrayList} con \java{List}? ¿Por qué no puedes instanciar una \java{List}?

\index{constructor}


\chapter{Análisis de Algoritmos}
\label{cs-analysis-of-algorithms-readme}

Como vimos en el capítulo anterior, Java provee dos
implementaciones de la interfaz \java{List}, \java{ArrayList} y
\java{LinkedList}. Para algunas aplicaciones, \java{LinkedList} es más rápida;
para otras, \java{ArrayList} es más rápida.

\index{análisis de algoritmos}
\index{perfilado}

Para decidir cuál es mejor para una aplicación particular, una aproximación
es probar ambas y ver cuánto se tardan. Esta aproximación, que se conoce
como ``perfilado'', tiene algunos problemas:

\begin{enumerate}

\item Antes de comparar los algoritmos, tienes que implementar ambos.

\item Los resultados podrían depender de qué tipo de computadora uses. Un 
  algoritmo podría ser mejor en una máquina; el otro podría ser mejor
  en una máquina diferente.

\item Los resultados podrían depender del tamaño del problema o de los datos
  que se proporcionaron como entrada.

\end{enumerate}

Podemos superar algunos de estos problemas al realizar un {\bf análisis de
algoritmos}. Cuando funciona, el análisis de algoritmos hace posible
comparar algoritmos sin tener que implementarlos. Pero tenemos que
asumir algunos supuestos:

\begin{enumerate}

\item Para no lidiar con los detalles del hardware de computadoras, 
  usualmente identificamos las operaciones básicas que conforman un
  algoritmo ---como suma, multiplicación y comparación de números--- y
  contamos el número de operaciones que cada algoritmo requiere.

\item Para no lidiar con los detalles de los datos de entrada, la mejor
  opción es analizar el desempeño promedio para las entradas que
  esperamos. Si eso no es posible, una alternativa común es analizar
  el peor escenario.

\item Finalmente, tenemos que lidiar con la posibilidad que un algoritmo
  funcione mejor para problemas pequeños y otro para los grandes. En ese
  caso, usualmente nos enfocamos en los grandes, porque para problemas
  pequeños la diferencia probablemente no importe, pero para problemas
  grandes la diferencia puede ser enorme.

\end{enumerate}

Esta clase de análisis concude a una clasificación simple de los
algoritmos. Por ejemplo, si sabemos que el tiempo de ejecución del Algoritmo
A tiende a ser proporcional al tamaño de las entradas, $n$, y el Algoritmo
B tiende a ser proporcional a $n^2$, esperaríamos que A sea más rápido que B,
al menos para valores grandes de $n$.

\index{tiempo constante}
\index{tiempo lineal}
\index{tiempo cuadrático}

La mayoría de algoritmos simples pueden agruparse en unas pocas categorías.

\begin{itemize}

\item Tiempo constante: Un algoritmo es de ``tiempo constante'' si el tiempo de ejecución
  no depende del tamaño de las entradas. Por ejemplo, si tienes un
  arreglo de $n$ elementos y usas el operador de corchetes
  (\java{[]}) para acceder a uno de los elementos, esta operación requiere el mismo
  número de operaciones independientemente de qué tan grande sea el arreglo.

\item Lineal: Un algoritmo es ``lineal'' si el tiempo de ejecución es
  proporcional al tamaño de la entrada. Por ejemplo, si sumas todos los
  elementos de un arreglo, tienes que acceder a $n$ elementos y
  realizar $n-1$ sumas. El número total de operaciones
  (accesos a elementos y sumas) es $2n-1$, que es proporcional
  a $n$.

\item Cuadrático: Un algoritmo es ``cuadrático'' si el tiempo de ejecución es
  proporcional a $n^2$.  Por ejemplo, supón que quieres comprobar si cualquiera
  de los elementos en una lista aparece más de una vez. Un algoritmo simple
  es comparar cada elemento con todos los demás. Si hay
  $n$ elementos y cada se compara a los $n-1$ restantes, el número
  total de comparaciones es $n^2 -n$, que es proporcional a
  $n^2$ conforme $n$ crece.

\end{itemize}


\section{Ordenamiento por selección}
\label{selection-sort}

\index{ordenamiento por selección}
\index{ordenamiento}

Por ejemplo, aquí está una implementación de un algoritmo simple llamado
{\bf ordenamiento por selección}
(véase \url{http://thinkdast.com/selectsort}):

\begin{verbatim}
public class SelectionSort {

    /**
     * Intercambia los elementos en los índices i y j.
     */
    public static void swapElements(int[] array, int i, int j) {
        int temp = array[i];
        array[i] = array[j];
        array[j] = temp;
    }

    /**
     * Encuentra el índice del valor más bajo
     * comenzando desde el índice al principio (inclusive)
     * y continuando hasta el final del arreglo.
     */
    public static int indexLowest(int[] array, int start) {
        int lowIndex = start;
        for (int i = start; i < array.length; i++) {
            if (array[i] < array[lowIndex]) {
                lowIndex = i;
            }
        }
        return lowIndex;
    }

    /**
     * Ordena los elementos (en sitio) por selección.
     */
    public static void selectionSort(int[] array) {
        for (int i = 0; i < array.length; i++) {
            int j = indexLowest(array, i);
            swapElements(array, i, j);
        }
    }
}
\end{verbatim}

El primer método, \java{swapElements}, intercambia (del inglés \emph{swap}) dos elementos del
arreglo. Leer y escribir elementos son operaciones de tiempo constante,
porque si conocemos el número de elementos y la ubicación del primero,
podemos calcular la ubicación de cualquier otro elemento con una multiplicación
y una suma, y estas son operaciones de tiempo constante. Dado que todo en
\java{swapElements} es de tiempo constante, el método completo es de tiempo constante.

\index{tiempo constante}
El segundo método, \java{indexLowest}, encuentra el índice del elemento más
pequeño del arreglo comenzando en un índice dado, \java{start}. Cada vez,
en todas las repeticiones, accede a dos elementos del arreglo y
realiza una comparación. Dado que estas son todas operaciones de tiempo
constante, realmente no importa cuáles contemos. Para mantenerlo simple,
contemos el número de comparaciones.

\begin{enumerate}

\item Si \java{start} es 0, \java{indexLowest} recorre el arreglo
  completo, y el número total de comparacioones es la longitud del
  arreglo, a la que llamaré $n$.

\item Si \java{start} es 1, el número de comparaciones es $n-1$.

\item En general, el número de comparaciones es $n$ - \java{start}, así que 
  \java{indexLowest} es lineal.

\end{enumerate}

El tercer método, \java{selectionSort}, orderna el arreglo. Se repite desde
0 hasta $n-1$, así que el bucle se ejecuta $n$ veces. Cada vez, llama
a \java{indexLowest} y luego realiza una operación de tiempo constante,
\java{swapElements}.

\index{tiempo lineal}

La primera vez que se llama a \java{indexLowest}, éste lleva
a cabo $n$ comparaciones. La segunda vez, se llevan a cabo
$n-1$ comparaciones, y así sucesivamente. El número total de comparaciones es

\[ n + n-1 + n-2 + ... + 1 + 0 \]

La suma de esta serie es $n(n+1)/2$, que es proporcional a
$n^2$; eso implica que \java{selectionSort} es cuadrático.

\index{tiempo lineal}

Para obtener el mismo resultado de forma diferente, podemos pensar en
\java{indexLowest} como un bucle anidado. Cada vez que llamamos a
\java{indexLowest}, el número de operaciones es proporcional
a $n$. Lo llamamos $n$ veces, así que el número total de
operaciones es proporcional a $n^2$.


\section{Notación Big O}
\label{big-o-notation}

\index{notación Big O}

Todos los algoritmos de tiempo constante pertenecen a un conjunto
llamado $O(1)$. Así que otra manera de decir que un algoritmo es de
tiempo constante es decir que está en $O(1)$. De forma similar, todos
los algoritmos lineales pertenecen a $O(n)$, y todos los algoritmos
cuadráticos pertenecen a $O(n^2)$. A esta forma de clasificar algoritmos
se la conoce como ``notación big O''.

NOTA: Esta es un definición informal de la notación big O. Para un
tratamiento más formal, véase
\url{http://thinkdast.com/bigo}.

Esta notación provee una manera conveniente de escribir reglas generales
acerca de cómo se comportan los algoritmos cuando los combinamos. Por
ejemplo, si se lleva a cabo un algoritmo de tiempo lineal seguido de un
algoritmo constante, el tiempo total de ejecución es lineal. Al usar $\in$
con el significado ``pertenece a'':

Si $f \in O(n)$ u $g \in O(1)$, $f+g \in O(n)$.

Si se llevan a cabo dos operaciones lineales, el total sigue siendo lineal.

Si $f \in O(n)$ y $g \in O(n)$, $f+g \in O(n)$.

De hecho, si se lleva a cabo una operación lineal cualquier número
de veces, $k$, el total es lineal, siempre qye $k$ sea una constante
que no dependa de $n$.

Si $f \in O(n)$ y $k$ es una constante, $kf \in O(n)$.

Pero si llevas a cabo una operación lineal $n$ veces, el resultado
es cuadrático:

Si $f \in O(n)$, $nf \in O(n^2)$.

En general, sólo nos interesa el exponente mayor de $n$. Así que si
el número total de operaciones es $2n + 1$, pertenece a
$O(n)$. El coeficiente, 2, y el término aditivo, 1, no son importantes
para este tipo de análisis. De forma similar, $n^2 + 100n + 1000$ está
en $O(n^2)$.  ¡Que no te distraigan los números grandes!

``Orden de crecimiento'' es otro nombre para la misma idea. Una orden de
crecimiento es un conjunto de algoritmos cuyos tiempos de ejecución están
en la misma categoría de big O; por ejemplo, todos los algoritmos lineales
pertenecen a la misma orden de crecimiento porque sus tiempos de ejecución
están en $O(n)$.

\index{orden de crecimiento}

En este contexto, una``orden'' es un grupo, como la \emph{Orden de
los Caballeros de la Mesa Redonda}, que es un grupo de caballeros, no una forma
de alinearlos. Así que puedes imaginarte a la \emph{Orden de los Algoritmos
Lineales} como un conjunto de algoritmos valientes, galantes y particularmente eficientes.


\section{Ejercicio 2}
\label{exercise2}

El ejercicio para este capítulo es implementar una \java{List} que
use un arreglo de Java para guardar sus elementos. 

En el repositorio de código para este libro (véase la Sección~\ref{code}),
encontrarás los archivos de código fuente que necesitarás:

\index{MyArrayList}

\begin{itemize}
\item \java{MyArrayList.java} contiene una implementación parcial de la interfaz de
 \java{List}. Cuatro de los métodos están incompletos, tu trabajo es agregar las partes faltantes.

\item \java{MyArrayListTest.java} contiene tests de JUnit que puedes usar para comprobar tu trabajo.

\end{itemize}

También encontrarás el archivo de construcción Ant \java{build.xml}.  Desde el
directorio {\tt code}, deberías poder ejecutar \java{ant MyArrayList} para
ejecutar \java{MyArrayList.java}, que contiene unos pocos tests simples. O puedes
ejecutar \java{ant MyArrayListTest} para ejecutar los tests de JUnit.

\index{Ant}
%TODO: either make the build step automatic or add instructions

Cuando ejecutes los tests, varios de ellos deberían fallar. Si examinas el
código fuente, verás cuatro comentarios \java{TODO} (cosas por hacer)
indicando los métodos que deberías completar.

Antes de comenzar a agregar el código en los métodos incompletos, revisemos
una porción del código. Aquí esta la definición de la clase, variables de instancia
y el constructor.

\index{variable de instancia}
\index{constructor}


\begin{verbatim}
public class MyArrayList<E> implements List<E> {
    int size;                    // lleva un registro del número de elementos
    private E[] array;           // guarda los elementos
    
    public MyArrayList() {
        array = (E[]) new Object[10];
        size = 0;
    }
}
\end{verbatim}

Como indican los comentarios, \java{size} registra cuántos elementos
están en \java{MyArrayList}, y \java{array} es el arreglo que, de hecho,
contiene los elementos.

\index{elemento}

El constructor crea un arreglo de 10 elementos, que inicialmente son
\java{null}, y establece el \java{size} en 0. La mayor parte del tiempo, la
longitud del arreglo es mayor que \java{size}, así que hay muchos espacios
sin utilizar en el arreglo.

\index{parámetro de tipo}

Un detalle sobre Java: no puedes instanciar  un arreglo usando un parámetro
de tipo; por ejemplo, lo siguiente no funcionará:

\begin{verbatim}
        array = new E[10];
\end{verbatim}

Para superar esta limitante, tendrás que instanciar un arreglo de
\java{Object} y después forzar la conversión de tipo. Puedes leer más al respecto
en \url{http://thinkdast.com/generics}.

A continuación examinaremos el método que agrega elementos a la lista:

\begin{verbatim}
    public boolean add(E element) {
        if (size >= array.length) {
            // crear un arreglo más grande y copiar los elementos
            E[] bigger = (E[]) new Object[array.length * 2];
            System.arraycopy(array, 0, bigger, 0, array.length);
            array = bigger;
        } 
        array[size] = element;
        size++;
        return true;
    }
\end{verbatim}

Si no hay espacios sin utilizar en el arreglo, tenemos que crear un arreglo
más grande y copiar los elementos a éste. Luego ya podemos guardar el
elemento en el arreglo e incrementar el \java{size}.

\index{booleano}

Puede que no sea obvio por qué este método devuelve un booleano, dado
que siempre devuelve \java{true}. Como siempre, puedes encontrar la
respuesta en la documentación:
\url{http://thinkdast.com/colladd}.
Tampoco es obvio cómo analizar el desempeño de este
método. En el caso normal, es de tiempo constante, pero si tenemos
que redimensionar el arreglo, es lineal. Explicaré cómo manejar esto en la
Sección~\ref{classifying-add}.

\index{tiempo constante}
\index{tiempo lineal}

Finalmente, demos una mirada a \java{get}; y luego ya puedes empezar con
los ejercicios.

\begin{verbatim}
    public T get(int index) {
        if (index < 0 || index >= size) {
            throw new IndexOutOfBoundsException();
        }
        return array[index];
    }
\end{verbatim}

De hecho, \java{get} es bastante simple:
si el índice está fuera de rango, lanza una excepción; de lo contrario
lee y devuelve un elemento del arreglo. Nota que se comprueba si
el índice es menor que \java{size}, no \java{array.length}, así que
no es posible acceder a los elementos sin utilizar del arreglo.

\index{get}

En \java{MyArrayList.java}, encontrarás código de relleno para \java{set} que
se ve como esto:

\begin{verbatim}
    public T set(int index, T element) {
        // TODO: fill in this method.
        return null;
    }
\end{verbatim}

Lee la documentación de \java{set} en
\url{http://thinkdast.com/listset}, luego llena el cuerpo de este
método. Si ejecutas \java{MyArrayListTest} de nuevo, \java{testSet} debería
pasar.

\index{set}

PISTA: Trata de no repetir el código que comprueba el índice.

Tu siguiente misión es llenar \java{indexOf}. Como es usual, debería
leer la documentación en \url{http://thinkdast.com/listindof} así ya
sabes lo que se supone que haga. En particular, nota cómo se supone
que maneje \java{null}.

\index{indexOf}
\index{método auxiliar}

He provisto un método auxiliar llamado
\java{equals} que compara un elementos del arreglo con un valor
objetivo y devuelve \java{true} si son iguales (y que maneja los
\java{null} correctamente). Nota que este método es privado porque solo
se usa dentro de la clase; no es parte de la interfaz \java{List}.

\index{equals}

Cuando termines, ejecuta \java{MyArrayListTest} de nuevo;
\java{testIndexOf} debería pasar ahora, así como el otro test que
depende de él.

Sólo dos métodos más para terminar, y habrás finalizado este
ejercicio. El siguiente es una versión sobrecargada de \java{add} que
toma un entero y guarda el nuevo valor en un índice dado, desplazando
los otros elementos para hacer espacio, de ser necesario.

\index{add}

De nuevo, lee la documentación en \url{http://thinkdast.com/listadd},
escribe una implementación, y ejecuta los tests para confirmar.

PISTA: Evita repetir el código que hace al arreglo más grande.

El último: llena el cuerpo de \java{remove}.  La documentación está en
\url{http://thinkdast.com/listrem}. Cuando finalices este útlimo, todos
los tests deberían pasar.

\index{remove}

Una vez que tus implementaciones funcionen, compáralas con la mía,
la cual puedes leer en \url{http://thinkdast.com/myarraylist}.


\chapter{ArrayList}
\label{cs-analyzing-our-arraylist-readme}

\index{ArrayList}

Este capítulo mata dos pájaros de un tiro: presento las soluciones
al ejercicio anterior y demuestro una forma de clasificar
algoritmos utilizando el {\bf análisis amortizado}.

\index{análisis amortizado}


\section{Clasificación de métodos de MyArrayList}
\label{classifying-myarraylist-methods}

Para muchos métodos, podemos identificar la orden de crecimiento al
examinar el código. Por ejemplo, aquí está la implementación de \java{get} de
\java{MyArrayList}:

\begin{verbatim}
    public E get(int index) {
        if (index < 0 || index >= size) {
            throw new IndexOutOfBoundsException();
        }
        return array[index];
    }
\end{verbatim}

Todo en \java{get} es de tiempo constante, así que \java{get} es de tiempo
constante. Sin problemas.

\index{tiempo constante}
\index{get}

Ahora que hemos clasificado \java{get}, podemos clasificar \java{set},
que lo usa. Aquí está nuestra implementación de \java{set} del
ejercicio anterior:

\begin{verbatim}
    public E set(int index, E element) {
        E old = get(index);
        array[index] = element;
        return old;
    }
\end{verbatim}

Una parte ligeramente astuta de esta solución es que no comprueba los
límites del arreglo de forma explítica, sino que se aprovecha de \java{get},
que lanza una excepción si el índice es inválido.

\index{excepción}
\index{set}

Todo en \java{set}, incluso la invocación de \java{get}, es de
tiempo constante, así que \java{set} también es de tiempo constante.

\index{indexOf}
\index{tiempo lineal}

Luego examinaremos algunos métodos lineales. Por ejemplo, aquí esta mi
implementación de \java{indexOf}:

\begin{verbatim}
    public int indexOf(Object target) {
        for (int i = 0; i<size; i++) {
            if (equals(target, array[i])) {
                return i;
            }
        }
        return -1;
    }
\end{verbatim}

En cada repetición del bucle, \java{indexOf} invoca a \java{equals}, así que
tenemos que clasificar a \java{equals} primero. Aquí está:

\begin{verbatim}
    private boolean equals(Object target, Object element) {
        if (target == null) {
            return element == null;
        } else {
            return target.equals(element);
        }
    }
\end{verbatim}

Este método invoca a \java{target.equals}; el tiempo de ejecución de este
método podría depender del tamaño de \java{target} o de \java{element}, pero
probablemente no depende del tamaño del arreglo, así que lo consideraremos
de tiempo constante para el propósito de de analizar \java{indexOf}.

\index{tiempo constante}
\index{tiempo lineal}
\index{equals}

Regresando a \java{indexOf}, todo dentro del bucle es de tiempo constante, 
así que la siguiente pregunta que tenemos que considerar es: ¿cuántas veces
se repite el bucle?

Si tenemos suerte, podríamos encontrar que el valor objetivo (target) al
principio y devolverlo después de comprobar sólo un elemento. Si somos
desafortunados, podríamos tener que comprobar todos los elementos. En
promedio, esperaríamos comprobar la mitad de los elementos, así que este
método es considerado lineal (excepto en el improbable caso que
sepamos que el elemento objetivo está al principio del arreglo).

\index{remove}

El análisis de \java{remove} es similar. Aquí está mi implementación:

\begin{verbatim}
    public E remove(int index) {
        E element = get(index);
        for (int i=index; i<size-1; i++) {
            array[i] = array[i+1];
        }
        size--;
        return element;
    }
\end{verbatim}

Este método usa a \java{get}, que es de tiempo constante, y luego itera a lo
largo del arreglo, comenzando en \java{index}. Si removemos el elemento al final
de la lista, el bucle nunca se ejecuta y este método es de tiempo constante. Si
removemos el primer elemento, recorreremos todos los elementos restantes, lo
que es lineal. Así que, de nuevo, este método se considera lineal (excepto en el
caso especial donde sabemos que elemento está al final o a una distancia constante
del final).


\section{Clasificación de \java{add}}
\label{classifying-add}

Aquí está una versión de \java{add} que toma un índice y un elemento como parámetros:

\begin{verbatim}
    public void add(int index, E element) {
        if (index < 0 || index > size) {
            throw new IndexOutOfBoundsException();
        }
        // agregar el elemento para forzar el redimensionamiento
        add(element);
        
        // desplaza los otros elementos
        for (int i=size-1; i>index; i--) {
            array[i] = array[i-1];
        }
        // coloca el nuevo elemento en el lugar correcto
        array[index] = element;
    }
\end{verbatim}

Esta versión con dos parámetros, llamada \java{add(int, E)}, usa a
la versión con un parámettros, llamada \java{add(E)}, que agrega un
nuevo elemento al final. Luego desplaza los otros elementos a la derecha,
y coloca el nuevo elemento en el lugar correcto.

\index{add}

Antes de clasificar \java{add(int, E)} con dos parámetros, tenemos que
clasificar \java{add(E)} con un parámetro:

\begin{verbatim}
    public boolean add(E element) {
        if (size >= array.length) {
            // make a bigger array and copy over the elements
            E[] bigger = (E[]) new Object[array.length * 2];
            System.arraycopy(array, 0, bigger, 0, array.length);
            array = bigger;
        } 
        array[size] = element;
        size++;
        return true;
    }
\end{verbatim}

La versión con un parámetro resulta difícil de analizar. Si hay un espacio
sin utilizar en el arreglo, es de tiempo constante, pero si tenemos que
redimensionar el arreglo, es lineal porque \java{System.arraycopy} toma
tiempo proporcional al tamaño del arreglo. 

\index{tiempo constante}
\index{tiempo lineal}

¿Así que es {\tt add} de tiempo constante o lineal?
Podemos clasificar este método al pensar en el número promedio de
operaciones por add en una serie de $n$ adds. Por simplicidad,
asume que comenzamos con un arreglo que tiene espacio para 2 elementos.

\begin{itemize}

\item
  La primera vez que llamamos a add, encuentra un espacio libre en el arreglo, así que
  guarda un elemento.

\item
  La segunda vez, encuentra un espacio libre en el arreglo, así que guarda 1
  elemento.

\item
  La tercera vez, tenemos que redimensionar el arreglo, copiar 2 elementos y
  guardar un elemento. Ahora el tamaño del arreglo es 4.

\item
  La cuarta vez se guarda un elemento.

\item
  La quinta vez redimensiona el arreglo, copia 4 elementos, y guarda 1
  elemento. Ahora el tamaño del arreglo es 8.

\item
  Los siguientes 3 llamados a add guardan 3 elementos.

\item
  El siguiente add copia 8 y guarda 1. Ahora el tamaño es 16.

\item
  Los siguientes 7 llamados a add guardan 7 elementos.

\end{itemize}

Y así sucesivamente. Juntando todo:

\begin{itemize}

\item
  Tras 4 llamados a add, hemos guardado 4 elementos and copiado 2.

\item
  Tras 8 llamados a add, hemos guardado 8 elementos and copiado 6.

\item
  Tras 16 llamados a add, hemos guardado 16 elementos and copiado 14.

\end{itemize}

Por ahora ya deberías ver el patrón: para llamar a add $n$ veces, tenemos
que guardar $n$ elementos y copiar $n-2$. Así que el número total de
operaciones es $n + n - 2$, que es $2n-2$.

Para obtener el número promedio de operaciones por add, dividimos el total por
$n$; el resultado es $2 - 2/n$. Conforme $n$ se hace más grande, el
segundo término, $2/n$, se hace más pequeño. Si tenemos en cuenta el principio que
sólo nos interesa el exponente mayor de $n$, podemos pensar en
\java{add} como de tiempo constante.

\index{tiempo constante}
\index{tiempo lineal}

Podría parecer extraño que un algoritmo que a veces es lineal puede ser de
tiempo constante en promedio. La clave es que duplicamos la longitud del
arreglo cada vez que se redimensiona. Esto limita el número de veces que
cada elemento es copiado. De otra manera --- si agregáramos una cantidad
fija a la longitud del arreglo, en lugar de multiplicar por una cantidad fija --- el
análisis no funcionaría.

% NOTE: Patrick notes potential confusion in my use of average, which
% was an average over a hypothetical set of inputs when we looked at
% indexOf, and here is the average over a sequence of operations.

% I am inclined to leave this alone on the grounds that it it more
% confusing for experts (who know the difference between average
% case analysis and amortized analysis) than for beginners (who will
% not, I conjecture, be bothered).

\index{análisis amortizado}
\index{tiempo promedio}

Esta forma de clasificar un algoritmo, al calcular el tiempo promedio en una
serie de invocaciones, es llamada {\bf análisis amortizado}.  Puedes
leer más al respecto en
\url{http://thinkdast.com/amort}. 
La idea clave es que el costo extra de copiar el arreglo es distribuido,
o ``amortizado'', entre una serie de invocaciones.

Ahora, si \java{add(E)} es de tiempo constante, ¿qué sucede con
\java{add(int, E)}? Tras llamar a \java{add(E)}, itera a través de
parte del arreglo y desplaza elementos. Este bucle es lineal, excepto
en el caso especial donde estamos agregando al final de la lista. Así
que \java{add(int, E)} es lineal.

\index{tiempo lineal}


\section{Tamaño del problema}
\label{classifying-removeall}

El último ejemplo que consideraremos es \java{removeAll}; aquí está la
la implementación en \java{MyArrayList}:

\begin{verbatim}
    public boolean removeAll(Collection<?> collection) {
        boolean flag = true;
        for (Object obj: collection) {
            flag &= remove(obj);
        }
        return flag;
    }
\end{verbatim}

En cada repetición, \java{removeAll} invoca a \java{remove},
que es lineal.  Así que es tentador pensar que \java{removeAll} es
cuadrático.  Pero ese no es necesariamente el caso.

\index{tiempo cuadrático}

En este método, el bucle se ejecuta una vez para cada elemento en
\java{collection}. Si \java{collection} contiene $m$ elementos y la
lista de la que estamos removiendo contiene $n$ elementos, este método está en
$O(nm)$. Si el tamaño de la \java{collection} puede ser considerado constante,
\java{removeAll} es lineal con respecto a $n$. Pero si el tamaño de la
colección es proporcional a $n$, \java{removeAll} es cuadrático. Por ejemplo,
si \java{collection} siempre contiene 100 elementos o menos,
\java{removeAll} es lineal. Pero si \java{collection} generalmente
contiene 1\% de los elementos en la lista, \java{removeAll} es
cuadrático.

\index{tiempo constante}
\index{tamaño del problema}
\index{removeAll}

Cuando hablamos del {\bf tamaño del problema}, tenemos que ser cuidadosos con
respecto a cuál tamaño, o tamaños, estamos hablando. Este ejemplo demuestra
un error de bulto en el análisis de algoritmos: el tentador atajo de contar
bucles. Si sólo hay un bucle, el algoritmo es \emph{generalmente}
linear.  Si hay dos bucles (uno anidado dentro del otro), el algoritmo es
\emph{generalmente} cuadrático. ¡Pero ten cuidado! Tienes que pensar
en cuántas veces se ejecuta cada bucle. Si el número de iteraciones
proporcional a $n$ para todos los bucles, puedes salirte con la tuya limitándote
a contar los bucles. Pero si, como en este ejemplo, el número de iteraciones no es
siempre proporcional a $n$, tendrás que pensarlo con más detalle.


\section{Estructuras de datos enlazadas}
\label{linked-data-structures}

Para el siguiente ejercicio proveo una implementación parcial de la
interfaz \java{List} que usa una lista enlazada para guardar los elementos.
Si no estás familiarizado con las listas enlazadas, puedes leer sobre ellas en
\url{http://thinkdast.com/linkedlist},
pero esta sección provee una breve introducción.

\index{estructuras de datos enlazadas}
\index{nodo}

Una estructura de datos está ``linked'' si está formada por objetos, muchas veces llamados
``nodos'', que contienen referencias a los otros nodos. En una \emph{lista} enlazada,
cada nodo contiene una referencia al siguiente nodo en la lista. Otras estructuras enlazadas
incluyen árboles y grafos, en los cuales los nodos pueden contener referencias a más de
un nodo separado.

Aquí está una definición de clase para un nodo simple:

\begin{verbatim}
public class ListNode {

    public Object data;
    public ListNode next;

    public ListNode() {
        this.data = null;
        this.next = null;
    }

    public ListNode(Object data) {
        this.data = data;
        this.next = null;
    }

    public ListNode(Object data, ListNode next) {
        this.data = data;
        this.next = next;
    }

    public String toString() {
        return "ListNode(" + data.toString() + ")";
    }
}
\end{verbatim}

El objeto \java{ListNode} tiene dos variables de instancia: \java{data} es una
referencia a algún tipo de \java{Object}, y \java{next} es una referencia al
siguiente nodo en la lista. En el último nodo de la lista, por convención,
\java{next} es \java{null}.

\index{null}

\java{ListNode} provee varios constructores, permitiéndote proveer valores
para \java{data} y \java{next}, o inicializarlos con el valor por defecto, \java{null}.

\index{ListNode}

Puedes pensar en cada \java{ListNode} como una lista con un único elemento,
pero de forma más general, una lista puede contener cualquier número de nodos. Hay
varias manera de crear una nueva lista. Una opción simple es crear un conjunto de
objetos \java{ListNode}, así:

\begin{verbatim}
        ListNode node1 = new ListNode(1);
        ListNode node2 = new ListNode(2);
        ListNode node3 = new ListNode(3);
\end{verbatim}

Y luego enlazarlos, de esta manera:

\begin{verbatim}
        node1.next = node2;
        node2.next = node3;
        node3.next = null;
\end{verbatim}

Alternativamente, puedes crear un nodo y enlazarlo al mismo tiempo. Por
ejemplo, si quieres agregar un nuevo nodo al principio de una lista, puedes
hacerlo así::

\begin{verbatim}
        ListNode node0 = new ListNode(0, node1);
\end{verbatim}

Tras esta secuencia de instrucciones, tenemos cuatro nodos que contienen los
\java{Integer}s 0, 1, 2, y 3 como datos, enlazados en orden ascendente. En el
último nodo, el campo \java{next} es \java{null}.

\begin{figure}
\centering
\includegraphics[width=4in]{figs/linked_list1.pdf}
\caption{Diagrama de objeto de una lista enlazada.}
\label{linkedlistfig}
\end{figure}

\index{lista enlazada}
\index{diagrama de objeto}

La figura~\ref{linkedlistfig} es un diagrama de objeto que muestra estas
variables y los objetos a los que se refieren.  En un diagrama de objeto,
las variables aparecen como nombres fuera de las cajas, con flechas que muestran
a qué se refieren. Los objetos aparecen como cajas con su tipo en el exterior
(como \java{ListNode} y \java{Integer}) y sus variables de instancia en el interior.


\section{Ejercicio 3}
\label{exercise3}

En el repositorio para este libro, encontrarás los archivos
de código fuente que necesitas para este ejercicio:

\index{MyLinkedList}

\begin{itemize}

\item \java{MyLinkedList.java} contiene una implementación parcial de
  la interfaz \java{List} que usa una lista enlazada para guardar los elementos.

\item \java{MyLinkedListTest.java} contiene tests de JUnit para
  \java{MyLinkedList}.

\end{itemize}

Ejecute \java{ant MyLinkedList} para correr \java{MyLinkedList.java}, que
contiene unos pocos tests simples. 

Luego puedes ejecutar \java{ant MyLinkedListTest} para correr los tests de JUnit.
Varios de ellos deberían fallar. Si examinas el código fuente, encontrarás
tres comentarios \java{TODO} indicando los métodos que deberías rellenar.

Antes de iniciar, revisemos una porción del
código. Aquí están las variables de instancia y el constructor para
\java{MyLinkedList}:

\begin{verbatim}
public class MyLinkedList<E> implements List<E> {

    private int size;            // registra el número de elementos
    private Node head;           // referencia al primer nodo

    public MyLinkedList() {
        head = null;
        size = 0;
    }
}
\end{verbatim}

Como lo indican los comentarios, \java{size} lleva el control de cuántos elementos
están en \java{MyLinkedList}; \java{head} es una referencia al primer
\java{Node} en la lista o \java{null} si la lista está vacía.

\index{MyLinkedList}

Guardar el número de elementos no es necesario y en general es
riesgoso mantener información redundante, porque si no se actualiza
correctamente, crea oportunidades para cometer errores. Además
toma un poquito de espacio extra.

\index{size}

Pero si guardamos \java{size} explícitamente, podemos implementar el
método \java{size} en tiempo constante; de otra forma, tendríamos que
recorrer toda la lista y contar los elementos, lo que requiere tiempo lineal.

\index{tiempo constante}
\index{tiempo lineal}

Porque guardamos \java{size} explícitamente, tenemos que actualizarlo cada
vez que agregamos o removemos un elemento, así que hace un poco más lentos
estos métodos, pero no cambia su orden de crecimiento, por lo que probablemente
vale la pena.

El constructor establece \java{head} en \java{null}, lo que indica una lista
vacía, y establece \java{size} en 0.

\index{parámetro de tipo}

Esta clase usa un parámetro de tipo \java{E} para el tipo de
elementos. Si no estás familiarizado con los parámetros de tipo, podrías
querer leer este tutorial:
\url{http://thinkdast.com/types}.

El parámetro de tipo también aparece en la definición de \java{Node},
que está anidada dentro de \java{MyLinkedList}:

\begin{verbatim}
    private class Node {
        public E data;
        public Node next;

        public Node(E data, Node next) {
            this.data = data;
            this.next = next;
        }
    }
\end{verbatim}

Aparte de eso, \java{Node} es similar a \java{ListNode}, presentada anteriormente.

\index{Node}
\index{add}

Finalmente, aquí está mi implementación de \java{add}:

\begin{verbatim}
    public boolean add(E element) {
        if (head == null) {
            head = new Node(element);
        } else {
            Node node = head;
            // loop until the last node
            for ( ; node.next != null; node = node.next) {}
            node.next = new Node(element);
        }
        size++;
        return true;
    }
\end{verbatim}

\index{caso especial}

Este ejemplo demuestra dos patrones que necesitarás para tus soluciones:

\begin{enumerate}

\item
  Para muchos métodos, tenemos que tratar al primer elemento de la lista como un
  caso especial. En este ejemplo, si estamos agregando el primer elemento de una
  lista, tenemos que modificar \java{head}. De lo contrario, recorremos la
  lista, encontramos el final, y agregamos el nuevo nodo.

\item
  Este método muestra cómo usar un bucle \java{for} para recorrer los nodos
  en una lista. En tus soluciones, probablemente escribirás varias
  variantes de este bucle. Nota que tenemos que declarar \java{node}
  antes del bucle para poder acceder a él después del bucle.

\end{enumerate}

Ahora es tu turno. Llena el cuerpo de \java{indexOf}.  Como es lo usual,
deberías leer la documentación, en
\url{http://thinkdast.com/listindof},
para que sepas lo que se supone que debe hacer. En particular, nota cómo se
supone que maneje los \java{null}.

\index{método auxiliar}

Como en el ejercicio anterior, proveo un método auxiliar llamado
\java{equals} que compara un elemento de un arreglo a un valor objetivo
y comprueba si son iguales --- y que maneja los \java{null}
correctamente. Este método es privado porque se usa dentro de esta clase
pero no es parte de la interfaz \java{List}.

Cuando termines, ejecuta los tests de nuevo; \java{testIndexOf}
debería pasar ahora, así como los otros tests que dependen de él.

\index{add}

Luego, deberías completar la versión con dos parámetros de \java{add},
que toma un índice y guarda el nuevo valor en el índice dado.
De nuevo, lee la documentación en \url{http://thinkdast.com/listadd},
escriba una implementación y ejecuta los tests para confirmar.

\index{remove}

El último: llena el cuerpo de \java{remove}.  Aquí está la documentación:
\url{http://thinkdast.com/listrem}.  Cuando finalices este, todos los tests
deberían pasar.

Una vez que tus implementaciones funcionen, compáralas a la versión
en el directorio \java{solution} del repositorio.


\section{Una nota sobre la recolección de basura}
\label{a-note-on-garbage-collection}

En \java{MyArrayList} del ejercicio anterior, el arreglo crece si es
necesario, pero nunca se reduce. El arreglo nunca es recolectado y los
elementos no son limpiados por el recolector de basura hasta que la lista
como tal es destruida.

\index{recolección de basura}

Una ventaja de la implementación de lista enlazada es que se reduce cuando
los elementos son removidos y los nodos sin utilizar son limpiados por el
recolector de basura inmediatamente.

\index{clear}

Aquí está mi implmenetación del método \java{clear}:

\begin{verbatim}
    public void clear() {
        head = null;
        size = 0;
    }
\end{verbatim}

Cuando establecemos el valor de \java{head} en \java{null}, removemos una
referencia al primer \java{Node}. Si no hay otras referencias a ese \java{Node}
(y no deberían haber), también es limpiado por el recolector de basura. Este
proceso continúa hasta que todos los nodos son limpiados.

Así que, ¿cómo deberíamos clasificar \java{clear}? El método en si mismo contiene dos
operaciones de tiempo constante, así que seguro parece como de tiempo constante. Pero
cuando lo invocas, haces que el recolector de basura realice un trabajo que es
proporcional al número de elementos. ¡Así que tal vez deberíamos considerarlo lineal!

\index{tiempo constante}
\index{tiempo lineal}
\index{bug de rendimiento}

Este es un ejemplo de lo que a veces se conoce como un {\bf bug de rendimiento}:
un programa que es correcto en el sentido que hace lo correcto,
pero que no pertenece a la orden de crecimiento que esperábamos. En lenguajes
como Java que realizan gran parte del trabajo, como la recolección de basura,
tras bambalinas, esta clase de bug puede ser difícil de encontrar.


\chapter{LinkedList}

Este capítulo presenta soluciones al ejercicio previo y continúa la
discusión sobre el análisis de algoritmos.


\section{Clasificación de los métodos de \java{MyLinkedList}}
\label{classifying-mylinkedlist-methods}

Mi implementación de \java{indexOf} se encuentra a continuación. Léela y mira
si puedes identificar su orden de crecimiento antes de leer la explicación.

\begin{verbatim}
    public int indexOf(Object target) {
        Node node = head;
        for (int i=0; i<size; i++) {
            if (equals(target, node.data)) {
                return i;
            }
            node = node.next;
        }
        return -1;
    }
\end{verbatim}

Inicialmente \java{node} obtiene una copia de \java{head}, así que ambos se
refieren al mismo \java{Node}. La variable de repetición, \java{i}, cuenta desde 0 hasta
\java{size-1}.  En cada repetición del bucle, usamos \java{equals} para
ver si hemos encontrado el objetivo (\java{target}). De ser así, devolvemos \java{i} inmediatamente.
De lo contrario, avanzamos al siguiente \java{Node} en la lista.

Normalmente deberíamos asegurarnos que el siguiente \java{Node} no sea
\java{null}, pero en este caso es seguro porque el bucle termina al llegar al
final de la lista (asumiendo que \java{size} es consistente con el número exacto de nodos en la lista).

Si el bucle finaliza sin haber encontrado al objetivo, devolvemos
\java{-1}.

\index{indexOf}
\index{tiempo constante}

Así que, ¿cuál es la orden de crecimiento para este método?

\begin{enumerate}

\item
  En cada repetición del bucle invocamos \java{equals}, que es de
  tiempo constante (lo que podría depender del tamaño de \java{target} o
  \java{data}, pero no depende del tamaño de la lista). Las
  otras operaciones en el bucle son también de tiempo constante.

\item
  El bucle podría ejecutarse $n$ veces, porque en el peor escenario,
  podríamos tener que recorrer la lista completa.

\end{enumerate}

Así que el tiempo de ejecución de este método es proporcional a la longitud
de la lista.

\index{add}

Para continuar, aquí está mi implementación del método \java{add}
con dos parámetros. De nuevo, deberías tratar de clasificarlo antes de
leer la explicación.

\begin{verbatim}
    public void add(int index, E element) {
        if (index == 0) {
            head = new Node(element, head);
        } else {
            Node node = getNode(index-1);
            node.next = new Node(element, node.next);
        }
        size++;
    }
\end{verbatim}

Si \java{index==0}, agregamos el nuevo \java{Node} al principio,
así que lo trataremos como un caso especial. De lo contrario, tendríamos
que recorrer la lista para encontrar el elemento en \java{index-1}. Usamos el
método auxiliar \java{getNode}:

\index{método auxiliar}

\begin{verbatim}
    private Node getNode(int index) {
        if (index < 0 || index >= size) {
            throw new IndexOutOfBoundsException();
        }
        Node node = head;
        for (int i=0; i<index; i++) {
            node = node.next;
        }
        return node;
    }
\end{verbatim}

\java{getNode} comprueba si el \java{index} está fuera de rango; de ser así,
lanza una excepción. De otra forma, recorre la lista y devuelve el Nodo solicitado.

\index{getNode}

Volviendo a \java{add}, una vez encontramos el \java{Node} apropiado, creamos el
nuevo \java{Node} y lo colocamos entre \java{node} y \java{node.next}. Podrías
encontrar útil dibujar un diagrama de esta operación para estar seguro que la
entiendes.

Así, ¿cuál es la orden de crecimiento para \java{add}?

\begin{enumerate}

\item
  \java{getNode} es similar a
  \java{indexOf}, y es lineal por la misma razón.

\item
  En \java{add}, todo antes y después de \java{getNode} es
  de tiempo constante.

\end{enumerate}

Al combinar todo, \java{add} es lineal.

\index{tiempo constante}
\index{tiempo lineal}
\index{remove}

Finalmente, examinemos \java{remove}:

\begin{verbatim}
    public E remove(int index) {
        E element = get(index);
        if (index == 0) {
            head = head.next;
        } else {
            Node node = getNode(index-1);
            node.next = node.next.next;
        }
        size--;
        return element;
    }
\end{verbatim}

\java{remove} usa \java{get} para encontrar y guardar el elemento en
\java{index}. Luego remueve el \java{Node} que lo contiene.

Si \java{index==0}, de nuevo lo tratamos como un caso especial. De lo contrario
encontramos el nodo en \java{index-1} y lo modificamos para que se salte
\java{node.next} y se enlace directamente con \java{node.next.next}. Esto
efectivamente remueve \java{node.next} de la lista, y puede ser limpiado
por el recolector de basura.

Finalmente, disminuimos \java{size} y devolvemos el elemento que recuperamos
al principio.

Así, ¿cuál es la orden de crecimiento para \java{remove}? Todo en
\java{remove} es de tiempo constante excepto \java{get} y
\java{getNode}, que son lineales. Así que \java{remove} es lineal.

Cuando las personas ven dos operaciones lineales, a veces creen que el resultado
es cuadrático, pero eso solo aplica si una operación está anidadad dentro de
la otra. Si invocas una operación después de la otra, los tiempos de ejecución
se suman. Si ambas están en $O(n)$, la suma también está en
$O(n)$.

\index{tiempo lineal}
\index{tiempo cuadrático}


\section{Comparación entre \java{MyArrayList} y \java{MyLinkedList}}
\label{comparing-mylinkedlist-and-myarraylist}

\index{MyArrayList}
\index{MyLinkedList}

La siguiente tabla resume las diferencias entre
\java{MyLinkedList} y \java{MyArrayList}, donde \java{1} significa
$O(1)$ o tiempo constante y $n$ significa $O(n)$ o
lineal.

\begin{tabular}[c]{@{}lll@{}}
\hline
& MyArrayList & MyLinkedList \\
\hline
add (al final) & \textbf{1} & n
\\
add (al principio) & n & \textbf{1}
\\
add (en general) & n & n
\\
get / set & \textbf{1} & n
\\
indexOf / lastIndexOf & n & n
\\
isEmpty / size & 1 & 1
\\
remove (del final) & \textbf{1} & n
\\
remove (del principio) & n & \textbf{1}
\\
remove (en general) & n & n
\\
\hline
\end{tabular}

Las operaciones en las \java{MyArrayList} destaca son agregar (add) al final,
remover (remove) del final, obtener (get) y establecer (set).

Las operaciones en las que \java{MyLinkedList} destaca son agregar al
principio y remover del principio.

Para otras operaciones, las dos implementaciones están en la misma orden
de crecimiento.

\index{orden de crecimiento}

¿Cuál implementación es mejor? Depende de cuáles operaciones es
probable que uses más. Y es por eso que Java provee más de una
implementación, porque esto depende.


\section{Perfilado}

Para el siguiente ejercicio proveo una clase llamada \java{Profiler} que
contiene código que ejecuta un método para varios tamaños de problemas,
mide el tiempo de ejecución y grafica los resultados.

\index{perfilado}

Usarás un \java{Profiler} (Perfilador) para clasificar el desempeño
de los métodos \java{add} para las implementaciones en Java de
\java{ArrayList} y \java{LinkedList}.

Aquí está un ejemplo que muestra como usar el perfilador:

\begin{verbatim}
    public static void profileArrayListAddEnd() {
        Timeable timeable = new Timeable() {
            List<String> list;

            public void setup(int n) {
                list = new ArrayList<String>();
            }

            public void timeMe(int n) {
                for (int i=0; i<n; i++) {
                    list.add("a string");
                }
            }
        };

        String title = "ArrayList add end";
        Profiler profiler = new Profiler(title, timeable);

        int startN = 4000;
        int endMillis = 1000;
        XYSeries series = profiler.timingLoop(startN, endMillis);
        profiler.plotResults(series);
    }
\end{verbatim}

Este método mide el tiempo que toma ejecutar \java{add} en una
\java{ArrayList}, el cual agrega el nuevo elemento al final. Explicaré
el código y luego mostraré los resultados.

\index{add}

Para usar el \java{Profiler}, necesitamos crear un objeto \java{Timeable}
que provee dos métodos: \java{setup} and \java{timeMe}.
El método \java{setup} hace lo que sea que se necesite hacer antes de iniciar
el cronómetro; en este caso crea una lista vacía. Luego \java{timeMe}
realiza cualquier operación que estemos tratando de medir; en este caso
agrega $n$ elementos a la lista.

\index{Profiler}
\index{Timeable}
\index{clase anónima}

El código que crea \java{timeable} es una {\bf clase anónima} que
define una nueva implementación de la interfaz \java{Timeable} y
crea una instancia de la nueva clase al mismo tiempo. Si no estás
familiarizado con las clases anónimas, puedes leer sobre ellas aquí:
\url{http://thinkdast.com/anonclass}.

Pero no necesitas conocer mucho para el siguiente ejercicio; incluso si
no te sientes cómodo con las clases anónimas, puedes copiar
y modificar el código de ejemplo.

El siguiente paso es crear el objeto \java{Profiler} pasándole el
objeto \java{Timeable} y un título como parámetros.

El \java{Profiler} provee \java{timingLoop} que usa el objeto
\java{Timeable} guardado como una variable de instancia. Éste invoca al
métoodo \java{timeMe} en el objeto \java{Timeable} varias veces
con un rango de valores de $n$. \java{timingLoop} toma dos
parámetros:

\begin{itemize}

\item
  \java{startN} es el valor de $n$ con el que debería iniciar el
  temporizador.

\item
  \java{endMillis} es un umbral en milisegundos. Conforme
  \java{timingLoop} incrementa el tamaño del problema, el tiempo de ejecución se incrementa;
  cuando el tiempo de ejecución sobrepasa este umbral, \java{timingLoop} se detiene.

\end{itemize}

Cuando realices los experimentos, podrías tener que ajustar estos
parámetros. Si \java{startN} es muy bajo, el tiempo de ejecución podría
ser muy corto para medirlo con exactitud. Si \java{endMillis} es muy bajo, puede
que no obtengas datos suficientes para ver una relación clara entre el tamaño del
problema y el tiempo de ejecución.

Este código está en \java{ProfileListAdd.java}, que ejecutarás en el siguiente
ejercicio. Cuando yo lo ejecuté, obtuve esta salida:

\begin{verbatim}
4000, 3
8000, 0
16000, 1
32000, 2
64000, 3
128000, 6
256000, 18
512000, 30
1024000, 88
2048000, 185
4096000, 242
8192000, 544
16384000, 1325
\end{verbatim}

La primera columna es el tamaño del problema, $n$; la segunda columna es
el tiempo de ejecución en milisegundos. Las primeras mediciones contienen
bastante ruido, podría haber sido mejor establecer \java{startN} alrededor de 64000.

\index{XYSeries}

El resultado del \java{timingLoop} es una \java{XYSeries} que
contiene estos datos. Si pasas esta serie a \java{plotResults},
genera una gráfica como la de Figura~\ref{fig-profile1}.

\begin{figure}
\centering
\includegraphics[height=2.5in]{figs/profile1.png}
\caption{Resultados del perfilado: tiempo de ejecución versus tamaño del problema para
agregar $n$ elementos al final de una \java{ArrayList}.}
\label{fig-profile1}
\end{figure}

La siguiente sección explica cómo interpretarla.


\section{Interpretación de los resultados}\label{interpreting-results}

Con base en nuestro entendimiento sobre cómo funciona \java{ArrayList},
esperaríamos que el método \java{add} tome una cantidad de tiempo constante
cuando agregamos elementos al final. Así que el tiempo total para agregar $n$
elementos debería ser lineal.

\index{tiempo constante}
\index{tiempo lineal}
\index{ArrayList}

Para comprobar esta teoría, podríamos graficar el tiempo total de ejecución
versus el tamaño del problema, y deberíamos ver una línea recta, al menos
para tamaños de problemas lo suficientemente grandes para obtener mediciones
precisas. Matemáticamente, podemos escribir la función para esa línea:

\newcommand{\runtime}{\mbox{tiempo de ejecución}}

\[ \runtime = a + b n \]

donde $a$ es la intersección de la línea y $b$ es la pendiente.

\index{tiempo cuadrático}

Por otro lado, si \java{add} es lineal, el tiempo total para
$n$ adds sería cuadrático. Si graficamos el tiempo de ejecución versus el tamaño
del problema, esperaríamos ver una parábola. O matemáticamente, algo como:

\[ \runtime = a + b n + c n^2 \]

Con datos perfectos, podríamos ser capaces de distinguir entre una línea
recta y una parábola, pero si las mediciones contienen ruido, esto puede
ser difícil. Una mejor manera de interpretar mediciones con ruido es
graficar el tiempo de ejecución y el tamaño del problema en una
escala \textbf{log-log}.

\index{logaritmo}
\index{escala log-log}

¿Por qué? Supongamos que el tiempo de ejecución es proporcional
a $n^k$, pero no sabemos cuál es el exponente $k$. Podemos escribir la
relación como sigue:

\[ \runtime = a + b n + \ldots + c n^k \]

Para valores grandes de $n$, el término con el exponente mayor es el
más importante, así que:

\[ \runtime \approx c n^k \]

donde $\approx$ significa ``aproximadamente igual a''. Ahora, si
calculamos el logaritmo de ambos lados de la ecuación:

\[ \log(\runtime) \approx \log(c) + k \log(n) \]

Esta ecuación implica que si graficamos $\runtime$ versus $n$ en una
escala log-log, esperaríamos ver una línea recta con intersección
$\log(c)$ y pendiente $k$. No nos interesa mucho la intersección,
pero la pendiente indica la orden de crecimiento: si
$k=1$, el algoritmo es lineal; si $k=2$, es cuadrático.

\index{pendiente}

Al observar la figura de la sección previa, puedes estimar la
pendiente visualmente. Pero cuando llamas a \java{plotResults}
se calcula un ajuste de mínimos cuadrados y se imprime la pendiente
estimada. En este ejemplo:

\begin{verbatim}
Estimated slope = 1.06194352346708
\end{verbatim}

Que es cercano a 1; y eso sugiere que el tiempo total para $n$ llamadas a add
es lineal, así que cada add es de tiempo constante, tal como esperábamos.

\index{tiempo constante}

Un punto importante: si ves una línea recta en una gráfica como esta,
eso \textbf{no} significa que el algoritmo es lineal. Si el tiempo de ejecuión
es proporcional a $n^k$ para cualquier exponente $k$, esperaríamos ver
una línea recta con pendiente $k$. Si la pendiente es cercana a 1, eso
sugiere que el algoritmo es lineal. Si es cercana a 2, probablemente sea
cuadrático.

\index{tiempo lineal}
\index{tiempo cuadrático}


\section{Ejercicio 4}
\label{instructions-4}

En el repositorio para este libro encontrarás los archivos de código fuente que
necesitarás para este ejercicio:

\begin{enumerate}

\item
  \java{Profiler.java} contiene la implementación de la clase
  \java{Profiler} descrita anteriormente. Usarás esta clase, aunque no
  tienes que saber cómo funciona. Pero siéntete libre de leer el código.

\item
  \java{ProfileListAdd.java} contiene un código inicial para este ejercicio,
  incluyendo el ejemplo anterior, que perfila
  \java{ArrayList.add}. Modificarás este archivo para perfilar algunos
  otros métodos.

\end{enumerate}

\index{ProfileListAdd}

También, en el directorio \java{code}, encontrarás el archivo de
construcción Ant \java{build.xml}.

Ejecuta \java{ant ProfileListAdd} para correr \java{ProfileListAdd.java}. Deberías
obtener resultados similares a la Figura~\ref{fig-profile1}, pero puede que tengas que
ajustar \java{startN} o \java{endMillis}. La pendiente estimada debería ser cercana
a 1, lo que indica que realizar $n$ operaciones add toma un tiempo proporcional
a $n$ elevada al exponente 1; es decir, está en $O(n)$.

En \java{ProfileListAdd.java}, encontrarás un método vacío llamado
\java{profileArrayListAddBeginning}. Llena el cuerpo de este método
con el código que prueba \java{ArrayList.add}, siempre poniendo el nuevo
elemento al principio. Si inicias con una copia de \java{profileArrayListAddEnd},
deberías tener que hacer unos cuantos cambios. Agrega una línea en
\java{main} para invocar este método.

Ejecuta \java{ant ProfileListAdd} de nuevo e interpreta los resultados. Con base en
nuestro entendimiento de cómo funciona una \java{ArrayList} esperaríamos que cada
operación add fuese lineal, así que el tiempo total para $n$ llamadas a add debería ser
cuadrático. De ser el caso, la pendiente estimada de la línea, en una escala log-log,
debería ser cercana a 2. ¿Lo es?

\index{tiempo lineal}
\index{tiempo cuadrático}

Ahora comparemos estas mediciones con el desempeño de \java{LinkedList}. Llena
el cuerpo de \java{profileLinkedListAddBeginning} y úsalo para clasificar
\java{LinkedList.add} cuando colocamos el nuevo elemento al principio. ¿Qué
desempeño esperaríamos? ¿Son los resultados consistentes con tus expectativas?

\index{LinkedList}

Finalmente, llena el cuerpo de \java{profileLinkedListAddEnd} y úsalo
para clasificar \java{LinkedList.add} cuando colocamos el nuevo elemento al
final. ¿Qué rendimiento esperarías? ¿Son los resultados consistentes con
tus expectativas?

Presentaré los resultados y las respuestas a estas preguntas en el siguiente capítulo.


\chapter{Listas de enlace doble}

Este capítulo revisa los resultados de los ejercicios previos e introduce
otra implementación de la interfaz \java{List}, la lista de enlace doble.

\section{Resultados del perfilado de desempeño}
\label{performance-profiling-results}

\index{perfilado}

En el ejercicio anterior, usamos \java{Profiler.java} para realizar varias
operaciones con \java{ArrayList} y \java{LinkedList} para un rango de
tamaños de problemas. Graficamos los tiempos de ejecución versus el tamaño
del problema en una escala log-log y estimamos la pendiente de la curva
resultante, que indica el exponente predominante de la relación entre tiempo
de ejecución y tamaño del problema.

\index{Profiler}
\index{add}
\index{tiempo promedio}

Por ejemplo, cuando usamos el método \java{add} para agregar elementos
al final de una \java{ArrayList}, encontramos que el tiempo total para llevar a
cabo $n$ llamadas a add era proporcional a $n$; es decir, la pendiente
estimada era cercana a 1. Concluimos que completar $n$ llamadas a add
está en $O(n)$, así que en promedio el tiempo para una llamada a add es de
tiempo constante, o $O(1)$, que es lo que esperaríamos con base en el análisis
de los algoritmos.

\index{tiempo constante}

% NOTE: Again, Patrick is concerned that my use of ``average'' might
% be confusing, but I think it's reasonable to describe amortized
% analysis as an average over a series of operations.

El ejercicio te pedía llenar el cuerpo de
\java{profileArrayListAddBeginning}, que prueba el desempeño de
agregar nuevos elementos al principio de una \java{ArrayList}. Con base en
nuestro análisis, esperábamos que add fuera lineal, porque tiene que desplazar
los otros elementos a la derecha; así que esperíamos que $n$ llamadas a add
sean cuadráticas.

\index{tiempo cuadrático}
\index{tiempo lineal}

Aquí está una solución, que puedes encontrar en
el directorio {\tt solution} del repositorio.

\begin{verbatim}
    public static void profileArrayListAddBeginning() {
        Timeable timeable = new Timeable() {
            List<String> list;

            public void setup(int n) {
                list = new ArrayList<String>();
            }

            public void timeMe(int n) {
                for (int i=0; i<n; i++) {
                    list.add(0, "a string");
                }
            }
        };
        int startN = 4000;
        int endMillis = 10000;
        runProfiler("ArrayList add beginning", timeable, startN, endMillis);
    }
\end{verbatim}

Este método es casi idéntico a \java{profileArrayListAddEnd}. La
única diferencia está en \java{timeMe}, que usa la versión de dos
parámetros de \java{add} para colocar el nuevo elemento en el índice 0. También,
incrementos \java{endMillis} para obtener un punto de datos adicional.

Aquí están los resultados de las mediciones (tamaño del problema a la
izquierda, tiempo de ejecución en milisegundos a la derecha):

\begin{verbatim}
4000, 14
8000, 35
16000, 150
32000, 604
64000, 2518
128000, 11555
\end{verbatim}

La figura~\ref{fig-profile2}
muestra la gráfica de tiempo de ejecución versus tamaño del problema.
\index{problem size}

\begin{figure}
\centering
\includegraphics[height=2.5in]{figs/profile2.png}
\caption{Resultados del perfilado: tiempo de ejecución versus tamaño del problema para agregar
$n$ elementos al principio de una \java{ArrayList}.}
\label{fig-profile2}
\end{figure}

Recuerda que una línea recta en esta gráfica \textbf{no} significa que
el algoritmo es lineal. En su lugar, si el tiempo de ejecución es proporcional a
$n^k$ para cualquier exponente, $k$, esperaríamos ver una línea recta
con pendiente $k$. En este caso, esperaríamos que el tiempo total para $n$ llamadas a
add sea proporcional a $n^2$, así que esperaríamos una línea recta con pendiente
2. De hecho, la pendiente estimada es 1.992, que se acerca tanto que me daría
temor falsificar datos tan buenos.

\index{perfilado}


\section{Perfilado de los métodos de \java{LinkedList}}
\label{profiling-linkedlist-methods}

En el ejercicio anterior también perfilaste el desempeño de agregar nuevos
elementos al principio de una \java{LinkedList}. Con base en nuestro
análisis, esperaríamos que cada llamada a \java{add} tomara tiempo constante,
porque en una lista enlazada, no tenemos que desplazar los elementos existentes;
podemos simplemente agregar un nuevo nodo al principio. Así que esperaríamos
que el tiempo total para $n$ llamadas a add fuese lineal.

\index{tiempo constante}
\index{tiempo lineal}
\index{LinkedList}

Aquí está una solución:

\begin{verbatim}
    public static void profileLinkedListAddBeginning() {
        Timeable timeable = new Timeable() {
            List<String> list;

            public void setup(int n) {
                list = new LinkedList<String>();
            }

            public void timeMe(int n) {
                for (int i=0; i<n; i++) {
                    list.add(0, "a string");
                }
            }
        };
        int startN = 128000;
        int endMillis = 2000;
        runProfiler("LinkedList add beginning", timeable, startN, endMillis);
    }
\end{verbatim}

Tenemos que hacer unos cuantos cambios, reemplazando
\java{ArrayList} con \java{LinkedList} y ajustando
\java{startN} y \java{endMillis} para obtener un buen rango de datos.
Las mediciones contenían más ruido que el anterior intento; aquí están
los resultados:

\begin{verbatim}
128000, 16
256000, 19
512000, 28
1024000, 77
2048000, 330
4096000, 892
8192000, 1047
16384000, 4755
\end{verbatim}

La figura~\ref{fig-profile3}
muestra la gráfica de estos resultados.

\begin{figure}
\centering
\includegraphics[height=2.5in]{figs/profile3.png}
\caption{Resultados del perfilado: tiempo de ejecución versus tamaño del problema para
agregar $n$ elementos al principio de una \java{LinkedList}.}
\label{fig-profile3}
\end{figure}

No es una línea muy recta, y la pendiente no es exactamente 1; la pendiente
del ajuste de mínimos cuadrados es 1.23. Pero estos resultados indican que
el tiempo total para $n$ llamadas a add es por lo menos aproximadamente $O(n)$,
así que cada llamada a add es de tiempo constante.

\index{tiempo constante}

\section{Agregar al final de una \java{LinkedList}}
\label{adding-to-the-end-of-a-linkedlist}

Agregar elementos al principio es una de las operaciones donde
esperamos que \java{LinkedList} sea más rápida que \java{ArrayList}. Pero para
agregar elementos al final, esperamos que \java{LinkedList} sea más lenta.
En mi implementación, tenemos que recorrer la lista completa para agregar
un elemento al final, lo que es lineal. Así que esperamos que el tiempo total
para $n$ llamadas a add sea cuadrático.

\index{tiempo cuadrático}
\index{tiempo lineal}
\index{LinkedList}
\index{add}

Bien, no lo es. Aquí está el código:

\begin{verbatim}
    public static void profileLinkedListAddEnd() {
        Timeable timeable = new Timeable() {
            List<String> list;

            public void setup(int n) {
                list = new LinkedList<String>();
            }

            public void timeMe(int n) {
                for (int i=0; i<n; i++) {
                    list.add("a string");
                }
            }
        };
        int startN = 64000;
        int endMillis = 1000;
        runProfiler("LinkedList add end", timeable, startN, endMillis);
    }
\end{verbatim}

Aquí están los resultados:

\begin{verbatim}
64000, 9
128000, 9
256000, 21
512000, 24
1024000, 78
2048000, 235
4096000, 851
8192000, 950
16384000, 6160
\end{verbatim}

La figura~\ref{fig-profile4}
muestra la gráfica de estos resultados.

\begin{figure}
\centering
\includegraphics[height=2.5in]{figs/profile4.png}
\caption{Resultados del perfilado: tiempo de ejecución versus tamaño del problema
para agregar $n$ elementos al final de una \java{LinkedList}.}
\label{fig-profile4}
\end{figure}

\index{perfilado}

De nuevo, las medidas contienen mucho ruido y la línea no es perfectamente
recta, pero la pendiente estimada es 1.19, que es cercana a la que obtuvimos
al agregar elementos al principio, y no muy cercana a 2, que es lo que
esperábamos con base en nuestro análisis. De hecho, es más cercana a
1, lo que sugiere que agregar elementos al final es de tiempo constante.
¿Qué está sucediendo?

\index{tiempo constante}

\section{Lista de enlace doble}
\label{doubly-linked-list}

Mi implementación de una lista enlazada, \java{MyLinkedList}, usa una
lista de enlace sencillo; es decir, cada elemento contiene un enlace al siguiente
y el objeto \java{MyArrayList} en sí mismo tiene un enlace al primer nodo.

\index{lista de enlace doble}
\index{LinkedList}

Pero si lees la documentación de \java{LinkedList} en
\url{http://thinkdast.com/linked},
dice:

\begin{quote}
Implementación de lista de enlace doble de las interfaces
List y Deque. [\ldots] Todas las operaciones se desempeñan
como podría esperarse de una lista de enlace doble. Las operaciones
provean un índice a la lista recorrerán la lista desde el principio o desde
el final, dependiendo de cuál esté más cerca al índice especificado.
\end{quote}

Si no estás familiarizado con las listas de enlace doble, puedes leer
más sobre ellas en \url{http://thinkdast.com/doublelist}, pero la
versión corta es:

\begin{itemize}
\item
  Cada nodo contiene un enlace al siguiente nodo y un enlace al nodo
  previo.

\item
  El objeto \java{LinkedList} contiene enlaces al primer y último
  elementos de la lista.

\end{itemize}

Así que podemos empezar en cualquier extremo de la lista y recorrerla
en cualquier dirección. Como resultado, ¡podemos agregar y remover
elementos desde el principio y el final de la lista en tiempo constante!

\index{tiempo constante}

La siguiente tabla resume el desempeño que esperaríamos de
\java{ArrayList}, \java{MyLinkedList} (enlace simple), y
\java{LinkedList} (enlace doble):

\begin{tabular}[c]{@{}llll@{}}
\hline
& MyArrayList & MyLinkedList & LinkedList
\\
\hline
add (al final) & \textbf{1} & n & \textbf{1}
\\
add (al principio) & n & \textbf{1} & \textbf{1}
\\
add (en general) & n & n & n
\\
get / set & \textbf{1} & n & n
\\
indexOf / lastIndexOf & n & n & n
\\
isEmpty / size & 1 & 1 & 1
\\
remove (del final) & \textbf{1} & n & \textbf{1}
\\
remove (del principio) & n & \textbf{1} & \textbf{1}
\\
remove (en general) & n & n & n
\\
\hline
\end{tabular}


\section{Elección de una estructura}

La implementación de enlace doble es mejor que \java{ArrayList} para
agregar y remover al principio e igual de buena que
\java{ArrayList} para agregar y remover al final. Así que la única
ventaja de \java{ArrayList} es para \java{get} y \java{set},
que requieren tiempo lineal en una lista enlazada, incluso si es de enlace doble.

\index{tiempo lineal}
\index{selección de una estructura de datos}
\index{elección de una estructura de datos}

Si sabes que el tiempo de ejecución de tu aplicación depende del tiempo
que toma obtener (\java{get}) o modificar (\java{set}) los elementos,
una \java{ArrayList} podría ser la mejor opción. Si el tiempo de ejecución depende de
agregar y remover elementos cerca del principio o del final, \java{LinkedList}
podría ser mejor.

\index{orden de crecimiento}
\index{tiempo constante}

Pero recuerda que estas recomendaciones se basan en la orden de crecimiento
para problemas grandes. Hay otros factores a considerar:

\begin{itemize}

\item
  Si estas operaciones no requieren una fracción sustancial del tiempo
  de ejecución para tu aplicación --- es decir, si tu aplicación pasa la
  mayor parte de su tiempo haciendo otras cosas --- entonces tu elección
  de una implementación de \java{List} no importará mucho.

\item
  Si las listas con las que estás trabajando no son muy grandes, podría ser
  que no obtengas el desempeño que esperas. Para problemas pequeños, un
  algoritmo cuadrático podría ser más rápido que un algoritmo lineal, o un algoritmo
  lineal podría ser más rápido que uno de tiempo constante. Y para problemas
  pequeños, la diferencia probablemente no es importante.

\item
  También, no olvides el espacio. Hasta el momento nos hemos enfocado en el
  tiempo de ejecución, pero diferentes implementaciones requieren diferentes
  cantidades de espacio. En una \java{ArrayList}, los elementos se guardan uno a
  la par de otro en un trozo de la memoria, así que hay poco espacio
  desperdiciado y el hardware de la computadora es más rápido con trozos
  contiguos. En una lista enlazada, cada elemento requiere un nodo con uno o dos
  enlaces. Los enlaces ocupan espacio (¡a veces más que los datos!), y con nodos
  dispersos por todas partes en la memoria, el hardware podría ser menos eficiente.

\end{itemize}

En resumen, el análisis de algoritmos provee algunas guías para elegir entre
estructuras de datos, pero solo si

\begin{enumerate}

\item
  El tiempo de ejecución de tu aplicación es importante,

\item
  El tiempo de ejecución de tu aplicación depende de la elección de una estructura
  de datos y

\item
  El tamaño del problema es lo suficientemente grande para que el orden de crecimiento
  realmente prediga cuál estructura de datos es mejor.

\end{enumerate}

Podrías tener una larga carrera como ingeniero de software y nunca encontrarte
en esta situación.


\chapter{Recorrido de árboles}
\label{cs-traversing-trees}

Este capítulo introduce la aplicación que desarrollaremos durante el
resto del libro, un motor de búsqueda web.
Describo los elementos de un motor de búsqueda e
introduzco la primera aplicación, un rastreador Web que descarga e interpreta
páginas de Wikipedia.  Este capítulo también presenta una implementación
recursiva de la búsqueda en profundidad y una implementación iterativa que usa
una \java{Deque} de java para implementar una pila ``último en entrar, primero en salir''.

\index{Deque}

\section{Motores de búsqueda}
\label{the-road-ahead}

Un \textbf{motor de búsqueda web}, como Google Search o Bing, toma un conjunto
de ``términos de búsqueda'' y devuelve una lista de páginas web que son relevantes
para esos términos (explicaré más tarde lo que significa ``relevante'').  Puedes leer
más en \url{http://thinkdast.com/searcheng}, pero explicaré lo que necesites conforme
que avancemos.

\index{motor de búsqueda}
\index{término de búsqueda}
\index{rastreador}
\index{indexador}
\index{recuperador}

Los componentes esenciales de un motor de búsqueda son:

\begin{itemize}

\item
  Rastrear: Necesitaremos un programa que pueda descargar una página, interpretarla
  y extraer el texto y cualquier enlace a otras páginas.

\item
  Indexar: Necesitaremos una estructura de datos que haga posible buscar un término
  de búsqueda y encontrar las páginas que lo contienen.

\item
  Recuperar: Y necesitaremos una forma de recolectar los resultados del Índice e identificar
  las páginas que son más relevantes para los términos de búsqueda.

\end{itemize}

Comenzaremos con el rastreador. La meta de un rastreador es descubir y
descargar un conjunto de páginas web. Para motor de búsqueda como Google
y Bing, la meta es encontrar \emph{todas} las páginas web, pero muchas veces los
rastreadores están limitados a un dominio más pequeño. En nuestro caso, sólo leeremos
páginas de Wikipedia.

\index{Wikipedia}
\index{Llegar a la filosofía}

Como un primer paso, construiremos un rastreador que lea una página de Wikipedia,
encuentre el primer enlace, siga un enlace a otra página y repita el proceso. Usaremos
este rastreador para comprobar la conjetura ``Llegar a la Filosofía'', que establece:

\begin{quote}
Al hacer clic en el primer enlace en minúsculas en el texto principal de un artículo de
Wikipedia, y luego repetir el proceso para artículos subsiguientes, por lo general
eventualmente te conducirá al artículo sobre Filosofía.
\end{quote}

La conjetura se establece en
\url{http://thinkdast.com/getphil}{},
y puedes leer su historia ahí.

Probar la conjetura nos permitirá
Testing the conjecture will allow us to build the basic pieces of a
crawler without having to crawl the entire web, or even all of
Wikipedia. And I think the exercise is kind of fun!

In a few chapters, we'll work on the indexer, and then we'll get to the
retriever.

\section{Parsing HTML}
\label{parsing-html}

When you download a web page, the contents are written in
HyperText Markup Language, aka HTML.
For example, here is a minimal HTML document:

\begin{verbatim}
<!DOCTYPE html>
<html>
  <head>
    <title>This is a title</title>
  </head>
  <body>
    <p>Hello world!</p>
  </body>
</html>
\end{verbatim}

The phrases ``This is a title'' and ``Hello world!'' are the text that
actually appears on the page; the other elements are \textbf{tags} that
indicate how the text should be displayed.

\index{HTML}
\index{tag}
\index{jsoup}
\index{parsing}

When our crawler downloads a page, it will need to parse the HTML in
order to extract the text and find the links. To do that, we'll use
\textbf{jsoup}, which is an open-source Java library that downloads and
parses HTML.

\index{DOM tree}

The result of parsing HTML is a Document Object Model tree, or
\textbf{DOM tree}, that contains the elements of the document, including
text and tags. The tree is a linked data structure made up of nodes; the
nodes represent text, tags, and other document elements.

\index{root}
\index{child node}

The relationships between the nodes are determined by the structure of
the document. In the example above, the first node, called the
\textbf{root}, is the \java{<html>} tag, which
contains links to the two nodes it contains,
\java{<head>} and
\java{<body>}; these nodes are the
\textbf{children} of the root node.

The \java{<head>} node has one child,
\java{<title>}, and the
\java{<body>} node has one child,
\java{<p>} (which stands for ``paragraph''). 
Figure~\ref{fig-dom1}
 represents this tree graphically.

\begin{figure}
\centering
\includegraphics[height=2.5in]{figs/dom_tree1.pdf}
\caption{DOM tree for a simple HTML page.}
\label{fig-dom1}
\end{figure}


Each node contains links to its children; in addition, each node
contains a link to its \textbf{parent}, so from any node it is possible
to navigate up and down the tree. The DOM tree for real pages is usually
more complicated than this example.

\index{parent node}
\index{inspecting the DOM}

Most web browsers provide tools for inspecting the DOM of the page you
are viewing. In Chrome, you can right-click on any part of a web page
and select ``Inspect'' from the menu that pops up. In Firefox, you can
right-click and select ``Inspect Element'' from the menu. Safari
provides a tool called Web Inspector, which you can read about at
\url{http://thinkdast.com/safari}.
For Internet Explorer, you can read the instructions at
\url{http://thinkdast.com/explorer}.

\begin{figure}
\centering
\includegraphics[height=2.5in]{figs/DOMinspector.png}
\caption{Screenshot of the Chrome DOM Inspector.}
\label{fig-dom2}
\end{figure}

Figure~\ref{fig-dom2}
shows a screenshot of the DOM for the Wikipedia page on Java,
\url{http://thinkdast.com/java}.
The element that's highlighted is the first paragraph of the main text
of the article, which is contained in a
\java{<div>} element with
\java{id="mw-content-text"}. We'll use this element id to identify the
main text of each article we download.

\index{element}



\section{Using jsoup}
\label{using-jsoup}

jsoup makes it easy to download and parse web pages, and to navigate the
DOM tree. Here's an example:

\begin{verbatim}
    String url = "http://en.wikipedia.org/wiki/Java_(programming_language)";

    // download and parse the document
    Connection conn = Jsoup.connect(url);
    Document doc = conn.get();

    // select the content text and pull out the paragraphs.
    Element content = doc.getElementById("mw-content-text");
    Elements paragraphs = content.select("p");
\end{verbatim}

\java{Jsoup.connect} takes a URL as a \java{String} and makes a connection to
the web server; the \java{get} method downloads the HTML, parses it,
and returns a \java{Document} object, which represents the DOM.

\index{jsoup}
\index{Document}

\java{Document} provides methods for navigating the
tree and selecting nodes. In fact, it provides so many methods, it can
be confusing. This example demonstrates two ways to select nodes:

\begin{itemize}

\item
  \java{getElementById} takes a \java{String} and searches the tree for an
  element that has a matching ``id'' field. Here it selects the node
  \java{<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr">},
  which appears on every Wikipedia page to identify the
  \java{<div>} element that contains the main
  text of the page, as opposed to the navigation sidebar and other
  elements.

  The return value from \java{getElementById} is an \java{Element}
  object that represents this \java{<div>} and
  contains the elements in the \java{<div>} as
  children, grandchildren, etc.

\item
  \java{select} takes a \java{String}, traverses the tree, and returns all
  the elements with tags that match the \java{String}. In this example, it
  returns all paragraph tags that appear in \java{content}. The return
  value is an \java{Elements} object.

\end{itemize}

\index{select}
\index{Node}
\index{Element}

Before you go on, you should skim the documentation of these classes so
you know what they can do. The most important classes are
\java{Element}, \java{Elements}, and \java{Node}, which you can read 
about at 
\url{http://thinkdast.com/jsoupelt},
\url{http://thinkdast.com/jsoupelts}, and
\url{http://thinkdast.com/jsoupnode}.

\java{Node} represents a node in the DOM tree;  there are several
subclasses that extend \java{Node}, including 
\java{Element}, \java{TextNode}, \java{DataNode}, and \java{Comment}.
\java{Elements} is a \java{Collection} of \java{Element} objects.

\index{subclass}

\begin{figure}
\centering
\includegraphics[width=5in]{figs/yuml2.pdf}
\caption{UML diagram for selected classes provided by jsoup.}
\label{fig-uml2}
% Edit: http://yuml.me/edit/4bc1c919
\end{figure}

Figure~\ref{fig-uml2} is a UML diagram showing the relationships among
these classes.  In a UML class diagram, a line with a hollow arrow
head indicates that one class extends another.  For example, this
diagram indicates that \java{Elements} extends \java{ArrayList}.
We'll get back to UML diagrams in Section~\ref{uml-class-diagrams}.

\index{UML diagram}


\section{Iterating through the DOM}
\label{iterating-through-the-dom}

To make your life easier, I provide a class called
\java{WikiNodeIterable} that lets you iterate through the nodes in a
DOM tree. Here's an example that shows how to use it:

\index{WikiNodeIterable}

\begin{verbatim}
    Elements paragraphs = content.select("p");
    Element firstPara = paragraphs.get(0);

    Iterable<Node> iter = new WikiNodeIterable(firstPara);
    for (Node node: iter) {
        if (node instanceof TextNode) {
            System.out.print(node);
        }
    }
\end{verbatim}

This example picks up where the previous one leaves off. It selects the
first paragraph in \java{paragraphs} and then creates a
\java{WikiNodeIterable}, which implements
\java{Iterable<Node>}. 
\java{WikiNodeIterable} performs a ``depth-first search'', which
produces the nodes in the order they would appear on the page.

\index{depth-first search}
\index{TextNode}

In this example, we print a \java{Node} only if it is a
\java{TextNode} and ignore other types of \java{Node}, specifically
the \java{Element} objects that represent tags. The result is the
plain text of the HTML paragraph without any markup. The output is:

\begin{quote}
Java is a general-purpose computer programming language that is
concurrent, class-based, object-oriented,{[}13{]} and specifically
designed \ldots
\end{quote}


\section{Depth-first search}
\label{depth-first-search}

There are several ways you might reasonably traverse a tree, each with
different applications. We'll start with ``depth-first search'', or DFS.
DFS starts at the root of the tree and selects the first child. If the
child has children, it selects the first child again. When it gets to a
node with no children, it backtracks, moving up the tree to the parent
node, where it selects the next child if there is one; otherwise it
backtracks again. When it has explored the last child of the root, it's
done.

\index{DFS}
\index{recursion}

There are two common ways to implement DFS, recursively and iteratively.
The recursive implementation is simple and elegant:

\begin{verbatim}
private static void recursiveDFS(Node node) {
    if (node instanceof TextNode) {
        System.out.print(node);
    }
    for (Node child: node.childNodes()) {
        recursiveDFS(child);
    }
}
\end{verbatim}

This method gets invoked on every \java{Node} in the tree, starting
with the root. If the \java{Node} it gets is a \java{TextNode}, it
prints the contents. If the \java{Node} has any children, it invokes
\java{recursiveDFS} on each one of them in order.

\index{tree traversal}
\index{pre-order}
\index{post-order}
\index{in-order}

In this example, we print the contents of each \java{TextNode} before
traversing the children, so this is an example of a ``pre-order''
traversal. You can read about ``pre-order'', ``post-order'', and
``in-order'' traversals at \url{http://thinkdast.com/treetrav}.  For
this application, the traversal order doesn't matter.

\index{call stack}

By making recursive calls, \java{recursiveDFS} uses the call stack
(\url{http://thinkdast.com/callstack}) to keep
track of the child nodes and process them in the right order. As an
alternative, we can use a stack data structure to keep track of the
nodes ourselves; if we do that, we can avoid the recursion and traverse
the tree iteratively.


\section{Stacks in Java}
\label{stacks-in-java}

Before I explain the iterative version of DFS, I'll explain
the stack data structure.  We'll start with the general concept of a
stack, which I'll call a ``stack'' with a lowercase ``s''. Then we'll
talk about two Java \java{interfaces} that define stack methods:
\java{Stack} and \java{Deque}.

\index{Stack}
\index{Deque}

% TODO: introduce the term ``Abstract Data Type''?

A stack is a data structure that is similar to a list: it is a
collection that maintains the order of the elements. The primary
difference between a stack and a list is that the stack provides fewer
methods. In the usual convention, it provides:

\begin{itemize}

\item
  \java{push}: which adds an element to the top of the stack.

\item
  \java{pop}: which removes and returns the top-most element from the stack.

\item
  \java{peek}: which returns the top-most element without modifying
  the stack.

\item
  \java{isEmpty}: which indicates whether the stack is empty.

\end{itemize}

Because \java{pop} always returns the top-most element, a stack is
also called a ``LIFO'', which stands for ``last in, first out''. An
alternative to a stack is a ``queue'', which returns elements in the
same order they are added; that is, ``first in, first out'', or FIFO.

\index{push}
\index{pop}
\index{peek}
\index{isEmpty}
\index{FIFO}
\index{LIFO}
\index{stack}
\index{queue}

It might not be obvious why stacks and queues are useful: they don't
provide any capabilities that aren't provided by lists; in fact, they
provide fewer capabilities. So why not use lists for everything? There
are two reasons:

\begin{enumerate}

\item
  If you limit yourself to a small set of methods --- that is, a small
  API --- your code will be more readable and less error-prone. For
  example, if you use a list to represent a stack, you might
  accidentally remove an element in the wrong order. With the stack API,
  this kind of mistake is literally impossible. And the best way to
  avoid errors is to make them impossible.

\item
  If a data structure provides a small API, it is easier to implement
  efficiently. For example, a simple way to implement a stack is a
  singly-linked list. When we push an element onto the stack, we add it
  to the beginning of the list; when we pop an element, we remove it
  from the beginning. For a linked list, adding and removing from the
  beginning are constant time operations, so this implementation is
  efficient. Conversely, big APIs are harder to implement efficiently.

\end{enumerate}

\index{constant time}

To implement a stack in Java, you have three options:

\begin{enumerate}

\item
  Go ahead and use \java{ArrayList} or \java{LinkedList}. If you use
  \java{ArrayList}, be sure to add and remove from the \emph{end},
  which is a constant time operation. And be careful not to add elements
  in the wrong place or remove them in the wrong order.

\item
  Java provides a class called \java{Stack} that provides the standard
  set of stack methods. But this class is an old part of Java: it is not
  consistent with the Java Collections Framework, which came later.

\item
  Probably the best choice is to use one of the implementations of the
  \java{Deque} interface, like \java{ArrayDeque}.

\end{enumerate}

``Deque'' stands for ``double-ended queue''; it's supposed to be
pronounced ``deck'', but some people say ``deek''. In Java, the
\java{Deque} interface provides \java{push}, \java{pop},
\java{peek}, and \java{isEmpty}, so you can use a \java{Deque} as
a stack. It provides other methods, which you can read about at
\url{http://thinkdast.com/deque},
but we won't use them for now.

\index{deque}


\section{Iterative DFS}
\label{iterative-dfs}

Here is an iterative version of DFS that uses an \java{ArrayDeque} to
represent a stack of \java{Node} objects:

\begin{verbatim}
    private static void iterativeDFS(Node root) {
        Deque<Node> stack = new ArrayDeque<Node>();
        stack.push(root);

        while (!stack.isEmpty()) {
            Node node = stack.pop();
            if (node instanceof TextNode) {
                System.out.print(node);
            }

            List<Node> nodes = new ArrayList<Node>(node.childNodes());
            Collections.reverse(nodes);

            for (Node child: nodes) {
                stack.push(child);
            }
        }
    }
\end{verbatim}

The parameter, \java{root}, is the root of the tree we want to
traverse, so we start by creating the stack and pushing the root onto
it.

\index{ArrayDeque}
\index{iterative DFS}

The loop continues until the stack is empty. Each time through, it pops
a \java{Node} off the stack. If it gets a \java{TextNode}, it prints
the contents. Then it pushes the children onto the stack. In order to
process the children in the right order, we have to push them onto the
stack in reverse order; we do that by copying the children into an
\java{ArrayList}, reversing the elements in place, and then iterating
through the reversed \java{ArrayList}.

One advantage of the iterative version of DFS is that it is easier to
implement as a Java \java{Iterator}; you'll see how in the next
chapter.

\index{LinkedList}

But first, one last note about the \java{Deque} interface: in
addition to \java{ArrayDeque}, Java provides another implementation of
\java{Deque}, our old friend \java{LinkedList}. \java{LinkedList}
implements both interfaces, \java{List} and \java{Deque}. Which
interface you get depends on how you use it. For example, if you assign
a \java{LinkedList} object to a \java{Deque} variable, like this:

\begin{verbatim}
Deqeue<Node> deque = new LinkedList<Node>();
\end{verbatim}

you can use the methods in the \java{Deque} interface, but not all
methods in the \java{List} interface. If you assign it to a
\java{List} variable, like this:

\begin{verbatim}
List<Node> deque = new LinkedList<Node>();
\end{verbatim}

you can use \java{List} methods but not all \java{Deque} methods.
And if you assign it like this:

\begin{verbatim}
LinkedList<Node> deque = new LinkedList<Node>();
\end{verbatim}

you can use \emph{all} the methods. But if you combine methods from
different interfaces, your code will be less readable and more
error-prone.



\chapter{Getting to Philosophy}
\label{getphilo}

The goal of this chapter is to develop a Web crawler that tests the
``Getting to Philosophy'' conjecture, which we presented in
Section~\ref{the-road-ahead}.

\index{Getting to Philosophy}


\section{Getting started}
\label{getting-started}

In the repository for this book,
you'll find some code to help you get started:

\begin{enumerate}

\item
  \java{WikiNodeExample.java} contains the code from the previous
  chapter, demonstrating recursive and iterative implementations of
  depth-first search (DFS) in a DOM tree.

\item
  \java{WikiNodeIterable.java} contains an \java{Iterable} class for
  traversing a DOM tree. I'll explain this code in the next section.

\item
  \java{WikiFetcher.java} contains a utility class that uses jsoup to
  download pages from Wikipedia. To help you comply with Wikipedia's
  terms of service, this class limits how fast you can download pages;
  if you request more than one page per second, it sleeps before
  downloading the next page.

\item
  \java{WikiPhilosophy.java} contains an outline of the code you will
  write for this exercise. We'll walk through it below.

\end{enumerate}

You'll also find the Ant build file
\java{build.xml}.  If you run \java{ant WikiPhilosophy}, it will run
a simple bit of starter code.

\index{WikiPhilosophy}
\index{Ant}


\section{Iterables and Iterators}
\label{iterables-and-iterators}

In the previous chapter, I presented an iterative depth-first search
(DFS), and suggested that an advantage of the iterative version,
compared to the recursive version, is that it is easier to wrap in an
\java{Iterator} object. In this section we'll see how to do that.

\index{Iterable}
\index{Iterator}

If you are not familiar with the \java{Iterator} and \java{Iterable}
interfaces, you can read about them at
\url{http://thinkdast.com/iterator}
and
\url{http://thinkdast.com/iterable}.

Take a look at the contents of \java{WikiNodeIterable.java}. The outer
class, \java{WikiNodeIterable} implements the
\java{Iterable<Node>} interface  so we can use
it in a for loop like this:

\begin{verbatim}
    Node root = ...
    Iterable<Node> iter = new WikiNodeIterable(root);
    for (Node node: iter) {
        visit(node);
    }
\end{verbatim}

where \java{root} is the root of the tree we want to traverse and
\java{visit} is a method that does whatever we want when we ``visit''
a \java{Node}.

\index{WikiNodeIterable}

The implementation of \java{WikiNodeIterable} follows a conventional
formula:

\begin{enumerate}

\item
  The constructor takes and stores a reference to the root
  \java{Node}.

\item
  The \java{iterator} method creates a returns an \java{Iterator}
  object.

\end{enumerate}

Here's what it looks like:

\begin{verbatim}
public class WikiNodeIterable implements Iterable<Node> {

    private Node root;

    public WikiNodeIterable(Node root) {
        this.root = root;
    }

    @Override
    public Iterator<Node> iterator() {
        return new WikiNodeIterator(root);
    }
}
\end{verbatim}

The inner class, \java{WikiNodeIterator}, does all the real work:

\begin{verbatim}
    private class WikiNodeIterator implements Iterator<Node> {

        Deque<Node> stack;

        public WikiNodeIterator(Node node) {
            stack = new ArrayDeque<Node>();
            stack.push(root);
        }

        @Override
        public boolean hasNext() {
            return !stack.isEmpty();
        }

        @Override
        public Node next() {
            if (stack.isEmpty()) {
                throw new NoSuchElementException();
            }

            Node node = stack.pop();
            List<Node> nodes = new ArrayList<Node>(node.childNodes());
            Collections.reverse(nodes);
            for (Node child: nodes) {
                stack.push(child);
            }
            return node;
        }
    }
\end{verbatim}

\index{WikiNodeIterator}
\index{DFS}
\index{depth-first search}

This code is almost identical to the iterative version of DFS, but now
it's split into three methods:

\begin{enumerate}

\item
  The constructor initializes the stack (which is implemented using an
  \java{ArrayDeque}) and pushes the root node onto it.

\item
  \java{isEmpty} checks whether the stack is empty.

\item
  \java{next} pops the next \java{Node} off the stack, pushes its
  children in reverse order, and returns the \java{Node} it popped. If
  someone invokes \java{next} on an empty \java{Iterator}, it throws
  an exception.

\end{enumerate}

It might not be obvious that it is worthwhile to rewrite a perfectly
good method with two classes and five methods.  But now that we've
done it, we can use \java{WikiNodeIterable} anywhere an
\java{Iterable} is called for, which makes it easy and syntactically
clean to separate the logic of the iteration (DFS) from whatever
processing we are doing on the nodes.

\index{isEmpty}
\index{next}


\section{\java{WikiFetcher}}
\label{wikifetcher}

\index{WikiFetcher}

When you write a Web crawler, it is easy to download too many pages too
fast, which might violate the terms of service for the server you are
downloading from. To help you avoid that, I provide a class called
\java{WikiFetcher} that does two things:

\begin{enumerate}

\item
  It encapsulates the code we demonstrated in the previous chapter for
  downloading pages from Wikipedia, parsing the HTML, and selecting the
  content text.

\item
  It measures the time between requests and, if we don't leave enough
  time between requests, it sleeps until a reasonable interval has
  elapsed. By default, the interval is one second.

\end{enumerate}

Here's the definition of \java{WikiFetcher}:

\begin{verbatim}
public class WikiFetcher {
    private long lastRequestTime = -1;
    private long minInterval = 1000;

    /**
     * Fetches and parses a URL string, 
     * returning a list of paragraph elements.
     *
     * @param url
     * @return
     * @throws IOException
     */
    public Elements fetchWikipedia(String url) throws IOException {
        sleepIfNeeded();

        Connection conn = Jsoup.connect(url);
        Document doc = conn.get();
        Element content = doc.getElementById("mw-content-text");
        Elements paragraphs = content.select("p");
        return paragraphs;
    }

    private void sleepIfNeeded() {
        if (lastRequestTime != -1) {
            long currentTime = System.currentTimeMillis();
            long nextRequestTime = lastRequestTime + minInterval;
            if (currentTime < nextRequestTime) {
                try {
                    Thread.sleep(nextRequestTime - currentTime);
                } catch (InterruptedException e) {
                    System.err.println(
                        "Warning: sleep interrupted in fetchWikipedia.");
                }
            }
        }
        lastRequestTime = System.currentTimeMillis();
    }
}
\end{verbatim}

The only public method is \java{fetchWikipedia}, which takes a URL as
a \java{String} and returns an \java{Elements} collection that contains one
DOM element for each paragraph in the content text. This code should
look familiar.

\index{Elements}

The new code is in \java{sleepIfNeeded}, which checks the time since
the last request and sleeps if the elapsed time is less than
\java{minInterval}, which is in milliseconds.

That's all there is to \java{WikiFetcher}. Here's an example that
demonstrates how it's used:

\begin{verbatim}
    WikiFetcher wf = new WikiFetcher();

    for (String url: urlList) {
        Elements paragraphs = wf.fetchWikipedia(url);
        processParagraphs(paragraphs);
    }
\end{verbatim}

In this example, we assume that \java{urlList} is a collection of
\java{String}s, and \java{processParagraphs} is a method that does something
with the \java{Elements} object returned by \java{fetchWikipedia}.

This example demonstrates something important: you should create one
\java{WikiFetcher} object and use it to handle all requests. If you
have multiple instances of \java{WikiFetcher}, they won't enforce the
minimum interval between requests.

\index{singleton}

NOTE: My implementation of \java{WikiFetcher} is simple, but it would
be easy for someone to misuse it by creating multiple instances. You
could avoid this problem by making \java{WikiFetcher} a ``singleton'',
which you can read about at
\url{http://thinkdast.com/singleton}.


\section{Exercise 5}
\label{exercise5}

In \java{WikiPhilosophy.java} you'll find a simple \java{main}
method that shows how to use some of these pieces. Starting with this
code, your job is to write a crawler that:

\begin{enumerate}

\item
  Takes a URL for a Wikipedia page, downloads it, and parses it.

\item
  It should traverse the resulting DOM tree to find the first
  \emph{valid} link. I'll explain what ``valid'' means below.

\item
  If the page has no links, or if the first link is a page we have
  already seen, the program should indicate failure and exit.

\item
  If the link matches the URL of the Wikipedia page on philosophy, the
  program should indicate success and exit.

\item
  Otherwise it should go back to Step 1.

\end{enumerate}

The program should build a \java{List} of the URLs it visits and
display the results at the end (whether it succeeds or fails).

\index{Getting to Philosophy}

So what should we consider a ``valid'' link? You have some choices here.
Various versions of the ``Getting to Philosophy'' conjecture use
slightly different rules, but here are some options:

\begin{enumerate}

\item
  The link should be in the content text of the page, not in a sidebar
  or boxout.

\item
  It should not be in italics or in parentheses.

\item
  You should skip external links, links to the current page, and red
  links.

\item
  In some versions, you should skip a link if the text starts with an
  uppercase letter.

\end{enumerate}

You don't have to enforce all of these rules, but we recommend that you
at least handle parentheses, italics, and links to the current page.

If you feel like you have enough information to get started, go ahead.
Or you might want to read these hints:

\begin{enumerate}

\item
  As you traverse the tree, the two kinds of \java{Node} you will need
  to deal with are \java{TextNode} and \java{Element}. If you find
  an \java{Element}, you will probably have to typecast it to access
  the tag and other information.

\item
  When you find an \java{Element} that contains a link, you can check
  whether it is in italics by following parent links up the tree. If
  there is an \java{<i>} or \java{<em>} tag in the parent chain, the
  link is in italics.

\item
  To check whether a link is in parentheses, you will have to scan
  through the text as you traverse the tree and keep track of opening
  and closing parentheses (ideally your solution should be able to
  handle nested parentheses (like this)).

\item
  If you start from the Java page, you should get to Philosophy
  after following
  seven links, unless something has changed since I ran the code.

\end{enumerate}

OK, that's all the help you're going to get. Now it's up to you.
Have fun!



\chapter{Indexer}

At this point we have built a basic Web crawler; the next piece we will
work on is the \textbf{index}. In the context of web search, an index is
a data structure that makes it possible to look up a search term and
find the pages where that term appears. In addition, we would like to
know how many times the search term appears on each page, which will
help identify the pages most relevant to the term.

\index{index}
\index{search term}

For example, if a user submits the search terms ``Java'' and
``programming'', we would look up both search terms and get two sets of
pages. Pages with the word ``Java'' would include pages about the island
of Java, the nickname for coffee, and the programming language. Pages
with the word ``programming'' would include pages about different
programming languages, as well as other uses of the word. By selecting
pages with both terms, we hope to eliminate irrelevant pages and find
the ones about Java programming.

Now that we understand what the index is and what operations it
performs, we can design a data structure to represent it.


\section{Data structure selection}
\label{data-structure-selection}

The fundamental operation of the index is a \textbf{lookup};
specifically, we need the ability to look up a term and find all pages
that contain it. The simplest implementation would be a collection of
pages. Given a search term, we could iterate through the contents of the
pages and select the ones that contain the search term. But the runtime
would be proportional to the total number of words on all the pages,
which would be way too slow.

\index{lookup}
\index{map}
\index{key-value pair}
\index{key}
\index{value}
\index{frequency}

A better alternative is a \textbf{map}, which is a data structure that
represents a collection of \textbf{key-value pairs} and provides a fast
way to look up a \textbf{key} and find the corresponding \textbf{value}.
For example, the first map we'll construct is a \java{TermCounter},
which maps from each search term to the number of times it appears in a
page. The keys are the search terms and the values are the counts (also
called ``frequencies'').

Java provides an interface called \java{Map} that specifies the
methods a map should provide; the most important are:

\begin{itemize}

\item
  \java{get(key)}: This method looks up a key and returns the
  corresponding value.

\item
  \java{put(key, value)}: This method adds a new key-value pair to the
  \java{Map}, or if the key is already in the map, it replaces the
  value associated with \java{key}.

\end{itemize}

Java provides several implementations of \java{Map}, including the two
we will focus on, \java{HashMap} and \java{TreeMap}. In upcoming
chapters, we'll look at these implementations and analyze their performance.

In addition to the \java{TermCounter}, which maps from search terms to
counts, we will define a class called \java{Index}, which maps from a
search term to a collection of pages where it appears. And that raises
the next question, which is how to represent a collection of pages.
Again, if we think about the operations we want to perform, that guides
our decision.

\index{Set}
\index{set intersection}

In this case, we'll need to combine two or more collections and find the
pages that appear in all of them. You might recognize this operation as
\textbf{set intersection}: the intersection of two sets is the set of
elements that appear in both.

As you might expect by now, Java provides a \java{Set} interface that
defines the operations a set should perform. It doesn't actually provide
set intersection, but it provides methods that make it possible to
implement intersection and other set operations efficiently. The core
\java{Set} methods are:

\begin{itemize}

\item
  \java{add(element)}: This method adds an element to a set; if the
  element is already in the set, it has no effect.

\item
  \java{contains(element)}: This method checks whether the given
  element is in the set.

\end{itemize}

Java provides several implementations of \java{Set}, including
\java{HashSet} and \java{TreeSet}.

\index{add}
\index{contains}

Now that we've designed our data structures from the top down, we'll
implement them from the inside out, starting with \java{TermCounter}.


\section{TermCounter}
\label{termcounter}

\index{TermCounter}

\java{TermCounter} is a class that represents a mapping from search
terms to the number of times they appear in a page. Here is the first
part of the class definition:

\begin{verbatim}
public class TermCounter {

    private Map<String, Integer> map;
    private String label;

    public TermCounter(String label) {
        this.label = label;
        this.map = new HashMap<String, Integer>();
    }
}
\end{verbatim}

The instance variables are \java{map}, which contains the mapping from
terms to counts, and \java{label}, which identifies the document the
terms came from; we'll use it to store URLs.

\index{URL}
\index{Map}
\index{HashMap}

To implement the mapping, I chose \java{HashMap}, which is the most
commonly-used \java{Map}. Coming up in a few chapters, you will see how
it works and why it is a common choice.

\java{TermCounter} provides \java{put} and \java{get}, which are
defined like this:

\begin{verbatim}
    public void put(String term, int count) {
        map.put(term, count);
    }

    public Integer get(String term) {
        Integer count = map.get(term);
        return count == null ? 0 : count;
    }
\end{verbatim}

\java{put} is just a \textbf{wrapper method}; when you call
\java{put} on a \java{TermCounter}, it calls \java{put} on the
embedded map.

\index{put}
\index{get}
\index{wrapper method}

On the other hand, \java{get} actually does some work. When you call
\java{get} on a \java{TermCounter}, it calls \java{get} on the
map, and then checks the result. If the term does not appear in the
map, \java{TermCount.get} returns 0. Defining \java{get} this way
makes it easier to write \java{incrementTermCount}, which takes a term
and increases by one the counter associated with that term.

\begin{verbatim}
    public void incrementTermCount(String term) {
        put(term, get(term) + 1);
    }
\end{verbatim}

If the term has not been seen before, \java{get} returns 0; we add 1,
then use \java{put} to add a new key-value pair to the map. If the
term is already in the map, we get the old count, add 1, and then store
the new count, which replaces the old value.

In addition, \java{TermCounter} provides these other methods to help
with indexing Web pages:

\begin{verbatim}
    public void processElements(Elements paragraphs) {
        for (Node node: paragraphs) {
            processTree(node);
        }
    }

    public void processTree(Node root) {
        for (Node node: new WikiNodeIterable(root)) {
            if (node instanceof TextNode) {
                processText(((TextNode) node).text());
            }
        }
    }

    public void processText(String text) {
        String[] array = text.replaceAll("\\pP", " ").
                              toLowerCase().
                              split("\\s+");

        for (int i=0; i<array.length; i++) {
            String term = array[i];
            incrementTermCount(term);
        }
    }
\end{verbatim}

\begin{itemize}

\item
  \java{processElements} takes an \java{Elements} object, which is a
  collection of jsoup \java{Element} objects. It iterates through the
  collection and calls \java{processTree} on each.

\item
  \java{processTree} takes a jsoup \java{Node} that represents the
  root of a DOM tree. It iterates through the tree to find the nodes
  that contain text; then it extracts the text and passes it to
  \java{processText}.

\item
  \java{processText} takes a \java{String} that contains words, spaces,
  punctuation, etc. It removes punctuation characters by replacing
  them with spaces, converts the remaining letters to lowercase, then
  splits the text into words. Then it loops through the words it found
  and calls \java{incrementTermCount} on each.  The \java{replaceAll}
  and \java{split} methods take {\bf regular expressions} as parameters;
  you can read more about them at \url{http://thinkdast.com/regex}.

\end{itemize}

\index{Element}
\index{DOM tree}
\index{regular expression}

Finally, here's an example that demonstrates how \java{TermCounter} is
used:

\begin{verbatim}
    String url = "http://en.wikipedia.org/wiki/Java_(programming_language)";
    WikiFetcher wf = new WikiFetcher();
    Elements paragraphs = wf.fetchWikipedia(url);

    TermCounter counter = new TermCounter(url);
    counter.processElements(paragraphs);
    counter.printCounts();
\end{verbatim}

This example uses a \java{WikiFetcher} to download a page from
Wikipedia and parse the main text. Then it creates a
\java{TermCounter} and uses it to count the words in the page.

\index{WikiFetcher}

In the next section, you'll have a chance to run this code and test your
understanding by filling in a missing method.


\section{Exercise 6}
\label{exercise6}

In the repository for this book,
you'll find the source files for this exercise:

\begin{itemize}

\item \java{TermCounter.java} contains the code from the previous
  section.

\item \java{TermCounterTest.java} contains test code for
  \java{TermCounter.java}.

\item \java{Index.java} contains the class definition for the next
  part of this exercise.

\item \java{WikiFetcher.java} contains the class we used in the
  previous exercise to download and parse Web pages.

\item \java{WikiNodeIterable.java} contains the class we used to
  traverse the nodes in a DOM tree.

\end{itemize}

You'll also find the Ant build file
\java{build.xml}.

\index{Ant}

Run \java{ant build} to compile the source
  files. Then run \java{ant TermCounter}; it should run the code from
  the previous section and print a list of terms and their counts. The
  output should look something like this:

\begin{verbatim}
genericservlet, 2
configurations, 1
claimed, 1
servletresponse, 2
occur, 2
Total of all counts = -1
\end{verbatim}

When you run it, the order of the terms might be different.

\index{size}

The last line is supposed to print the total of the term counts, but
it returns \java{-1} because the method \java{size} is incomplete.
Fill in this method and run \java{ant TermCounter} again. The result
should be \java{4798}.

Run \java{ant TermCounterTest} to confirm that this part of the
exercise is complete and correct.

\index{Index}

For the second part of the exercise, I'll present an implementation of an
\java{Index} object and you will fill in a missing method. Here's the
beginning of the class definition:

\begin{verbatim}
public class Index {

    private Map<String, Set<TermCounter>> index = 
        new HashMap<String, Set<TermCounter>>();

    public void add(String term, TermCounter tc) {
        Set<TermCounter> set = get(term);

        // if we're seeing a term for the first time, make a new Set
        if (set == null) {
            set = new HashSet<TermCounter>();
            index.put(term, set);
        }
        // otherwise we can modify an existing Set
        set.add(tc);
    }

    public Set<TermCounter> get(String term) {
        return index.get(term);
    }
\end{verbatim}

The instance variable, \java{index}, is a map from each search term to
a set of \java{TermCounter} objects. Each \java{TermCounter}
represents a page where the search term appears.

The \java{add} method adds a new \java{TermCounter} to the set
associated with a term. When we index a term that has not appeared
before, we have to create a new set. Otherwise we can just add a new
element to an existing set. In that case, \java{set.add} modifies a
set that lives inside \java{index}, but doesn't modify \java{index}
itself. The only time we modify \java{index} is when we add a new
term.

\index{add}
\index{get}

Finally, the \java{get} method takes a search term and returns the
corresponding set of \java{TermCounter} objects.

This data structure is moderately complicated. To review, an
\java{Index} contains a \java{Map} from each search term to a
\java{Set} of \java{TermCounter} objects, and each \java{TermCounter}
is a map from search terms to counts.

\begin{figure}
\centering
\includegraphics[width=4in]{figs/index.pdf}
\caption{Object diagram of an \java{Index}.}
\label{indexfig}
\end{figure}

Figure~\ref{indexfig} is an object diagram that shows these
objects.  The \java{Index} object has an instance variable named
\java{index} that refers to a \java{Map}.  In this example the
\java{Map} contains only one string, \java{"Java"}, which maps
to a \java{Set} that contains two \java{TermCounter} objects,
one for each page where the word ``Java'' appears.

\index{object diagram}
\index{URL}

Each \java{TermCounter} contains \java{label}, which is the URL
of the page, and \java{map}, which is a \java{Map} that
contains the words on the page
and the number of times each word appears.

The method \java{printIndex} shows how to
unpack this data structure:

\begin{verbatim}
    public void printIndex() {
        // loop through the search terms
        for (String term: keySet()) {
            System.out.println(term);

            // for each term, print pages where it appears and frequencies
            Set<TermCounter> tcs = get(term);
            for (TermCounter tc: tcs) {
                Integer count = tc.get(term);
                System.out.println("    " + tc.getLabel() + " " + count);
            }
        }
    }
\end{verbatim}

The outer loop iterates the search terms. The inner loop iterates the
\java{TermCounter} objects.

\index{Ant}

Run \java{ant build} to make sure your source code is compiled, and
then run \java{ant Index}. It downloads two Wikipedia pages, indexes
them, and prints the results; but when you run it you won't see any
output because we've left one of the methods empty.

\index{indexPage}

Your job is to fill in \java{indexPage}, which takes a URL (as a
\java{String}) and an \java{Elements} object, and updates the index. The
comments below sketch what it should do:

\begin{verbatim}
public void indexPage(String url, Elements paragraphs) {
    // make a TermCounter and count the terms in the paragraphs

    // for each term in the TermCounter, add the TermCounter to the index
}
\end{verbatim}

When it's working, run \java{ant Index} again, and you should see
  output like this:

\begin{verbatim}
...
configurations
    http://en.wikipedia.org/wiki/Programming_language 1
    http://en.wikipedia.org/wiki/Java_(programming_language) 1
claimed
    http://en.wikipedia.org/wiki/Java_(programming_language) 1
servletresponse
    http://en.wikipedia.org/wiki/Java_(programming_language) 2
occur
    http://en.wikipedia.org/wiki/Java_(programming_language) 2
\end{verbatim}

The order of the search terms might be different when you run it.

Also, run \java{ant TestIndex} to confirm that this part of the exercise is
complete.


\chapter{The Map interface}

In the next few exercises, I present several implementations of the
\java{Map} interface. One of them is based on a \textbf{hash table},
which is arguably the most magical data structure ever
invented. Another, which is similar to \java{TreeMap}, is not quite as
magical, but it has the added capability that it can iterate the
elements in order.

\index{map}
\index{hash table}

You will have a chance to implement these data structures, and then we
will analyze their performance.

But before we can explain hash tables, we'll start with a simple
implementation of a \java{Map} using a \java{List} of key-value
pairs.

\section{Implementing \java{MyLinearMap}}
\label{implementing-mylinearmap}

\index{MyLinearMap}

As usual, I provide starter code and you will fill in the missing
methods. Here's the beginning of the \java{MyLinearMap} class
definition:

\begin{verbatim}
public class MyLinearMap<K, V> implements Map<K, V> {

    private List<Entry> entries = new ArrayList<Entry>();
\end{verbatim}

This class uses two type parameters, \java{K}, which is the type of
the keys, and \java{V}, which is the type of the values.
\java{MyLinearMap} implements \java{Map}, which means it has to
provide the methods in the \java{Map} interface.

\index{type parameter}
\index{ArrayList}

A \java{MyLinearMap} object has a single instance variable,
\java{entries}, which is an \java{ArrayList} of \java{Entry}
objects. Each \java{Entry} contains a key-value pair. Here is the
definition:

\begin{verbatim}
    public class Entry implements Map.Entry<K, V> {
        private K key;
        private V value;
        
        public Entry(K key, V value) {
            this.key = key;
            this.value = value;
        }
        
        @Override
        public K getKey() {
            return key;
        }
        @Override
        public V getValue() {
            return value;
        }
    }
\end{verbatim}

There's not much to it; an \java{Entry} is just a container for a key
and a value. This definition is nested inside \java{MyLinearList}, so
it uses the same type parameters, \java{K} and \java{V}.

\index{Entry}

That's all you need to do the exercise, so let's get started.


\section{Exercise 7}
\label{exercise7}

In the repository for this book,
you'll find the source files for this exercise:

\begin{itemize}

\item \java{MyLinearMap.java} contains starter code for the first part
  of the exercise.

\item \java{MyLinearMapTest.java} contains the unit tests for
  \java{MyLinearMap}.

\end{itemize}

You'll also find the Ant build file
\java{build.xml}.

\index{Ant}

Run \java{ant build} to compile the source files. Then run \java{ant
  MyLinearMapTest}; several tests should fail, because you have some
work to do!

\index{helper method}

First, fill in the body of \java{findEntry}. This is a helper method
that is not part of the \java{Map} interface, but once you get it
working, you can use it for several methods. Given a target key, it
should search through the entries and return the entry that contains
the target (as a key, not a value) or \java{null} if it's not
there. Notice that I provide an \java{equals} method that
compares two keys and handles \java{null} correctly.

\index{findEntry}

You can run \java{ant MyLinearMapTest} again, but even if your
\java{findEntry} is correct, the tests won't pass because \java{put}
is not complete.

\index{put}

Fill in \java{put}. You should read the documentation of
\java{Map.put} at \url{http://thinkdast.com/listput} so you know what
it is supposed to do. You might want to start with a version of
\java{put} that always adds a new entry and does not modify an
existing entry; that way you can test the simple case first.  Or if
you feel more confident, you can write the whole thing at once.

\index{containsKey}
\index{get}
\index{remove}

Once you've got \java{put} working, the test for \java{containsKey}
should pass.

Read the documentation of \java{Map.get} at
  \url{http://thinkdast.com/listget}
  and then fill in the method. Run the tests again.

Finally, read the documentation of \java{Map.remove} at
  \url{http://thinkdast.com/maprem}
  and fill in the method.

At this point, all tests should pass. Congratulations!


\section{Analyzing \java{MyLinearMap}}
\label{analyzing-mylinearmap}

\index{equals}

In this section I present a solution to the previous exercise and
analyze the performance of the core methods.  Here are
\java{findEntry} and \java{equals}:

\begin{verbatim}
private Entry findEntry(Object target) {
    for (Entry entry: entries) {
        if (equals(target, entry.getKey())) {
            return entry;
        }
    }
    return null;
}

private boolean equals(Object target, Object obj) {
    if (target == null) {
        return obj == null;
    }
    return target.equals(obj);
}
\end{verbatim}

The runtime of \java{equals} might depend on the size of the
\java{target} and the keys, but does not generally depend on
the number of entries, $n$. So \java{equals} is constant time.

\index{constant time}
\index{analysis of algorithms}

In \java{findEntry}, we might get lucky and find the key we're looking
for at the beginning, but we can't count on it. In general, the number
of entries we have to search is proportional to $n$, so
\java{findEntry} is linear.

\index{findEntry}
\index{linear time}

Most of the core methods in \java{MyLinearMap} use \java{findEntry},
including \java{put}, \java{get}, and \java{remove}. Here's what
they look like:

\begin{verbatim}
public V put(K key, V value) {
    Entry entry = findEntry(key);
    if (entry == null) {
        entries.add(new Entry(key, value));
        return null;
    } else {
        V oldValue = entry.getValue();
        entry.setValue(value);
        return oldValue;
    }
}
\end{verbatim}

\begin{verbatim}
public V get(Object key) {
    Entry entry = findEntry(key);
    if (entry == null) {
        return null;
    }
    return entry.getValue();
}
\end{verbatim}
    
\begin{verbatim}
public V remove(Object key) {
    Entry entry = findEntry(key);
    if (entry == null) {
        return null;
    } else {
        V value = entry.getValue();
        entries.remove(entry);
        return value;
    }
}
\end{verbatim}

After \java{put} calls \java{findEntry}, everything else is constant
time. Remember that \java{entries} is an \java{ArrayList}, so adding
an element \emph{at the end} is constant time, on average. If the key is
already in the map, we don't have to add an entry, but we have to call
\java{entry.getValue} and \java{entry.setValue}, and those are both
constant time. Putting it all together, \java{put} is linear.

\index{put}
\index{get}
\index{constant time}

By the same reasoning, \java{get} is also linear.

\java{remove} is slightly more complicated because
\java{entries.remove} might have to remove an element from the
beginning or middle of the \java{ArrayList}, and that takes linear
time. But that's OK: two linear operations are still linear.

\index{linear time}

In summary, the core methods are all linear, which is why we called this
implementation \java{MyLinearMap} (ta-da!).

If we know that the number of entries will be small, this implementation
might be good enough, but we can do better. In fact, there is an
implementation of \java{Map} where all of the core methods are
constant time. When you first hear that, it might not seem possible.
What we are saying, in effect, is that you can find a needle in a
haystack in constant time, regardless of how big the haystack is. It's
magic.

\index{haystack}

I'll explain how it works in two steps:

\begin{enumerate}

\item
  Instead of storing entries in one big \java{List}, we'll break them
  up into lots of short lists. For each key, we'll use a \textbf{hash
  code} (explained in the next section) to determine which list to use.

\item
  Using lots of short lists is faster than using just one, but as I'll
  explain, it doesn't change the order of growth; the core operations
  are still linear. But there is one more trick: if we increase the
  number of lists to limit the number of entries per list, the result is
  a constant-time map. You'll see the details in the next exercise, but
  first: hashing!

\end{enumerate}


\index{hash code}

In the next chapter, I'll present a solution, analyze the performance
of the core \java{Map} methods, and introduce a more efficient
implementation.


\chapter{Hashing}
\label{cs-maps-hashing-readme}

In this chapter, I define
\java{MyBetterMap}, a better implementation of the \java{Map} interface
than \java{MyLinearMap}, and introduce
\textbf{hashing}, which makes \java{MyBetterMap} more efficient.


\section{Hashing}
\label{hashing}

\index{hashing}
\index{MyBetterMap}

To improve the performance of \java{MyLinearMap}, we'll write a new
class, called \java{MyBetterMap}, that contains a collection of
\java{MyLinearMap} objects. It divides the keys among the embedded
maps, so the number of entries in each map is smaller, which speeds up
\java{findEntry} and the methods that depend on it.

Here's the beginning of the class definition:

\begin{verbatim}
public class MyBetterMap<K, V> implements Map<K, V> {
    
    protected List<MyLinearMap<K, V>> maps;
    
    public MyBetterMap(int k) {
        makeMaps(k);
    }

    protected void makeMaps(int k) {
        maps = new ArrayList<MyLinearMap<K, V>>(k);
        for (int i=0; i<k; i++) {
            maps.add(new MyLinearMap<K, V>());
        }
    }
}
\end{verbatim}

The instance variable, \java{maps}, is a collection of
\java{MyLinearMap} objects. The constructor takes a parameter,
\java{k}, that determines how many maps to use, at least initially.
Then \java{makeMaps} creates the embedded maps and stores them in an
\java{ArrayList}.

\index{ArrayList}

Now, the key to making this work is that we need some way to look at a
key and decide which of the embedded maps it should go into. When we
\java{put} a new key, we choose one of the maps; when we \java{get}
the same key, we have to remember where we put it.

\index{get}
\index{Map}

One possibility is to choose one of the sub-maps at random and keep
track of where we put each key. But how should we keep track? It might
seem like we could use a \java{Map} to look up the key and find the
right sub-map, but the whole point of the exercise is to write an
efficient implementation of a \java{Map}. We can't assume we already
have one.

A better approach is to use a \textbf{hash function}, which takes an
\java{Object}, any \java{Object}, and returns an integer called a
\textbf{hash code}.  Importantly, if it sees the same \java{Object}
more than once, it always returns the same hash code. That way, if we
use the hash code to store a key, we'll get the same hash code when we
look it up.

\index{hash function}
\index{hash code}

In Java, every \java{Object} provides a method called
\java{hashCode} that computes a hash function. The implementation of
this method is different for different objects; we'll see an example
soon.

\index{helper method}

Here's a helper method that chooses the right sub-map for a
given key:

\begin{verbatim}
protected MyLinearMap<K, V> chooseMap(Object key) {
    int index = 0;
    if (key != null) { 
        index = Math.abs(key.hashCode()) % maps.size();
    }
    return maps.get(index);
}
\end{verbatim}

If \java{key} is \java{null}, we choose the sub-map with index 0,
arbitrarily. Otherwise we use \java{hashCode} to get an integer,
apply \java{Math.abs} to make sure it is non-negative,
then use the remainder operator, \java{\%}, which guarantees that the
result is between 0 and \java{maps.size()-1}. So \java{index} is
always a valid index into \java{maps}. Then \java{chooseMap} returns
a reference to the map it chose.

\index{chooseMap}
\index{put}
\index{get}

We use \java{chooseMap} in both \java{put} and \java{get}, so when
we look up a key, we get the same map we chose when we added the key. At
least, we should --- I'll explain a little later why this might not
work.

Here's my implementation of \java{put} and \java{get}:

\begin{verbatim}
public V put(K key, V value) {
  MyLinearMap<K, V> map = chooseMap(key);
    return map.put(key, value);
}

public V get(Object key) {
    MyLinearMap<K, V> map = chooseMap(key);
    return map.get(key);
}
\end{verbatim}

Pretty simple, right? In both methods, we use \java{chooseMap} to find
the right sub-map and then invoke a method on the sub-map. 
That's how it works; now let's think about performance.

\index{sub-map}

If there are $n$ entries split up among $k$ sub-maps,
there will be $n/k$ entries per map, on average. When we look up
a key, we have to compute its hash code, which takes some time, then we
search the corresponding sub-map.

Because the entry lists in
\java{MyBetterMap} are $k$ times shorter than the entry list in
\java{MyLinearMap}, we expect the search to be $k$ times
faster. But the runtime is still proportional to $n$, so
\java{MyBetterMap} is still linear. In the next exercise, you'll see how we
can fix that.

\index{linear time}


\section{How does hashing work?}
\label{how-does-hashing-work}

The fundamental requirement for a hash function is that the same object
should produce the same hash code every time. For immutable objects,
that's relatively easy. For objects with mutable state, we have to think
harder.

\index{SillyString}

As an example of an immutable object, I'll define a class called
\java{SillyString} that encapsulates a \java{String}:

\begin{verbatim}
public class SillyString {
    private final String innerString;

    public SillyString(String innerString) {
        this.innerString = innerString;
    }

    public String toString() {
        return innerString;
    }
\end{verbatim}

This class is not very useful, which is why it's called
\java{SillyString}, but I'll use it to show how a class can define
its own hash function:

\begin{verbatim}
    @Override
    public boolean equals(Object other) {
        return this.toString().equals(other.toString());
    }
    
    @Override
    public int hashCode() {
        int total = 0;
        for (int i=0; i<innerString.length(); i++) {
            total += innerString.charAt(i);
        }
        return total;
    }
\end{verbatim}

Notice that \java{SillyString} overrides both \java{equals} and
\java{hashCode}. This is important. In order to work properly,
\java{equals} has to be consistent with \java{hashCode}, which means
that if two objects are considered equal --- that is, \java{equals}
returns \java{true} --- they should have the same hash code. But this
requirement only works one way; if two objects have the same hash code,
they don't necessarily have to be equal.

\index{equals}
\index{toString}

\java{equals} works by invoking \java{toString}, which returns
\java{innerString}. So two \java{SillyString} objects are equal if
their \java{innerString} instance variables are equal.

\index{hashCode}

\java{hashCode} works by iterating through the characters in the
\java{String} and adding them up. When you add a character to an \java{int},
Java converts the character to an integer using its Unicode code point.
You don't need to know anything about Unicode to understand this
example, but if you are curious, you can read more at 
\url{http://thinkdast.com/codepoint}.

\index{Unicode}
\index{code point}

This hash function satisfies the requirement: if two
\java{SillyString} objects contain embedded strings that are equal,
they will get the same hash code.

This works correctly, but it might not yield good performance,
because it returns the same hash code for many different strings. If two
strings contain the same letters in any order, they will have the same
hash code. And even if they don't contain the same letters, they might
yield the same total, like \java{"ac"} and \java{"bb"}.

If many objects have the same hash code, they end up in the same
sub-map.  If some sub-maps have more entries than others, the speedup
when we have $k$ maps might be much less than $k$. So one of the goals
of a hash function is to be uniform; that is, it should be equally
likely to produce any value in the range.  You can read more about
designing good hash functions at
\url{http://thinkdast.com/hash}.

\index{sub-map}

\section{Hashing and mutation}
\label{hashing-and-mutation}

\java{String}s are immutable, and \java{SillyString} is also immutable
because \java{innerString} is declared to be \java{final}. Once you
create a \java{SillyString}, you can't make \java{innerString} refer
to a different \java{String}, and you can't modify the \java{String} it
refers to. Therefore, it will always have the same hash code.

\index{mutable}
\index{immutable}
\index{SillyArray}

But let's see what happens with a mutable object. Here's a definition
for \java{SillyArray}, which is identical to \java{SillyString},
except that it uses an array of characters instead of a \java{String}:

\begin{verbatim}
public class SillyArray {
    private final char[] array;

    public SillyArray(char[] array) {
        this.array = array;
    }

    public String toString() {
        return Arrays.toString(array);
    }
    
    @Override
    public boolean equals(Object other) {
        return this.toString().equals(other.toString());
    }
    
    @Override
    public int hashCode() {
        int total = 0;
        for (int i=0; i<array.length; i++) {
            total += array[i];
        }
        System.out.println(total);
        return total;
    }
\end{verbatim}

\index{setChar}

\java{SillyArray} also provides \java{setChar}, which makes it
possible to modify the characters in the array:

\begin{verbatim}
public void setChar(int i, char c) {
    this.array[i] = c;
}
\end{verbatim}

Now suppose we create a \java{SillyArray} and add it to a map:

\begin{verbatim}
SillyArray array1 = new SillyArray("Word1".toCharArray());
map.put(array1, 1);
\end{verbatim}

The hash code for this array is 461. Now if we modify the contents of
the array and then try to look it up, like this:

\begin{verbatim}
array1.setChar(0, 'C');
Integer value = map.get(array1);
\end{verbatim}

the hash code after the mutation is 441. With a different hash code,
there's a good chance we'll go looking in the wrong sub-map. In that
case, we won't find the key, even though it is in the map. And that's
bad.

\index{hash code}

In general, it is dangerous to use mutable objects as keys in data
structures that use hashing, which includes \java{MyBetterMap} and
\java{HashMap}. If you can guarantee that the keys won't be modified
while they are in the map, or that any changes won't affect the hash
code, it might be OK. But it is probably a good idea to avoid it.


\section{Exercise 8}

\index{MyBetterMap}

In this exercise, you will finish off the implementation of
\java{MyBetterMap}.  In the repository for this book,
you'll find the source files for this exercise:

\begin{itemize}

\item
  \java{MyLinearMap.java} contains our solution to the previous exercise,
  which we will build on in this exercise.

\item
  \java{MyBetterMap.java} contains the code from the previous chapter
  with some methods you will fill in.

\item
  \java{MyHashMap.java} contains the outline of a hash table that
  grows when needed, which you will complete.

\item
  \java{MyLinearMapTest.java} contains the unit tests for
  \java{MyLinearMap}.

\item
  \java{MyBetterMapTest.java} contains the unit tests for
  \java{MyBetterMap}.

\item
  \java{MyHashMapTest.java} contains the unit tests for
  \java{MyHashMap}.

\item
  \java{Profiler.java} contains code for measuring and plotting
  runtime versus problem size.

\item
  \java{ProfileMapPut.java} contains code that profiles the
  \java{Map.put} method.
\end{itemize}

As usual, you should run \java{ant build} to compile the source
files. Then run \java{ant MyBetterMapTest}. Several tests should fail,
because you have some work to do!

\index{Ant}

Review the implementation of \java{put} and \java{get} from the
previous chapter. Then fill in the body of \java{containsKey}. HINT:
use \java{chooseMap}. Run \java{ant MyBetterMapTest} again and confirm
that \java{testContainsKey} passes.

\index{put}
\index{get}
\index{containsValue}

Fill in the body of \java{containsValue}. HINT: \emph{don't} use
\java{chooseMap}.  Run \java{ant MyBetterMapTest} again and confirm
that \java{testContainsValue} passes. Notice that we have to do more
work to find a value than to find a key.

Like \java{put} and \java{get}, this implementation of
\java{containsKey} is linear, because it has to search one of the
embedded sub-maps.  In the next chapter, we'll see how we can
improve this implementation even more.

\index{linear time}


\chapter{HashMap}

In the previous chapter, we wrote an implementation of the
\java{Map} interface that uses hashing.  We expect this version
to be faster, because the lists it searches are shorter, but
the order of growth is still linear.

\index{HashMap}
\index{sub-map}

If there are $n$ entries and $k$ sub-maps, the size of the sub-maps is
$n/k$ on average, which is still proportional to $n$.  But if we
increase $k$ along with $n$, we can limit the size of $n/k$.

For example, suppose we double $k$ every
time $n$ exceeds $k$; in that case the number of entries
per map would be less than 1 on average, and pretty much always less
than 10, as long as the hash function spreads out the keys reasonably
well.

\index{constant time}

If the number of entries per sub-map is constant, we can search a single
sub-map in constant time. And computing the hash function is generally
constant time (it might depend on the size of the key, but does not
depend on the number of keys). That makes the core \java{Map} methods,
\java{put} and \java{get}, constant time.

In the next exercise, you'll see the details.


\section{Exercise 9}
\label{implementing-myhashmap}

\index{MyHashMap}

In \java{MyHashMap.java}, I provide the outline of a hash table that
grows when needed. Here's the beginning of the definition:

\begin{verbatim}
public class MyHashMap<K, V> extends MyBetterMap<K, V> implements Map<K, V> {

    // average number of entries per sub-map before we rehash
    private static final double FACTOR = 1.0;

    @Override
    public V put(K key, V value) {
        V oldValue = super.put(key, value);

        // check if the number of elements per sub-map exceeds the threshold
        if (size() > maps.size() * FACTOR) {
            rehash();
        }
        return oldValue;
    }
}
\end{verbatim}

\java{MyHashMap} extends \java{MyBetterMap}, so it inherits the
methods defined there. The only method it overrides is \java{put}
which calls \java{put} in the superclass --- that is, it calls the
version of \java{put} in \java{MyBetterMap} --- and then it checks
whether it has to rehash. Calling \java{size} returns the total number
of entries, $n$. Calling \java{maps.size} returns the number of
embedded maps, $k$.

\index{superclass}
\index{load factor}
\index{MyBetterMap}

The constant \java{FACTOR}, which is called the \textbf{load factor},
determines the maximum number of entries per sub-map, on average. If
\java{n > k * FACTOR}, that means
\java{n/k > FACTOR}, which means the number of entries
per sub-map exceeds the threshold, so we call \java{rehash}.

\index{Ant}

Run \java{ant build} to compile the source files. Then run \java{ant
  MyHashMapTest}.  It should fail because the implementation of
\java{rehash} throws an exception. Your job is to fill it in.

\index{rehash}

Fill in the body of \java{rehash} to collect the entries in the table,
resize the table, and then put the entries back in. I provide two
methods that might come in handy: \java{MyBetterMap.makeMaps} and
\java{MyLinearMap.getEntries}. Your solution should double the number
of maps, $k$, each time it is called.


\section{Analyzing \java{MyHashMap}}
\label{analyzing-myhashmap}

\index{constant time}

If the number of entries in the biggest sub-map is proportional to
$n/k$, and $k$ grows in proportion to $n$, several of the core
\java{MyBetterMap} methods become constant time:

\begin{verbatim}
    public boolean containsKey(Object target) {
        MyLinearMap<K, V> map = chooseMap(target);
        return map.containsKey(target);
    }

    public V get(Object key) {
        MyLinearMap<K, V> map = chooseMap(key);
        return map.get(key);
    }

    public V remove(Object key) {
        MyLinearMap<K, V> map = chooseMap(key);
        return map.remove(key);
    }
\end{verbatim}

Each method hashes a key, which is constant time, and then invokes a
method on a sub-map, which is constant time.

\index{put}

So far, so good. But the other core method, \java{put}, is a little
harder to analyze. When we don't have to rehash, it is constant time,
but when we do, it's linear. In that way, it's similar to
\java{ArrayList.add}, which we analyzed in Section~\ref{classifying-add}.

\index{linear time}

For the same reason, \java{MyHashMap.put} turns out to be
constant time if we average over a series of invocations.
Again, the argument is based on amortized analysis 
(see Section~\ref{classifying-add}).

\index{amortized analysis}

Suppose the initial number of sub-maps, $k$, is 2, and the load
factor is 1. Now let's see how much work it takes to \java{put} a
series of keys. As the basic ``unit of work'', we'll count the number of
times we have to hash a key and add it to a sub-map.

\index{unit of work}

The first time we call \java{put} it takes 1 unit of work. The second
time also takes 1 unit. The third time we have to rehash, so it takes 2
units to rehash the existing keys and 1 unit to hash the new key.

Now the size of the hash table is 4, so the next time we call
\java{put}, it takes 1 unit of work. But the next time we have to
rehash, which takes 4 units to rehash the existing keys and 1 unit to
hash the new key.

\index{hashing}

Figure~\ref{fig-hashtable} shows the pattern, with the normal work of hashing
a new key shown across the bottom and extra work of rehashing shown as a
tower.

\begin{figure}
\centerline{\includegraphics[width=5.5in]{figs/tower.pdf}}
\caption{Representation of the work done to add elements to a hash table.}
\label{fig-hashtable}
\end{figure}

As the arrows suggest, if we knock down the towers, each one fills the
space before the next tower. The result is a uniform height of 2 units,
which shows that the average work per \java{put} is about 2 units. And
that means that \java{put} is constant time on average.

This diagram also shows why it is important to double the number of
sub-maps, $k$, when we rehash. If we only add to $k$
instead of multiplying, the towers would be too close together and
they would start piling up. And that would not be constant
time.

\index{constant time}


\section{The tradeoffs}
\label{the-tradeoffs}

We've shown that \java{containsKey}, \java{get}, and \java{remove}
are constant time, and \java{put} is constant time on average. We
should take a minute to appreciate how remarkable that is. The
performance of these operations is pretty much the same no matter how
big the hash table is. Well, sort of.

\index{containsKey}
\index{get}
\index{remove}
\index{put}

Remember that our analysis is based on a simple model of computation
where each ``unit of work'' takes the same amount of time. Real
computers are more complicated than that. In particular, they are
usually fastest when working with data structures small enough to fit in
cache; somewhat slower if the structure doesn't fit in cache but still
fits in memory; and \emph{much} slower if the structure doesn't fit in
memory.

\index{cache}
\index{containsValue}

Another limitation of this implementation is that hashing doesn't help
if we are given a value rather than a key: \java{containsValue} is
linear because it has to search all of the sub-maps. And there
is no particularly efficient way to look up a value and find the
corresponding key (or possibly keys).

\index{linear time}

And there's one more limitation: some of the methods that were constant
time in \java{MyLinearMap} have become linear. For example:

\begin{verbatim}
    public void clear() {
        for (int i=0; i<maps.size(); i++) {
            maps.get(i).clear();
        }
    }
\end{verbatim}

\java{clear} has to clear all of the sub-maps, and the number of
sub-maps is proportional to $n$, so it's linear. Fortunately,
this operation is not used very often, so for most applications this
tradeoff is acceptable.

\index{clear}


\section{Profiling \java{MyHashMap}}
\label{profiling-myhashmap}

Before we go on, we should check whether \java{MyHashMap.put} is really
constant time.

\index{MyHashMap}
\index{profiling}
\index{Ant}

Run \java{ant build} to compile the source
files. Then run \java{ant ProfileMapPut}. It measures the runtime of
\java{HashMap.put} (provided by Java) with a range of problem sizes,
and plots runtime versus problem size on a log-log scale. If this
operation is constant time, the total time for $n$ operations
should be linear, so the result should be a straight line with slope
1. When I ran this code, the estimated slope was close to 1, which is
consistent with our analysis. You should get something similar.

Modify \java{ProfileMapPut.java} so it profiles your implementation,
\java{MyHashMap}, instead of Java's \java{HashMap}. Run the
profiler again and see if the slope is near 1. You might have to
adjust \java{startN} and \java{endMillis} to find a range of
problem sizes where the runtimes are more than a few milliseconds, but
not more than a few thousand.

When I ran this code, I got a surprise: the slope was about 1.7,
which suggests that this implementation is not constant time after all.
It contains a ``performance bug''. 

\index{performance bug}

Before you read the next section, you should track down the error, fix
it, and confirm that \java{put} is now constant time, as expected.


\section{Fixing \java{MyHashMap}}
\label{fixing-myhashmap}

\index{size}

The problem with \java{MyHashMap} is in \java{size}, which is
inherited from \java{MyBetterMap}:

\begin{verbatim}
    public int size() {
        int total = 0;
        for (MyLinearMap<K, V> map: maps) {
            total += map.size();
        }
        return total;
    }
\end{verbatim}

To add up the total size it has to iterate the sub-maps. Since we
increase the number of sub-maps, $k$, as the number of entries,
$n$, increases, $k$ is proportional to $n$, so
\java{size} is linear.

\index{linear time}

And that makes \java{put} linear, too, because it uses \java{size}:

\begin{verbatim}
    public V put(K key, V value) {
        V oldValue = super.put(key, value);

        if (size() > maps.size() * FACTOR) {
            rehash();
        }
        return oldValue;
    }
\end{verbatim}

Everything we did to make \java{put} constant time is wasted if
\java{size} is linear!

\index{constant time}
\index{linear time}

Fortunately, there is a simple solution, and we have seen it before: we
have to keep the number of entries in an instance variable and update it
whenever we call a method that changes it.

\index{MyFixedHashMap}

You'll find my solution in the repository for this book, in
\java{MyFixedHashMap.java}.  Here's the beginning of the class definition:

\begin{verbatim}
public class MyFixedHashMap<K, V> extends MyHashMap<K, V> implements Map<K, V> {

    private int size = 0;

    public void clear() {
        super.clear();
        size = 0;
    }
\end{verbatim}

Rather than modify \java{MyHashMap}, I define a new class that
extends it. It adds a new instance variable, \java{size}, which is
initialized to zero.

Updating \java{clear} is straightforward; we invoke \java{clear} in
the superclass (which clears the sub-maps), and then update
\java{size}.

\index{superclass}

Updating \java{remove} and \java{put} is a little more difficult
because when we invoke the method on the superclass, we can't tell
whether the size of the sub-map changed. Here's how I worked around
that:

\begin{verbatim}
    public V remove(Object key) {
        MyLinearMap<K, V> map = chooseMap(key);
        size -= map.size();
        V oldValue = map.remove(key);
        size += map.size();
        return oldValue;
    }
\end{verbatim}

\java{remove} uses \java{chooseMap} to find the right sub-map, then
subtracts away the size of the sub-map. It invokes \java{remove} on
the sub-map, which may or may not change the size of the sub-map,
depending on whether it finds the key. But either way, we add the new
size of the sub-map back to \java{size}, so the final value of
\java{size} is correct.

\index{remove}

The rewritten version of \java{put} is similar:

\begin{verbatim}
    public V put(K key, V value) {
        MyLinearMap<K, V> map = chooseMap(key);
        size -= map.size();
        V oldValue = map.put(key, value);
        size += map.size();

        if (size() > maps.size() * FACTOR) {
            size = 0;
            rehash();
        }
        return oldValue;
    }
\end{verbatim}

We have the same problem here: when we invoke \java{put} on the
sub-map, we don't know whether it added a new entry. So we use the same
solution, subtracting off the old size and then adding in the new size.

\index{put}
\index{size}

Now the implementation of the \java{size} method is simple:

\begin{verbatim}
    public int size() {
        return size;
    }
\end{verbatim}

And that's pretty clearly constant time.

\index{constant time}

When I profiled this solution, I found that the total time for putting
$n$ keys is proportional to $n$, which means that each \java{put} is
constant time, as it's supposed to be.

\index{profiling}


\section{UML class diagrams}
\label{uml-class-diagrams}

\index{UML}
\index{class diagram}

One challenge of working with the code in this chapter is that we have
several classes that depend on each other. Here are some of the
relationships between the classes:

\begin{itemize}

\item
  \java{MyLinearMap} contains a \java{LinkedList} and implements
  \java{Map}.
\item
  \java{MyBetterMap} contains many \java{MyLinearMap} objects and
  implements \java{Map}.
\item
  \java{MyHashMap} extends \java{MyBetterMap}, so it also contains
  \java{MyLinearMap} objects, and it implements \java{Map}.
\item
  \java{MyFixedHashMap} extends \java{MyHashMap} and
  implements \java{Map}.
\end{itemize}

To help keep track of relationships like these, software engineers
often use {\bf UML class diagrams}. UML stands for Unified Modeling
Language
(see \url{http://thinkdast.com/uml}).
A ``class diagram'' is one of several graphical standards defined by UML.

In a class diagram, each class is represented by a box, and
relationships between classes are represented by
arrows. Figure~\ref{fig-uml} shows a UML class diagram for the classes
from the previous exercise, generated using the online tool yUML at
\url{http://yuml.me/}.

\begin{figure}
\centering
\includegraphics[width=5in]{figs/yuml1.pdf}
\caption{UML diagram for the classes in this chapter.}
\label{fig-uml}
% Edit: http://yuml.me/edit/2aa18a2d
\end{figure}

\index{inheritance}
\index{IS-A relationship}
\index{HAS-A relationship}

Different relationships are represented by different arrows:

\begin{itemize}

\item
  Arrows with a solid head indicate HAS-A relationships. For example,
  each instance of \java{MyBetterMap} contains multiple instances of
  \java{MyLinearMap}, so they are connected by a solid arrow.

\item
  Arrows with a hollow head and a solid line indicate IS-A
  relationships. For example, \java{MyHashMap} extends
  \java{MyBetterMap}, so they are connected by an IS-A arrow.

\item
  Arrows with a hollow head and a dashed line indicate that a class
  implements an interface; in this diagram, every class implements
  \java{Map}.

\end{itemize}

UML class diagrams provide a concise way to represent a lot of
information about a collection of classes. They are used during design
phases to communicate about alternative designs, during implementation
phases to maintain a shared mental map of the project, and during
deployment to document the design.


\chapter{TreeMap}

\index{TreeMap}
\index{Map}

This chapter presents the binary search tree, which is an efficient
implementation of the \java{Map} interface that is particularly useful
if we want to keep the elements sorted.


\section{What's wrong with hashing?}

At this point you should be familiar with the \java{Map} interface and
the \java{HashMap} implementation provided by Java. And by making your
own \java{Map} using a hash table, you should understand how
\java{HashMap} works and why we expect its core methods to be constant
time.

\index{constant time}

Because of this performance, \java{HashMap} is widely used, but it is
not the only implementation of \java{Map}. There are a few reasons you
might want another implementation:

\begin{enumerate}

\item
  Hashing can be slow, so even though \java{HashMap} operations are
  constant time, the ``constant'' might be big.

\item
  Hashing works well if the hash function distributes the keys evenly
  among the sub-maps.  But designing good hash functions is not easy,
  and if too many keys end up in the same sub-map, the performance of
  the \java{HashMap} may be poor.

\item
  The keys in a hash table are not stored in any particular order; in
  fact, the order might change when the table grows and the keys are
  rehashed. For some applications, it is necessary, or at least useful,
  to keep the keys in order.

\end{enumerate}

It is hard to solve all of these problems at the same
time, but Java provides an implementation called \java{TreeMap} that
comes close:

\begin{enumerate}

\item
  It doesn't use a hash function, so it avoids the cost of hashing
  and the difficulty of choosing a hash function.

\item
  Inside the \java{TreeMap}, the keys are are stored in a
  \textbf{binary search tree}, which makes it possible to traverse the
  keys, in order, in linear time.

\item
  The runtime of the core methods is proportional to $\log n$,
  which is not quite as good as constant time, but it is still
  very good.

\end{enumerate}

In the next section, I'll explain how binary search trees work and then you
will use one to implement a \java{Map}. Along the way, we'll analyze
the performance of the core map methods when implemented using a tree.

\index{linear time}


\section{Binary search tree}
\label{binary-search-tree}

\index{binary search tree}
\index{BST}
\index{BST property}
\index{node}

A binary search tree (BST) is a tree where each node contains a key, and
every \java{node} has the ``BST property'':

\begin{enumerate}

\item
  If \java{node} has a left child, all keys in the left subtree must
  be less than the key in \java{node}.

\item
  If \java{node} has a right child, all keys in the right subtree must
  be greater than the key in \java{node}.

\end{enumerate}

\begin{figure}
\centering
\includegraphics[height=2.5in]{figs/Binary_search_tree_1229.png}
%\includegraphics[height=2.5in]{figs/Binary_search_tree.svg}
\caption{Example of a binary search tree.}
\label{fig-bst}
\end{figure}

Figure~\ref{fig-bst}
shows a tree of integers that has this property.
This figure is from the Wikipedia page on binary search trees at
\url{http://thinkdast.com/bst}, which you
might find useful while you work on this exercise.

The key in the root is 8, and you can confirm that all keys to the left
of the root are less than 8, and all keys to the right are greater. You
can also check that the other nodes have this property.

\index{key}

Looking up a key in a binary search tree is fast because we don't have
to search the entire tree. Starting at the root, we can use the
following algorithm:

\begin{enumerate}

\item
  Compare the key you are looking for, \java{target}, to the key in
  the current node. If they are equal, you are done.

\item
  If \java{target} is less than the current key, search the left tree.
  If there isn't one, \java{target} is not in the tree.

\item
  If \java{target} is greater than the current key, search the right
  tree. If there isn't one, \java{target} is not in the tree.

\end{enumerate}

At each level of the tree, you only have to search one child. For
example, if you look for \java{target = 4} in the previous diagram,
you start at the root, which contains the key \java{8}. Because
\java{target} is less than \java{8}, you go left. Because
\java{target} is greater than \java{3} you go right. Because
\java{target} is less than \java{6}, you go left. And then you find
the key you are looking for.

In this example, it takes four comparisons to find the target,
even though the tree contains nine keys. In general, the number of
comparisons is proportional to the height of the tree, not the number of
keys in the tree.

\index{height}

So what can we say about the relationship between the height of the
tree, \java{h}, and the number of nodes, $n$? Starting small
and working up:

\begin{itemize}

\item
  If \java{h=1}, the tree only contains one node, so \java{n=1}.

\item
  If \java{h=2}, we can add two more nodes, for a total of
  \java{n=3}.

\item
  If \java{h=3}, we can add up to four more nodes, for a total
  of \java{n=7}.

\item
  If \java{h=4}, we can add up to eight more nodes, for a total
  of \java{n=15}.

\end{itemize}

By now you might see the pattern. If we number the levels of the tree from
\java{1} to \java{h}, the level with index \java{i} can have up to
$2^{i-1}$ nodes. And the total number of nodes in \java{h} levels is $2^h-1$.
If we have

\[ n = 2^h - 1 \]

we can take the logarithm base 2 of both sides:

\[ log_2 n \approx h \]

which means that the height of the tree is proportional to
$\log n$, if the tree is full; that is, if each level contains the
maximum number of nodes.

So we expect that we can look up a key in a binary search tree in time
proportional to $\log n$. This is true if the tree is full, and
even if the tree is only partially full. But it is not always true, as
we will see.

\index{log time}
\index{logarithm}
\index{order of growth}

An algorithm that takes time proportional to $\log n$ is called
``logarithmic'' or ``log time'', and it belongs to the order of growth
$O(\log n)$.


\section{Exercise 10}
\label{exercise10}

For this exercise you will write an implementation of
the \java{Map} interface using a binary search tree.

\index{Map}

Here's the beginning of an implementation, called \java{MyTreeMap}:

\begin{verbatim}
public class MyTreeMap<K, V> implements Map<K, V> {

    private int size = 0;
    private Node root = null;
\end{verbatim}

The instance variables are \java{size}, which keeps track of the
number of keys, and \java{root}, which is a reference to the root node
in the tree. When the tree is empty, \java{root} is \java{null} and
\java{size} is 0.

Here's the definition of \java{Node}, which is defined inside
\java{MyTreeMap}:

\begin{verbatim}
    protected class Node {
        public K key;
        public V value;
        public Node left = null;
        public Node right = null;

        public Node(K key, V value) {
            this.key = key;
            this.value = value;
        }
    }
\end{verbatim}

\index{Node}
\index{key-value pair}

Each node contains a key-value pair and references to two child nodes,
\java{left} and \java{right}. Either or both of the child nodes can
be \java{null}.

Some of the \java{Map} methods are easy to implement, like
\java{size} and \java{clear}:

\begin{verbatim}
    public int size() {
        return size;
    }

    public void clear() {
        size = 0;
        root = null;
    }
\end{verbatim}

\java{size} is clearly constant time.

\index{size}
\index{constant time}

\java{clear} appears to be constant time, but consider this: when
\java{root} is set to \java{null}, the garbage collector reclaims
the nodes in the tree, which takes linear time. Should work done by the
garbage collector count? I think so.

\index{clear}
\index{linear time}

In the next section, you'll fill in some of the other methods, including
the most important ones, \java{get} and \java{put}.

\section{Implementing a TreeMap}

\index{MyTreeMap}

In the repository for this book, you'll find these source files:

\begin{itemize}

\item
  \java{MyTreeMap.java} contains the code from the previous section
  with outlines for the missing methods.

\item
  \java{MyTreeMapTest.java} contains the unit tests for
  \java{MyTreeMap}.

\end{itemize}

Run \java{ant build} to compile the source files. Then run \java{ant
  MyTreeMapTest}.  Several tests should fail, because you have some
work to do!

\index{Ant}

I've provided outlines for \java{get} and \java{containsKey}.  Both of
them use \java{findNode}, which is a private method I defined; it is
not part of the \java{Map} interface. Here's how it starts:

\begin{verbatim}
    private Node findNode(Object target) {
        if (target == null) {
            throw new IllegalArgumentException();
        }

        @SuppressWarnings("unchecked")
        Comparable<? super K> k = (Comparable<? super K>) target;

        // TODO: FILL THIS IN!
        return null;
    }
\end{verbatim}

\index{get}
\index{containsKey}
\index{findNode}

The parameter \java{target} is the key we're looking for. If
\java{target} is \java{null}, \java{findNode} throws an exception.
Some implementations of \java{Map} can handle \java{null} as a key,
but in a binary search tree, we need to be able to compare keys, so
dealing with \java{null} is problematic. To keep things simple,
this implementation does not allow \java{null} as a key.

The next lines show how we can compare \java{target} to a key in the
tree. From the signature of \java{get} and \java{containsKey}, the
compiler considers \java{target} to be an \java{Object}. But we need
to be able to compare keys, so we typecast \java{target} to
\java{Comparable<? super K>}, which means that
it is comparable to an instance of type \java{K}, or any superclass of
\java{K}.  If you are not familiar with this use of ``type
wildcards'', you can read more at
\url{http://thinkdast.com/gentut}.

\index{type wildcard}
\index{superclass}

Fortunately, dealing with Java's type system is not the point of this
exercise. Your job is to fill in the rest of \java{findNode}. If it
finds a node that contains \java{target} as a key, it should return
the node. Otherwise it should return \java{null}. When you get this
working, the tests for \java{get} and \java{containsKey} should
pass.

Note that your solution should only search one path through the tree, so
it should take time proportional to the height of the tree. You should
not search the whole tree!

\index{height}
\index{helper method}

Your next task is to fill in \java{containsValue}. To get you started,
I've provided a helper method, \java{equals}, that compares
\java{target} and a given key. Note that the values in the tree (as
opposed to the keys) are not necessarily comparable, so we can't use
\java{compareTo}; we have to invoke \java{equals} on \java{target}.

\index{containsValue}

Unlike your previous solution for \java{findNode}, your solution for
\java{containsValue} \emph{does} have to search the whole tree, so its
runtime is proportional to the number of keys, $n$, not the
height of the tree, \java{h}.

The next method you should fill in is \java{put}. I've provided
  starter code that handles the simple cases:

\begin{verbatim}
    public V put(K key, V value) {
        if (key == null) {
            throw new IllegalArgumentException();
        }
        if (root == null) {
            root = new Node(key, value);
            size++;
            return null;
        }
        return putHelper(root, key, value);
    }

    private V putHelper(Node node, K key, V value) {
        // TODO: Fill this in.
    }
\end{verbatim}

If you try to put \java{null} as a key, \java{put} throws an
exception.

If the tree is empty, \java{put} creates a new node and initializes
the instance variable \java{root}.

\index{put}
\index{helper method}

Otherwise, it calls \java{putHelper}, which is a private method I
defined; it is not part of the \java{Map} interface.

Fill in \java{putHelper} so it searches the tree and:

\begin{enumerate}

\item
  If \java{key} is already in the tree, it replaces the old value with
  the new, and returns the old value.

\item
  If \java{key} is not in the tree, it creates a new node, finds the
  right place to add it, and returns \java{null}.

\end{enumerate}

Your implementation of \java{put} should take time proportional to the
height of the tree, $h$, not the number of elements, $n$. Ideally you
should search the tree only once, but if you find it easier to search
twice, you can do that; it will be slower, but it doesn't change the
order of growth.

\index{keySet}

Finally, you should fill in the body of \java{keySet}.  According to
the documentation at \url{http://thinkdast.com/mapkeyset}, this method
should return a \java{Set} that iterates the keys in order; that is,
in increasing order according to the \java{compareTo} method.  The
\java{HashSet} implementation of \java{Set}, which we used in
Section~\ref{exercise6}, doesn't maintain the order of the keys, but
the \java{LinkedHashSet} implementation does.  You can read about it
at \url{http://thinkdast.com/linkedhashset}.

I've provided an outline of \java{keySet} that creates and returns a
\java{LinkedHashSet}:

\begin{verbatim}
    public Set<K> keySet() {
        Set<K> set = new LinkedHashSet<K>();
        return set;
    }
\end{verbatim}

\index{helper method}
\index{recursion}

You should finish off this method so it adds the keys from the tree to
\java{set} in ascending order. HINT: you might want to write a helper
method; you might want to make it recursive; and you might want to
read about in-order tree traversal at
\url{http://thinkdast.com/inorder}.

\index{in-order} 
\index{tree traversal}

% TODO: more help with recursion?

When you are done, all tests should pass. In the next chapter, I'll go
over my solutions and test the performance of the core methods.


\chapter{Binary search tree}

This chapter presents solutions to the previous exercise, then tests the
performance of the tree-backed map. I present a problem with the
implementation and explain how Java's \java{TreeMap} solves it.


\section{A simple \java{MyTreeMap}}
\label{our-version-of-mytreemap}

In the previous exercise I gave you the outline of \java{MyTreeMap} and
asked you to fill in the missing methods. Now I'll present a
solution, starting with \java{findNode}:

\index{MyTreeMap}
\index{findNode}

\begin{verbatim}
private Node findNode(Object target) {
    // some implementations can handle null as a key, but not this one
    if (target == null) {
            throw new IllegalArgumentException();
    }

    // something to make the compiler happy
    @SuppressWarnings("unchecked")
    Comparable<? super K> k = (Comparable<? super K>) target;

    // the actual search
    Node node = root;
    while (node != null) {
        int cmp = k.compareTo(node.key);
        if (cmp < 0)
            node = node.left;
        else if (cmp > 0)
            node = node.right;
        else
            return node;
    }
    return null;
}
\end{verbatim}

\java{findNode} is a private method used by \java{containsKey} and
\java{get}; it is not part of the \java{Map} interface. The
parameter \java{target} is the key we're looking for. I explained the
first part of this method in the previous exercise:

\begin{itemize}

\item
  In this implementation, \java{null} is not a legal value for a key.

\item
  Before we can invoke \java{compareTo} on \java{target}, we have to
  typecast it to some kind of \java{Comparable}. The ``type wildcard''
  used here is as permissive as possible; that is, it works with any
  type that implements \java{Comparable} and whose \java{compareTo}
  method accepts \java{K} or any supertype of \java{K}.

\end{itemize}

\index{type wildcard}

After all that, the actual search is relatively simple. We initialize a
loop variable \java{node} so it refers to the root node. Each time
through the loop, we compare the target to \java{node.key}. If the
target is less than the current key, we move to the left child. If it's
greater, we move to the right child. And if it's equal, we return the
current node.

If we get to the bottom of the tree without finding the target, we
conclude that it is not in the tree and return \java{null}.


\section{Searching for values}
\label{searching-for-values}

As I explained in the previous exercise, the runtime of
\java{findNode} is proportional to the height of the tree, not the
number of nodes, because we don't have to search the whole tree. But
for \java{containsValue}, we have to search the values, not the keys;
the BST property doesn't apply to the values, so we have to search the
whole tree.

\index{recursion}

My solution is recursive:

\begin{verbatim}
public boolean containsValue(Object target) {
    return containsValueHelper(root, target);
}

private boolean containsValueHelper(Node node, Object target) {
    if (node == null) {
        return false;
    }
    if (equals(target, node.value)) {
        return true;
    }
    if (containsValueHelper(node.left, target)) {
        return true;
    }
    if (containsValueHelper(node.right, target)) {
        return true;
    }
    return false;
}
\end{verbatim}

\java{containsValue} takes the target value as a parameter and
immediately invokes \java{containsValueHelper}, passing the root of
the tree as an additional parameter.

\index{base case}
\index{recursion}

Here's how \java{containsValueHelper} works:

\begin{itemize}

\item
  The first \java{if} statement checks the base case of the recursion.
  If \java{node} is \java{null}, that means we have recursed to the
  bottom of the tree without finding the \java{target}, so we should
  return \java{false}. Note that this only means that the target did
  not appear on one path through the tree; it is still possible that it
  will be found on another.

\item
  The second case checks whether we've found what we're looking for. If
  so, we return \java{true}. Otherwise, we have to keep going.

\item
  The third case makes a recursive call to search for \java{target} in
  the left subtree. If we find it, we can return \java{true}
  immediately, without searching the right subtree. Otherwise, we keep
  going.

\item
  The fourth case searches the right subtree. Again, if we find what we
  are looking for, we return \java{true}. Otherwise, having searched
  the whole tree, we return \java{false}.

\end{itemize}

This method ``visits'' every node in the tree, so it takes time
proportional to the number of nodes.

\index{linear time}


\section{Implementing {\tt put}}
\label{implementing-put}

The \java{put} method is a little more complicated than \java{get}
because it has to deal with two cases: (1) if the given key is already
in the tree, it replaces and returns the old value; (2) otherwise it has
to add a new node to the tree, in the right place.

\index{put}

In the previous exercise, I provided this starter code:

\begin{verbatim}
public V put(K key, V value) {
    if (key == null) {
        throw new IllegalArgumentException();
    }
    if (root == null) {
        root = new Node(key, value);
        size++;
        return null;
    }
    return putHelper(root, key, value);
}
\end{verbatim}

And asked you to fill in \java{putHelper}. Here's my solution:

\begin{verbatim}
private V putHelper(Node node, K key, V value) {
    Comparable<? super K> k = (Comparable<? super K>) key;
    int cmp = k.compareTo(node.key);

    if (cmp < 0) {
        if (node.left == null) {
            node.left = new Node(key, value);
            size++;
            return null;
        } else {
            return putHelper(node.left, key, value);
        }
    }
    if (cmp > 0) {
        if (node.right == null) {
            node.right = new Node(key, value);
            size++;
            return null;
        } else {
            return putHelper(node.right, key, value);
        }
    }
    V oldValue = node.value;
    node.value = value;
    return oldValue;
}
\end{verbatim}

\index{subtree}

The first parameter, \java{node}, is initially the root of the tree,
but each time we make a recursive call, it refers to a different
subtree.  As in \java{get}, we use the \java{compareTo} method to
figure out which path to follow through the tree.  If \java{cmp < 0},
the key we're adding is less than \java{node.key}, so we want to look
in the left subtree. There are two cases:

\begin{itemize}

\item
  If the left subtree is empty, that is, if \java{node.left} is
  \java{null}, we have reached the bottom of the tree without finding
  \java{key}. At this point, we know that \java{key} isn't in the
  tree, and we know where it should go. So we create a new node and add
  it as the left child of \java{node}.

\item
  Otherwise we make a recursive call to search the left subtree.

\end{itemize}

If \java{cmp > 0}, the key we're adding is greater than
\java{node.key}, so we want to look in the right subtree. And we
handle the same two cases as in the previous branch.
Finally, if \java{cmp == 0}, we found the key in the tree, so we
replace and return the old value.

\index{iterative}

I wrote this method recursively to make it more readable, but it would
be straightforward to rewrite it iteratively, which you might want to
do as an exercise.


\section{In-order traversal}
\label{in-order-traversal}

The last method I asked you to write is \java{keySet}, which returns
a \java{Set} that contains the keys from the tree in ascending order.
In other implementations of \java{Map}, the keys returned by
\java{keySet} are in no particular order, but one of the capabilities
of the tree implementation is that it is simple and efficient to sort
the keys. So we should take advantage of that.

\index{in-order}
\index{tree traversal}
\index{keySet}

Here's my solution:

\begin{verbatim}
public Set<K> keySet() {
    Set<K> set = new LinkedHashSet<K>();
    addInOrder(root, set);
    return set;
}

private void addInOrder(Node node, Set<K> set) {
    if (node == null) return;
    addInOrder(node.left, set);
    set.add(node.key);
    addInOrder(node.right, set);        
}
\end{verbatim}

In \java{keySet}, we create a \java{LinkedHashSet}, which is a
\java{Set} implementation that keeps the elements in order (unlike
most other \java{Set} implementations). Then we call
\java{addInOrder} to traverse the tree.

\index{LinkedHashSet}

The first parameter, \java{node}, is initially the root of the tree,
but as you should expect by now, we use it to traverse the tree
recursively. \java{addInOrder} performs a classic ``in-order
traversal'' of the tree.

If \java{node} is \java{null}, that means the subtree is empty, so
we return without adding anything to \java{set}. Otherwise we:

\begin{enumerate}

\item
  Traverse the left subtree in order.

\item
  Add \java{node.key}.

\item
  Traverse the right subtree in order.

\end{enumerate}

Remember that the BST property guarantees that all nodes in the left
subtree are less than \java{node.key}, and all nodes in the right
subtree are greater. So we know that \java{node.key} has been added in
the correct order.

\index{BST property}
\index{recursion}
\index{base case}

Applying the same argument recursively, we know that the elements from
the left subtree are in order, as well as the elements from the right
subtree.  And the base case is correct: if the subtree is empty, no
keys are added.  So we can conclude that this method adds all keys in
the correct order.

Because this method visits every node in the tree, like
\java{containsValue}, it takes time proportional to $n$.


\section{The logarithmic methods}
\label{the-logarithmic-methods}

In \java{MyTreeMap}, the methods \java{get} and \java{put} take
time proportional to the height of the tree, $h$. In the previous
exercise, we showed that if the tree is full --- if every level of the tree
contains the maximum number of nodes --- the height of the tree is
proportional to $\log n$.

\index{logarithmic time}
\index{get}
\index{put}

And I claimed that \java{get} and \java{put} are logarithmic; that
is, they take time proportional to $\log n$. But for most
applications, there's no guarantee that the tree is full. In general,
the shape of the tree depends on the keys and what order they are added.

To see how this works out in practice, we'll test our implementation
with two sample datasets: a list of random strings and a list of
timestamps in increasing order.

\index{profiling}

Here's the code that generates random strings:

\begin{verbatim}
Map<String, Integer> map = new MyTreeMap<String, Integer>();

for (int i=0; i<n; i++) {
    String uuid = UUID.randomUUID().toString();
    map.put(uuid, 0);
}
\end{verbatim}

\java{UUID} is a class in the \java{java.util} package that can
generate a random ``universally unique identifier''. UUIDs are useful
for a variety of applications, but in this example we're taking
advantage of an easy way to generate random strings.

\index{UUID}

I ran this code with \java{n=16384} and measured the runtime and the
height of the final tree. Here's the output:

\begin{verbatim}
Time in milliseconds = 151
Final size of MyTreeMap = 16384
log base 2 of size of MyTreeMap = 14.0
Final height of MyTreeMap = 33
\end{verbatim}

I included ``log base 2 of size of MyTreeMap'' to see how tall the tree
would be if it were full. The result indicates that a full tree with
height 14 would contain 16,384 nodes.

The actual tree of random strings has height 33, which is substantially
more than the theoretical minimum, but not too bad. To find one key in a
collection of 16,384, we only have to make 33 comparisons. Compared to a
linear search, that's almost 500 times faster.

\index{linear search}

This performance is typical with random strings or other keys that are
added in no particular order. The final height of the tree might be 2-3
times the theoretical minimum, but it is still proportional to
$\log n$, which is much less than $n$. In fact,
$\log n$ grows so slowly as $n$ increases, it can be
difficult to distinguish logarithmic time from constant time in
practice.

\index{constant time}
\index{logarithmic time}
\index{timestamp}

However, binary search trees don't always behave so well. Let's see what
happens when we add keys in increasing order. Here's an example that
measures timestamps in nanoseconds and uses them as keys:

\begin{verbatim}
MyTreeMap<String, Integer> map = new MyTreeMap<String, Integer>();

for (int i=0; i<n; i++) {
    String timestamp = Long.toString(System.nanoTime());
    map.put(timestamp, 0);
}
\end{verbatim}

\java{System.nanoTime} returns an integer with type \java{long} that
indicates elapsed time in nanoseconds. Each time we call it, we get a
somewhat bigger number. When we convert these timestamps to strings,
they appear in increasing alphabetical order.

And let's see what happens when we run it:

\begin{verbatim}
Time in milliseconds = 1158
Final size of MyTreeMap = 16384
log base 2 of size of MyTreeMap = 14.0
Final height of MyTreeMap = 16384
\end{verbatim}

The runtime is more than seven times longer than in the previous case.
longer. If you wonder why, take a look at the final height of the tree:
16384!

\begin{figure}
\centering
\includegraphics[width=4in]{figs/bst.pdf}
\caption{Binary search trees, balanced (left) and unbalanced (right).}
\label{bstfig}
\end{figure}

If you think about how \java{put} works, you can figure out what's
going on. Every time we add a new key, it's larger than all of the keys
in the tree, so we always choose the right subtree, and always add the
new node as the right child of the rightmost node. The result is an
``unbalanced'' tree that only contains right children.

\index{unbalanced tree}
\index{balanced tree}

The height of this tree is proportional to $n$, not
$\log n$, so the performance of \java{get} and \java{put} is
linear, not logarithmic.

\index{linear time}

Figure~\ref{bstfig} shows an example of a balanced and unbalanced
tree.  In the balanced tree, the height is 4 and the total number of
nodes is $2^4-1 = 15$.  In the unbalanced tree with the same number of
nodes, the height is 15.


\section{Self-balancing trees}
\label{self-balancing-trees}

\index{self-balancing tree}

There are two possible solutions to this problem:

\begin{itemize}

\item
  You could avoid adding keys to the \java{Map} in order. But this is
  not always possible.

\item
  You could make a tree that does a better job of handling keys if they
  happen to be in order.

\end{itemize}

The second solution is better, and there are several ways to do it. The
most common is to modify \java{put} so that it detects when the tree
is starting to become unbalanced and, if so, rearranges the nodes. Trees
with this capability are called ``self-balancing''. Common
self-balancing trees include the AVL tree (``AVL'' are the initials of
the inventors), and the red-black tree, which is what the Java
\java{TreeMap} uses.

\index{AVL tree}
\index{red-black tree}

In our example code, if we replace \java{MyTreeMap} with the Java
\java{TreeMap}, the runtimes are about the same for the random strings
and the timestamps. In fact, the timestamps run faster, even though they
are in order, probably because they take less time to hash.

\index{logarithmic time}

In summary, a binary search tree can implement \java{get} and
\java{put} in logarithmic time, but only if the keys are added in an
order that keeps the tree sufficiently balanced. Self-balancing trees
avoid this problem by doing some additional work each time a new key is
added.

You can read more about self-balancing trees at
\url{http://thinkdast.com/balancing}.


\section{One more exercise}
\label{one-more-exercise}

In the previous exercise you didn't have to implement \java{remove},
but you might want to try it. If you remove a node from the middle of
the tree, you have to rearrange the remaining nodes to restore the BST
property.  You can probably figure out how to do that on your own, or
you can read the explanation at
\url{http://thinkdast.com/bstdel}.

\index{remove}

Removing a node and rebalancing a tree are similar operations: if you do
this exercise, you will have a better idea of how self-balancing trees
work.



\chapter{Persistence}

In the next few exercises we will get back to building a web search
engine. To review, the components of a search engine are:

\begin{itemize}

\item
  Crawling: We'll need a program that can download a web page, parse it,
  and extract the text and any links to other pages.

\item
  Indexing: We'll need an index that makes it possible to look up a
  search term and find the pages that contain it.

\item
  Retrieval: And we'll need a way to collect results from the index and
  identify pages that are most relevant to the search terms.

\end{itemize}

\index{search engine}
\index{crawler}
\index{indexer}
\index{retriever}

If you did Exercise~\ref{exercise6}, you implemented an index
using Java maps. In this exercise, we'll revisit the indexer and make
a new version that stores the results in a database.

\index{indexer}

If you did Exercise~\ref{exercise5}, you
built a crawler that follows the first link it finds. In the next exercise,
we'll make a more general version that stores every link it finds in a
queue and explores them in order.

And then, finally, you will work on the retrieval problem.

In these exercises, I provide less starter code, and you will make more
design decisions. These exercises are also more open-ended. I will suggest
some minimal goals you should try to reach, but there are many ways you
can go farther if you want to challenge yourself.

Now, let's get started on a new version of the indexer.

\section{Redis}
\label{redis}

\index{Redis}

The previous version of the indexer stores the index in two data
structures: a \java{TermCounter} that maps from a search term to the
number of times it appears on a web page, and an \java{Index} that
maps from a search term to the set of pages where it appears.

These data structures are stored in the memory of a running Java
program, which means that when the program stops running, the index is
lost. Data stored only in the memory of a running program is called
``volatile'', because it vaporizes when the program ends.

\index{volatile}
\index{persistent}

Data that persists after the program that created it ends is called
``persistent''. In general, files stored in a file system are
persistent, as well as data stored in databases.

\index{JSON}

A simple way to make data persistent is to store it in a file. Before
the program ends, it could translate its data structures into a format
like JSON (\url{http://thinkdast.com/json}) and then write them
into a file. When it starts again, it could read the file and rebuild
the data structures.

But there are several problems with this solution:

\begin{enumerate}
\item
  Reading and writing large data structures (like a Web index) would be
  slow.

\item
  The entire data structure might not fit into the memory of a single
  running program.

\item
  If a program ends unexpectedly (for example, due to a power outage),
  any changes made since the program last started would be lost.

\end{enumerate}

A better alternative is a database that provides persistent storage and
the ability to read and write parts of the database without reading and
writing the whole thing.

\index{database}
\index{DBMS}

There are many kinds of database management systems (DBMS) that provide
different capabilities. You can read an overview at
\url{http://thinkdast.com/database}.

\index{Redis}

The database I recommend for this exercise is Redis, which provides
persistent data structures that are similar to Java data structures.
Specifically, it provides:

\begin{itemize}

\item
  Lists of strings, similar to Java \java{List}.

\item
  Hashes, similar to Java \java{Map}.

\item
  Sets of strings, similar to Java \java{Set}.

\end{itemize}

Redis is a ``key-value database'', which means that the data structures
it contains (the values) are identified by unique strings (the keys). A
key in Redis plays the same role as a reference in Java: it identifies
an object. We'll see some examples soon.

\index{key-value database}


\section{Redis clients and servers}
\label{redis-clients-and-servers}

\index{client}
\index{server}

Redis is usually run as a remote service; in fact, the name stands for
``REmote DIctionary Server''. To use Redis, you have to run the Redis
server somewhere and then connect to it using a Redis client. There are
many ways to set up a server and many clients you could use. For this
exercise, I recommend:

\begin{enumerate}

\item
  Rather than install and run the server yourself, consider using a
  service like RedisToGo (\url{http://thinkdast.com/redistogo}), which runs
  Redis in the cloud. They offer a free plan with enough resources for
  the exercise.

\item
  For the client I recommend Jedis, which is a Java library that
  provides classes and methods for working with Redis.

\end{enumerate}

\index{RedisToGo}
\index{Jedis}

Here are more detailed instructions to help you get started:

\begin{itemize}

\item Create an account on RedisToGo, at
  \url{http://thinkdast.com/redissign},
  and select the plan you want (probably the free plan to get started).

\item
  Create an ``instance'', which is a virtual machine running the Redis
  server. If you click on the ``Instances'' tab, you should see your new
  instance, identified by a host name and a port number. For example, I
  have an instance named ``dory-10534''.

\item
  Click on the instance name to get the configuration page. Make a note
  of the URL near the top of the page, which looks like this:

  \begin{verbatim}
  redis://redistogo:1234567feedfacebeefa1e1234567@dory.redistogo.com:10534
  \end{verbatim}

\end{itemize}

\index{Redis instance}

This URL contains the server's host name, \java{dory.redistogo.com},
the port number, \java{10534}, and the password you will need to
connect to the server, which is the long string of letters and numbers
in the middle. You will need this information for the next step.


\section{Making a Redis-backed index}
\label{hello-jedis}

\index{JedisMaker}
\index{JedisIndex}
\index{WikiFetcher}

In the repository for this book,
you'll find the source files for this exercise:

\begin{itemize}

\item
  \java{JedisMaker.java} contains example code for connecting to a
  Redis server and running a few Jedis methods.

\item
  \java{JedisIndex.java} contains starter code for this exercise.

\item
  \java{JedisIndexTest.java} contains test code for
  \java{JedisIndex}.

\item
  \java{WikiFetcher.java} contains the code we saw in previous exercises to
  read web pages and parse them using jsoup.

\end{itemize}

You will also need these files, which you worked on in previous
exercises:

\begin{itemize}

\item
  \java{Index.java} implements an index using Java data structures.

\item
  \java{TermCounter.java} represents a map from terms to their
  frequencies.

\item
  \java{WikiNodeIterable.java} iterates through the nodes in a DOM
  tree produced by jsoup.

\end{itemize}

If you have working versions of these files, you can use them for
this exercise.  If you didn't do the previous exercises, or you
are not confident in your solutions, you can copy my solutions
from the {\tt solutions} folder.

The first step is to use Jedis to connect to your Redis server.
\java{RedisMaker.java} shows how to do this. It reads information
about your Redis server from a file, connects to it and logs in using
your password, then returns a \java{Jedis} object you can use to
perform Redis operations.

\index{helper class}

If you open \java{JedisMaker.java}, you should see the
\java{JedisMaker} class, which is a helper class that provides one
static method, \java{make}, which creates a \java{Jedis} object. Once
this object is authenticated, you can use it to communicate with your
Redis database.

\java{JedisMaker} reads information about your Redis server from a
file named \java{redis_url.txt}, which you should put in the
directory \java{src/resources}:

\begin{itemize}

\item
  Use a text editor to create end edit
  \java{ThinkDataStructures/code/src/resources/redis_url.txt}.

\item
  Paste in the URL of your server. If you are using RedisToGo, the URL
  will look like this:

\java{redis://redistogo:1234567feedfacebeefa1e1234567@dory.redistogo.com:10534}

\end{itemize}

Because this file contains the password for your Redis server, you
should not put this file in a public repository. To help you avoid
doing that by accident, the repository contains a {\tt .gitignore}
file that makes it harder (but not impossible) to put this file
in your repo.

\index{Ant}

Now run \java{ant build} to compile the
source files and \java{ant JedisMaker} to run the example code in
\java{main}:

\begin{verbatim}
    public static void main(String[] args) {

        Jedis jedis = make();
        
        // String
        jedis.set("mykey", "myvalue");
        String value = jedis.get("mykey");
        System.out.println("Got value: " + value);
        
        // Set
        jedis.sadd("myset", "element1", "element2", "element3");
        System.out.println("element2 is member: " + 
                           jedis.sismember("myset", "element2"));
        
        // List
        jedis.rpush("mylist", "element1", "element2", "element3");
        System.out.println("element at index 1: " + 
                           jedis.lindex("mylist", 1));
        
        // Hash
        jedis.hset("myhash", "word1", Integer.toString(2));
        jedis.hincrBy("myhash", "word2", 1);
        System.out.println("frequency of word1: " + 
                           jedis.hget("myhash", "word1"));
        System.out.println("frequency of word1: " + 
                            jedis.hget("myhash", "word2"));
        
        jedis.close();
    }
\end{verbatim}

This example demonstrates the data types and methods you are most likely
to use for this exercise. When you run it, the output should be:

\begin{verbatim}
Got value: myvalue
element2 is member: true
element at index 1: element2
frequency of word1: 2
frequency of word2: 1
\end{verbatim}

In the next section, I'll explain how the code works.


\newcommand{\redis}{\textit}

\section{Redis data types}
\label{redis-data-types}

Redis is basically a map from keys, which are strings, to
values, which can be one of several data types. The most basic Redis
data type is a \redis{string}.  I will write Redis types in
italics to distinguish them from Java types. 

To add a \redis{string} to the database,
use \java{jedis.set}, which is similar to \java{Map.put}; the
parameters are the new key and the corresponding value. To look up a
key and get its value, use \java{jedis.get}:

\begin{verbatim}
        jedis.set("mykey", "myvalue");
        String value = jedis.get("mykey");
\end{verbatim}

In this example, the key is \java{"mykey"} and the value is
\java{"myvalue"}.

\index{Redis set}
\index{Redis get}

Redis provides a \redis{set} structure, which is
similar to a Java
\java{Set<String>}. To add elements to a Redis \redis{set},
you choose a key to identify the \redis{set} and then use
\java{jedis.sadd}:

\begin{verbatim}
        jedis.sadd("myset", "element1", "element2", "element3");
        boolean flag = jedis.sismember("myset", "element2");
\end{verbatim}

You don't have to create the \redis{set} as a separate step. If it doesn't
exist, Redis creates it. In this case, it creates a \redis{set} named
\java{myset} that contains three elements.

The method \java{jedis.sismember} checks whether an element is in a
\redis{set}. Adding elements and checking membership are constant time
operations.

\index{constant time}

Redis also provides a \redis{list} structure, which is
similar to a Java
\java{List<String>}. The method
\java{jedis.rpush} adds elements to the end (right side) of a
\redis{list}:

\begin{verbatim}
        jedis.rpush("mylist", "element1", "element2", "element3");
        String element = jedis.lindex("mylist", 1);
\end{verbatim}

Again, you don't have to create the structure before you start
adding elements. This example creates a \redis{list} named ``mylist'' that
contains three elements.

\index{Redis list}
\index{Redis hash}

The method \java{jedis.lindex} takes an integer index and returns the
indicated element of a \redis{list}. Adding and accessing elements are
constant time operations.

Finally, Redis provides a \redis{hash} structure, which is similar to a Java
\java{Map<String, String>}. The method
\java{jedis.hset} adds a new entry to the \redis{hash}:

\begin{verbatim}
        jedis.hset("myhash", "word1", Integer.toString(2));
        String value = jedis.hget("myhash", "word1");
\end{verbatim}

This example creates a \redis{hash} named \java{myhash} that contains one
entry, which maps from the key \java{word1} to the value \java{"2"}.

The keys and values are \redis{string}s, so if we want to store
an \java{Integer}, we have to convert it to
a \java{String} before we call \java{hset}. 
And when we look up the value using \java{hget},
the result is a \java{String}, so we might have to convert it back
to \java{Integer}.

\index{field}

Working with Redis \redis{hash}es can be confusing, because we use a key to
identify which \redis{hash} we want, and then another key to identify a value in
the \redis{hash}. In the context of Redis, the second key is called a ``field'',
which might help keep things straight. So a ``key'' like \java{myhash}
identifies a particular \redis{hash}, and then a ``field'' like \java{word1}
identifies a value in the \redis{hash}.

For many applications, the values in a Redis \redis{hash} are integers, so Redis
provides a few special methods, like \java{hincrby}, that treat the
values as numbers:

\begin{verbatim}
        jedis.hincrBy("myhash", "word2", 1);
\end{verbatim}

This method accesses \java{myhash}, gets the current value associated
with \java{word2} (or 0 if it doesn't already exist), increments it by
1, and writes the result back to the \redis{hash}.

Setting, getting, and incrementing entries in a \redis{hash} are constant time
operations.

\index{constant time}
\index{Redis data type}

You can read more about Redis data types at
\url{http://thinkdast.com/redistypes}.


\section{Exercise 11}
\label{exercise11}

At this point you have the information you need to make a web search
index that stores results in a Redis database.

\index{JedisIndex}

Now run \java{ant JedisIndexTest}. It should
fail, because you have some work to do!

\java{JedisIndexTest} tests these methods:

\begin{itemize}

\item
  \java{JedisIndex}, which is the constructor that takes a
  \java{Jedis} object as a parameter.

\item
  \java{indexPage}, which adds a Web page to the index; it takes a
  \java{String} URL and a jsoup \java{Elements} object that contains the
  elements of the page that should be indexed.

\item
  \java{getCounts}, which takes a search term and returns a
  \java{Map<String, Integer>} that maps from
  each URL that contains the search term to the number of times it
  appears on that page.

\end{itemize}

Here's an example of how these methods are used:

\begin{verbatim}
        WikiFetcher wf = new WikiFetcher();
        String url1 = 
            "http://en.wikipedia.org/wiki/Java_(programming_language)";
        Elements paragraphs = wf.readWikipedia(url1);

        Jedis jedis = JedisMaker.make();
        JedisIndex index = new JedisIndex(jedis);
        index.indexPage(url1, paragraphs);
        Map<String, Integer> map = index.getCounts("the");
\end{verbatim}

If we look up \java{url1} in the result, \java{map}, we should get
339, which is the number of times the word ``the'' appears
on the Java Wikipedia page (that is, the version we saved).

\index{WikiFetcher}

If we index the same page again, the new results should replace the old
ones.

One suggestion for translating data structures from Java to Redis:
remember that each object in a Redis database is identified by a unique
key, which is a \redis{string}. If you have two kinds of objects in the same
database, you might want to add a prefix to the keys to distinguish
between them. For example, in our solution, we have two kinds of
objects:

\begin{itemize}

\item
  We define a \java{URLSet} to be a Redis \redis{set} that contains
  the URLs that contain a given search term. The key for each
  \java{URLSet} starts with \java{"URLSet:"}, so to get the URLs
  that contain the word ``the'', we access the \redis{set} with the key
  \java{"URLSet:the"}.

\item
  We define a \java{TermCounter} to be a Redis \redis{hash} that maps
  from each term that appears on a page to the number of times it
  appears. The key for each \java{TermCounter} starts with
  \java{"TermCounter:"} and ends with the URL of the page we're
  looking up.

\end{itemize}

\index{URLSet}
\index{TermCounter}

In my implementation,  there is one \java{URLSet} for each term and one
\java{TermCounter} for each indexed page. I provide two helper
methods, \java{urlSetKey} and \java{termCounterKey}, to assemble
these keys.

\index{helper method}


\section{More suggestions if you want them}
\label{more-suggestions-if-you-want-them}

At this point you have all the information you need to do the exercise, so
you can get started if you are ready. But I have a few suggestions you
might want to read first:

\begin{itemize}

\item
  For this exercise I provide less guidance than in previous
  exercises.  You will have to make some design decisions; in
  particular, you will have to figure out how to divide the problem
  into pieces that you can test one at a time, and then assemble the
  pieces into a complete solution. If you try to write the whole thing
  at once, without testing smaller pieces, it might take a very long
  time to debug.

\item
  One of the challenges of working with persistent data is that it is
  persistent. The structures stored in the database might change every
  time you run the program. If you mess something up in the database,
  you will have to fix it or start over before you can proceed. To help
  you keep things under control, I've provided methods called
  \java{deleteURLSets}, \java{deleteTermCounters}, and
  \java{deleteAllKeys}, which you can use to clean out the database
  and start fresh. You can also use \java{printIndex} to print the
  contents of the index.

\item
  Each time you invoke a \java{Jedis} method, your client sends a
  message to the server, then the server performs the action you
  requested and sends back a message. If you perform many small
  operations, it will probably take a long time. You can improve
  performance by grouping a series of operations into a
  \java{Transaction}.

\end{itemize}

For example, here's a simple version of \java{deleteAllKeys}:

\begin{verbatim}
    public void deleteAllKeys() {
        Set<String> keys = jedis.keys("*");
        for (String key: keys) {
            jedis.del(key);
        }
    }
\end{verbatim}

Each time you invoke \java{del} requires a round-trip from the client
to the server and back. If the index contains more than a few pages,
this method would take a long time to run. We can speed it up with a
\java{Transaction} object:

\index{server}

\begin{verbatim}
    public void deleteAllKeys() {
        Set<String> keys = jedis.keys("*");
        Transaction t = jedis.multi();
        for (String key: keys) {
            t.del(key);
        }
        t.exec();
    }
\end{verbatim}

\java{jedis.multi} returns a \java{Transaction} object, which
provides all the methods of a \java{Jedis} object. But when you invoke
a method on a \java{Transaction}, it doesn't run the operation
immediately, and it doesn't communicate with the server. It saves up a
batch of operations until you invoke \java{exec}. Then it sends all of
the saved operations to the server at the same time, which is usually
much faster.

\index{Transaction}



\section{A few design hints}
\label{a-few-design-hints}

Now you \emph{really} have all the information you need; you should
start working on the exercise. But if you get stuck, or if you really don't
know how to get started, you can come back for a few more hints.

\textbf{Don't read the following until you have run the test code, tried
out some basic Redis commands, and written a few methods in
\java{JedisIndex.java}}.

OK, if you are really stuck, here are some methods you might want to
work on:

\begin{verbatim}
    /**
     * Adds a URL to the set associated with term.
     */
    public void add(String term, TermCounter tc) {}

    /**
     * Looks up a search term and returns a set of URLs.
     */
    public Set<String> getURLs(String term) {}

    /**
     * Returns the number of times the given term appears at the given URL.
     */
    public Integer getCount(String url, String term) {}

    /**
     * Pushes the contents of the TermCounter to Redis.
     */
    public List<Object> pushTermCounterToRedis(TermCounter tc) {}
\end{verbatim}

These are the methods I used in my solution, but they are certainly
not the only way to divide things up. So please take these suggestions
if they help, but ignore them if they don't.

For each method, consider writing the tests first. When you figure out
how to test a method, you often get ideas about how to write it.

Good luck!



\chapter{Crawling Wikipedia}

In this chapter, I present a solution to the previous exercise and
analyze the performance of Web indexing algorithms. Then we build a
simple Web crawler.

\section{The Redis-backed indexer}
\label{redis-indexer}

\index{Redis}
\index{URLSet}
\index{TermCounter}

In my solution, we store two kinds of structures in Redis:

\begin{itemize}

\item
  For each search term, we have a \java{URLSet}, which is a Redis \redis{set}
  of URLs that contain the search term.

\item
  For each URL, we have a \java{TermCounter}, which is a Redis \redis{hash}
  that maps each search term to the number of times it appears.

\end{itemize}

We discussed these data types in the previous chapter. You can also
read about Redis structures at \url{http://thinkdast.com/redistypes}

\index{JedisIndex}

In \java{JedisIndex}, I provide a method that takes a search term
and returns the Redis key of its \java{URLSet}:

\begin{verbatim}
private String urlSetKey(String term) {
    return "URLSet:" + term;
}
\end{verbatim}

And a method that takes a URL and returns the Redis key of its
\java{TermCounter}:

\begin{verbatim}
private String termCounterKey(String url) {
    return "TermCounter:" + url;
}
\end{verbatim}

Here's the implementation of \java{indexPage}, which takes a URL and a
jsoup \java{Elements} object that contains the DOM tree of the
paragraphs we want to index:

\begin{verbatim}
public void indexPage(String url, Elements paragraphs) {
    System.out.println("Indexing " + url);

    // make a TermCounter and count the terms in the paragraphs
    TermCounter tc = new TermCounter(url);
    tc.processElements(paragraphs);

    // push the contents of the TermCounter to Redis
    pushTermCounterToRedis(tc);
}
\end{verbatim}

To index a page, we

\begin{enumerate}

\item
  Make a Java \java{TermCounter} for the contents of the page, using
  code from a previous exercise.

\item
  Push the contents of the \java{TermCounter} to Redis.

\end{enumerate}

Here's the new code that pushes a \java{TermCounter} to Redis:

\begin{verbatim}
public List<Object> pushTermCounterToRedis(TermCounter tc) {
    Transaction t = jedis.multi();

    String url = tc.getLabel();
    String hashname = termCounterKey(url);

    // if this page has already been indexed, delete the old hash
    t.del(hashname);

    // for each term, add an entry in the TermCounter and a new
    // member of the index
    for (String term: tc.keySet()) {
        Integer count = tc.get(term);
        t.hset(hashname, term, count.toString());
        t.sadd(urlSetKey(term), url);
    }
    List<Object> res = t.exec();
    return res;
}
\end{verbatim}

This method uses a \java{Transaction} to collect the operations and
send them to the server all at once, which is much faster than sending a
series of small operations.

\index{Transaction}

It loops through the terms in the \java{TermCounter}. For each one it

\begin{enumerate}

\item
  Finds or creates a \java{TermCounter} on Redis, then adds a field
  for the new term.

\item
  Finds or creates a \java{URLSet} on Redis, then adds the current
  URL.

\end{enumerate}

If the page has already been indexed, we delete its old
\java{TermCounter} before pushing the new contents.

That's it for indexing new pages.

\index{getCounts}

The second part of the exercise asked you to write \java{getCounts}, which
takes a search term and returns a map from each URL where the term
appears to the number of times it appears there. Here is my solution:

\begin{verbatim}
    public Map<String, Integer> getCounts(String term) {
        Map<String, Integer> map = new HashMap<String, Integer>();
        Set<String> urls = getURLs(term);
        for (String url: urls) {
            Integer count = getCount(url, term);
            map.put(url, count);
        }
        return map;
    }
\end{verbatim}

\index{helper method}
This method uses two helper methods:

\begin{itemize}

\item
  \java{getURLs} takes a search term and returns the Set of URLs where
  the term appears.

\item
  \java{getCount} takes a URL and a term and returns the number of
  times the term appears at the given URL.

\end{itemize}

Here are the implementations:

\begin{verbatim}
    public Set<String> getURLs(String term) {
        Set<String> set = jedis.smembers(urlSetKey(term));
        return set;
    }

    public Integer getCount(String url, String term) {
        String redisKey = termCounterKey(url);
        String count = jedis.hget(redisKey, term);
        return new Integer(count);
    }
\end{verbatim}

Because of the way we designed the index, these methods are simple and
efficient.


\section{Analysis of lookup}
\label{analysis-of-lookup}

Suppose we have indexed $N$ pages and discovered $M$
unique search terms. How long will it take to look up a search term?
Think about your answer before you continue.

\index{analysis}

To look up a search term, we run \java{getCounts}, which

\begin{enumerate}

\item
  Creates a map.

\item
  Runs \java{getURLs} to get a Set of URLs.

\item
  For each URL in the Set, runs \java{getCount} and adds an entry
  to a \java{HashMap}.

\end{enumerate}

\java{getURLs} takes time proportional to the number of URLs that
contain the search term. For rare terms, that might be a small number,
but for common terms it might be as large as $N$.

Inside the loop, we run \java{getCount}, which finds a
\java{TermCounter} on Redis, looks up a term, and adds an entry to a
HashMap. Those are all constant time operations, so the overall
complexity of \java{getCounts} is $O(N)$ in the worst case. However, in
practice the runtime is proportional to the number of pages that contain
the term, which is normally much less than $N$.

\index{constant time}
\index{linear time}

This algorithm is as efficient as it can be, in terms of
algorithmic complexity, but it is very slow because it sends many small
operations to Redis. You can make it faster using a
\java{Transaction}. You might want to do that as an exercise, or you
can see my solution in \java{RedisIndex.java}.

\index{Transaction}


\section{Analysis of indexing}
\label{analysis-of-indexing}

Using the data structures we designed, how long will it take to index a
page? Again, think about your answer before you continue.

\index{analysis}
\index{DOM tree}

To index a page, we traverse its DOM tree, find all the
\java{TextNode} objects, and split up the strings into search terms.
That all takes time proportional to the number of words on the page.

\index{HashMap}

For each term, we increment a counter in a HashMap, which is a constant
time operation. So making the \java{TermCounter} takes time
proportional to the number of words on the page.

\index{linear time}

Pushing the \java{TermCounter} to Redis requires deleting a
\java{TermCounter}, which is linear in the number of unique terms.
Then for each term we have to

\begin{enumerate}

\item
  Add an element to a \java{URLSet}, and

\item
  Add an element to a Redis \java{TermCounter}.

\end{enumerate}

Both of these are constant time operations, so the total time to push
the \java{TermCounter} is linear in the number of unique search terms.

\index{constant time}

In summary, making the \java{TermCounter} is proportional to the
number of words on the page. Pushing the \java{TermCounter} to Redis
is proportional to the number of unique terms.

\index{TermCounter}

Since the number of words on the page usually exceeds the number of
unique search terms, the overall complexity is proportional to the
number of words on the page. In theory a page might contain all search
terms in the index, so the worst case performance is $O(M)$, but we don't
expect to see the worse case in practice.

This analysis suggests a way to improve performance: we should probably
avoid indexing very common words. First of all, they take up a lot of
time and space, because they appear in almost every \java{URLSet} and
\java{TermCounter}. Furthermore, they are not very useful because they
don't help identify relevant pages.

\index{stop words}

Most search engines avoid indexing common words, which are known in this
context as stop words (\url{http://thinkdast.com/stopword}).


\section{Graph traversal}
\label{graph-traversal}

If you did the ``Getting to Philosophy'' exercise in
Chapter~\ref{getphilo}, you already have a program that reads a Wikipedia
page, finds the first link, uses the link to load the next page, and
repeats. This program is a specialized kind of crawler, but when
people say ``Web crawler'' they usually mean a program that

\begin{itemize}

\item
  Loads a starting page and indexes the contents,

\item
  Finds all the links on the page and adds the linked URLs to a collection,
  and

\item
  Works its way through the collection, loading pages, indexing them, and
  adding new URLs.

\item
  If it finds a URL that has already been indexed, it skips
  it.

\end{itemize}

You can think of the Web as a graph
where each page is a node and each link is a directed edge from one node
to another. If you are not familiar with graphs, you can read about
them at \url{http://thinkdast.com/graph}.

\index{graph}
\index{traversal}

Starting from a source node, a crawler traverses this graph,
visiting each reachable node once.

\index{queue}
\index{stack}
\index{FIFO}
\index{LIFO}

The collection we use to store the URLs determines what kind of
traversal the crawler performs:

\begin{itemize}

\item
  If it's a first-in-first-out (FIFO) queue, the crawler performs a
  breadth-first traversal.

\item
  If it's a last-in-first-out (LIFO) stack, the crawler performs a
  depth-first traversal.

\item
  More generally, the items in the collection might be prioritized. For
  example, we might want to give higher priority to pages that have not
  been indexed for a long time.

\end{itemize}

You can read more about graph traversal at
\url{http://thinkdast.com/graphtrav}.


\section{Exercise 12}
\label{exercise12}

\index{WikiCrawler}
\index{JedisIndex}

Now it's time to write the crawler.  In the repository for this book,
you'll find the source files for this exercise:

\begin{itemize}

\item \java{WikiCrawler.java}, which contains starter code for your
  crawler.

\item \java{WikiCrawlerTest.java}, which contains test code for
  \java{WikiCrawler}.

\item \java{JedisIndex.java}, which is my solution to the previous
  exercise.

\end{itemize}

\index{helper class}

You'll also need some of the helper classes we've used in previous
exercises:

\begin{itemize}
\item  \java{JedisMaker.java}
\item  \java{WikiFetcher.java}
\item  \java{TermCounter.java}
\item  \java{WikiNodeIterable.java}
\end{itemize}

Before you run \java{JedisMaker}, you have to provide a file with
information about your Redis server. If you did this in the previous
exercise, you should be all set. Otherwise you can find instructions in
Section~\ref{hello-jedis}.

\index{JedisMaker}
\index{Ant}

Run \java{ant build} to compile the source files, then run
\java{ant JedisMaker} to make sure it is configured to connect to your
Redis server.

Now run \java{ant WikiCrawlerTest}. It should
fail, because you have work to do!

Here's the beginning of the \java{WikiCrawler} class I provided:

\begin{verbatim}
public class WikiCrawler {

    public final String source;
    private JedisIndex index;
    private Queue<String> queue = new LinkedList<String>();
    final static WikiFetcher wf = new WikiFetcher();

    public WikiCrawler(String source, JedisIndex index) {
        this.source = source;
        this.index = index;
        queue.offer(source);
    }

    public int queueSize() {
        return queue.size();
    }
}
\end{verbatim}

The instance variables are

\begin{itemize}

\item
  \java{source} is the URL where we start crawling.

\item
  \java{index} is the \java{JedisIndex} where the results should go.

\item
  \java{queue} is a \java{LinkedList} where we keep track of URLs
  that have been discovered but not yet indexed.

\item
  \java{wf} is the \java{WikiFetcher} we'll use to read and parse
  Web pages.

\end{itemize}

Your job is to fill in \java{crawl}. Here's the prototype:

\index{crawl}

\begin{verbatim}
    public String crawl(boolean testing) throws IOException {}
\end{verbatim}

The parameter \java{testing} will be \java{true} when this method is
called from \java{WikiCrawlerTest} and should be \java{false}
otherwise.

When \java{testing} is \java{true}, the \java{crawl} method should:

\begin{itemize}

\item
  Choose and remove a URL from the queue in FIFO order.

\item
  Read the contents of the page using
  \java{WikiFetcher.readWikipedia}, which reads cached copies of pages
  included in the repository for testing purposes (to avoid
  problems if the Wikipedia version changes).

\item
  It should index pages regardless of whether they are already indexed.

\item
  It should find all the internal links on the page and add them to the
  queue in the order they appear. ``Internal links'' are links to other
  Wikipedia pages.

\item
  And it should return the URL of the page it indexed.

\end{itemize}

When \java{testing} is \java{false}, this method should:

\begin{itemize}

\item
  Choose and remove a URL from the queue in FIFO order.

\item
  If the URL is already indexed, it should not index it again, and
  should return \java{null}.

\item
  Otherwise it should read the contents of the page using
  \java{WikiFetcher.fetchWikipedia}, which reads current content from
  the Web.

\item
  Then it should index the page, add links to the queue, and return the
  URL of the page it indexed.

\end{itemize}

\java{WikiCrawlerTest} loads the queue with about 200 links and then
invokes \java{crawl} three times. After each invocation, it checks the
return value and the new length of the queue.

When your crawler is working as specified, this test should pass. Good
luck!



\chapter{Boolean search}

In this chapter I present a solution to the previous exercise. Then
you will write code to combine multiple search results and sort them
by their relevance to the search terms.


\section{Crawler solution}
\label{crawler-solution}

First, let's go over our solution to the previous exercise. I provided an
outline of \java{WikiCrawler}; your job was to fill in \java{crawl}.
As a reminder, here are the fields in the \java{WikiCrawler} class:

\index{WikiCrawler}

\begin{verbatim}
public class WikiCrawler {
    // keeps track of where we started
    private final String source;

    // the index where the results go
    private JedisIndex index;

    // queue of URLs to be indexed
    private Queue<String> queue = new LinkedList<String>();

    // fetcher used to get pages from Wikipedia
    final static WikiFetcher wf = new WikiFetcher();
}
\end{verbatim}

When we create a \java{WikiCrawler}, we provide \java{source} and
\java{index}. Initially, \java{queue} contains only one element,
\java{source}.

\index{queue}
\index{LinkedList}

Notice that the implementation of \java{queue} is a
\java{LinkedList}, so we can add elements at the end --- and remove
them from the beginning --- in constant time. By assigning a
\java{LinkedList} object to a \java{Queue} variable, we limit
ourselves to using methods in the \java{Queue} interface; specifically,
we'll use \java{offer} to add elements and \java{poll} to remove
them.

\index{constant time}

Here's my implementation of \java{WikiCrawler.crawl}:

\begin{verbatim}
    public String crawl(boolean testing) throws IOException {
        if (queue.isEmpty()) {
            return null;
        }
        String url = queue.poll();
        System.out.println("Crawling " + url);

        if (testing==false && index.isIndexed(url)) {
            System.out.println("Already indexed.");
            return null;
        }

        Elements paragraphs;
        if (testing) {
            paragraphs = wf.readWikipedia(url);
        } else {
            paragraphs = wf.fetchWikipedia(url);
        }
        index.indexPage(url, paragraphs);
        queueInternalLinks(paragraphs);
        return url;
    }
\end{verbatim}

Most of the complexity in this method is there to make it easier to
test. Here's the logic:

\begin{itemize}

\item
  If the queue is empty, it returns \java{null} to indicate that it
  did not index a page.

\item
  Otherwise it removes and stores the next URL from the queue.

\item
  If the URL has already been indexed, \java{crawl} doesn't index it
  again, unless it's in testing mode.

\item
  Next it reads the contents of the page: if it's in testing mode, it
  reads from a file; otherwise it reads from the Web.

\item
  It indexes the page.

\item
  It parses the page and adds internal links to the queue.

\item
  Finally, it returns the URL of the page it indexed.

\end{itemize}

I presented an implementation of \java{Index.indexPage} in
Section~\ref{redis-indexer}. So the only new method is
\java{WikiCrawler.queueInternalLinks}.

\index{Index}

I wrote two versions of this method with different parameters: one
takes an \java{Elements} object containing one DOM tree per
paragraph; the other takes an \java{Element} object that contains a
single paragraph.

\index{Element}

The first version just loops through the paragraphs. The second version
does the real work.

\begin{verbatim}
    void queueInternalLinks(Elements paragraphs) {
        for (Element paragraph: paragraphs) {
            queueInternalLinks(paragraph);
        }
    }

    private void queueInternalLinks(Element paragraph) {
        Elements elts = paragraph.select("a[href]");
        for (Element elt: elts) {
            String relURL = elt.attr("href");

            if (relURL.startsWith("/wiki/")) {
                String absURL = elt.attr("abs:href");
                queue.offer(absURL);
            }
        }
    }
\end{verbatim}


To determine whether a link is ``internal,'' we check whether the URL
starts with ``/wiki/''. This might include some pages we don't want to
index, like meta-pages about Wikipedia. And it might exclude some pages
we want, like links to pages in non-English languages. But this simple
test is good enough to get started.

\index{Wikipedia}

That's all there is to it. This exercise doesn't have a lot of new material;
it is mostly a chance to bring the pieces together.


\section{Information retrieval}
\label{information-retrieval}

\index{information retrieval}

The next phase of this project is to implement a search tool. The pieces
we'll need include:

\begin{enumerate}

\item
  An interface where users can provide search terms and view results.

\item
  A lookup mechanism that takes each search term and returns the pages
  that contain it.

\item
  Mechanisms for combining search results from multiple search terms.

\item
  Algorithms for ranking and sorting search results.

\end{enumerate}

The general term for processes like this is ``information retrieval'',
which you can read more about at 
\url{http://thinkdast.com/infret}.

In this exercise, we'll focus on steps 3 and 4. We've already built a simple
version of 2. If you are interested in building Web applications, you
might consider working on step 1.


\section{Boolean search}
\label{boolean-search}

\index{boolean search}

Most search engines can perform ``boolean searches'', which means you
can combine the results from multiple search terms using boolean logic.
For example:

\begin{itemize}

\item
  The search ``java AND programming'' might return only pages that
  contain both search terms: ``java'' and ``programming''.

\item
  ``java OR programming'' might return pages that contain either term
  but not necessarily both.

\item
  ``java -indonesia'' might return pages that contain ``java'' and do
  not contain ``indonesia''.

\end{itemize}

Expressions like these that contain search terms and operators are
called ``queries''.

\index{query}

When applied to search results, the boolean operators \java{AND},
\java{OR}, and \java{-} correspond to the set operations
\java{intersection}, \java{union}, and \java{difference}. For
example, suppose

\begin{itemize}

\item
  \java{s1} is the set of pages containing ``java'',

\item
  \java{s2} is the set of pages containing ``programming'', and

\item
  \java{s3} is the set of pages containing ``indonesia''.

\end{itemize}

In that case:

\begin{itemize}

\item
  The intersection of \java{s1} and \java{s2} is the set of pages
  containing ``java'' AND ``programming''.

\item
  The union of \java{s1} and \java{s2} is the set of pages
  containing ``java'' OR ``programming''.

\item
  The difference of \java{s1} and \java{s2} is the set of pages
  containing ``java'' and not ``indonesia''.
\end{itemize}

In the next section you will write a method to implement these operations.

\index{intersection}
\index{union}
\index{difference}
\index{set operations}


\section{Exercise 13}
\label{exercise13}

In the repository for this book
you'll find the source files for this exercise:

\begin{itemize}

\item
  \java{WikiSearch.java}, which defines an object that contains search
  results and performs operations on them.

\item
  \java{WikiSearchTest.java}, which contains test code for
  \java{WikiSearch}.

\item
  \java{Card.java}, which demonstrates how to use the \java{sort}
  method in \java{java.util.Collections}.

\end{itemize}

You will also find some of the helper classes we've used in previous
exercises.

\index{WikiSearch}
\index{helper class}

Here's the beginning of the \java{WikiSearch} class definition:

\begin{verbatim}
public class WikiSearch {

    // map from URLs that contain the term(s) to relevance score
    private Map<String, Integer> map;

    public WikiSearch(Map<String, Integer> map) {
        this.map = map;
    }

    public Integer getRelevance(String url) {
        Integer relevance = map.get(url);
        return relevance==null ? 0: relevance;
    }
}
\end{verbatim}

A \java{WikiSearch} object contains a map from URLs to their relevance
score. In the context of information retrieval, a ``relevance score'' is
a number intended to indicate how well a page meets the needs of the
user as inferred from the query. There are many ways to construct a
relevance score, but most of them are based on ``term frequency'', which
is the number of times the search terms appear on the page. A common
relevance score is called TF-IDF, which stands for ``term frequency --
inverse document frequency''.  You can read more about it at
\url{http://thinkdast.com/tfidf}.

\index{relevance}
\index{term frequency}
\index{inverse document frequency}
\index{TF-IDF}

You'll have the option to implement TF-IDF later, but we'll start with
something even simpler, TF:

\begin{itemize}

\item
  If a query contains a single search term, the relevance of a page is
  its term frequency; that is, the number of time the term appears on
  the page.

\item
  For queries with multiple terms, the relevance of a page is the sum of
  the term frequencies; that is, the total number of times any of the
  search terms appear.

\end{itemize}

Now you're ready to start the exercise.
Run \java{ant build} to compile the source files, then run
\java{ant WikiSearchTest}. As usual, it should
fail, because you have work to do.

\index{Ant}

In \java{WikiSearch.java}, fill in the bodies of \java{and},
\java{or}, and \java{minus} so that the relevant tests pass. You
don't have to worry about \java{testSort} yet.

\index{and}
\index{or}
\index{minus}

You can run \java{WikiSearchTest} without using Jedis because it
doesn't depend on the index in your Redis database. But if you want to
run a query against your index, you have to provide a file with
information about your Redis server.  See Section~\ref{hello-jedis}
for details.

\index{JedisMaker}

Run \java{ant JedisMaker} to make sure it is configured to connect to
your Redis server. Then run \java{WikiSearch}, which prints results
from three queries:

\begin{itemize}

\item
  ``java''

\item
  ``programming''

\item
  ``java AND programming''

\end{itemize}

Initially the results will be in no particular order, because
\java{WikiSearch.sort} is incomplete.

\index{sort}
\index{Collections}

Fill in the body of \java{sort} so the results are returned in
increasing order of relevance. I suggest you use the \java{sort}
method provided by \java{java.util.Collections}, which sorts any kind of
\java{List}. You can read the documentation at
\url{http://thinkdast.com/collections}.

There are two versions of \java{sort}:

\begin{itemize}

\item
  The one-parameter version takes a list and sorts the elements using
  the \java{compareTo} method, so the elements have to be
  \java{Comparable}.

\item
  The two-parameter version takes a list of any object type and a
  \java{Comparator}, which is an object that provides a
  \java{compare} method that compares elements.

\end{itemize}

\index{Comparable}
\index{Comparator}

If you are not familiar with the \java{Comparable} and
\java{Comparator} interfaces, I explain them in the next section.


\section{{\tt Comparable} and {\tt Comparator}}
\label{comparable-and-comparator}

\index{Card}

The repository for this book includes \java{Card.java}, which
demonstrates two ways to sort a list of \java{Card} objects. Here's
the beginning of the class definition:

\begin{verbatim}
public class Card implements Comparable<Card> {

    private final int rank;
    private final int suit;

    public Card(int rank, int suit) {
        this.rank = rank;
        this.suit = suit;
    }
\end{verbatim}

A \java{Card} object has two integer fields, \java{rank} and
\java{suit}. \java{Card} implements
\java{Comparable<Card>}, which means that it
provides \java{compareTo}:

\begin{verbatim}
    public int compareTo(Card that) {
        if (this.suit < that.suit) {
            return -1;
        }
        if (this.suit > that.suit) {
            return 1;
        }
        if (this.rank < that.rank) {
            return -1;
        }
        if (this.rank > that.rank) {
            return 1;
        }
        return 0;
    }
\end{verbatim}

\index{compareTo}

The specification of \java{compareTo} indicates that it should return
a negative number if \java{this} is considered less than
\java{that}, a positive number if it is considered greater, and 0 if
they are considered equal.

If you use the one-parameter version of \java{Collections.sort}, it
uses the \java{compareTo} method provided by the elements to sort
them. To demonstrate, we can make a list of 52 cards like this:

\begin{verbatim}
    public static List<Card> makeDeck() {
        List<Card> cards = new ArrayList<Card>();
        for (int suit = 0; suit <= 3; suit++) {
            for (int rank = 1; rank <= 13; rank++) {
                Card card = new Card(rank, suit);
                cards.add(card);
            }
        }
        return cards;
    }
\end{verbatim}

And sort them like this:

\begin{verbatim}
        Collections.sort(cards);
\end{verbatim}

This version of \java{sort} puts the elements in what's called their
``natural order'' because it's determined by the objects themselves.

\index{natural order}
\index{Comparator}
\index{compare}

But it is possible to impose a different ordering by providing a
\java{Comparator} object. For example, the natural order of
\java{Card} objects treats Aces as the lowest rank, but in some card
games they have the highest rank. We can define a \java{Comparator}
that considers ``Aces high'', like this:

\begin{verbatim}
        Comparator<Card> comparator = new Comparator<Card>() {
            @Override
            public int compare(Card card1, Card card2) {
                if (card1.getSuit() < card2.getSuit()) {
                    return -1;
                }
                if (card1.getSuit() > card2.getSuit()) {
                    return 1;
                }
                int rank1 = getRankAceHigh(card1);
                int rank2 = getRankAceHigh(card2);

                if (rank1 < rank2) {
                    return -1;
                }
                if (rank1 > rank2) {
                    return 1;
                }
                return 0;
            }

            private int getRankAceHigh(Card card) {
                int rank = card.getRank();
                if (rank == 1) {
                    return 14;
                } else {
                    return rank;
                }
            }
        };
\end{verbatim}

This code defines an anonymous class that implements \java{compare},
as required. Then it creates an instance of the newly-defined, unnamed
class. If you are not familiar with anonymous classes in Java, you can
read about them at \url{http://thinkdast.com/anonclass}.

\index{anonymous class}

Using this \java{Comparator}, we can invoke \java{sort} like this:

\begin{verbatim}
        Collections.sort(cards, comparator);
\end{verbatim}

In this ordering, the Ace of Spades is considered the highest class in
the deck; the two of Clubs is the lowest.

\index{ordering}

The code in this section is in \java{Card.java} if you want to
experiment with it. As an exercise, you might want to write a comparator
that sorts by \java{rank} first and then by \java{suit}, so all the
Aces should be together, and all the twos, etc.


\section{Extensions}
\label{extensions}

\index{TF-IDF}
\index{relevance}
\index{snippet}
\index{Heroku}

If you get a basic version of this exercise working, you might want to work
on these optional exercises:

\begin{itemize}

\item Read about TF-IDF at \url{http://thinkdast.com/tfidf}
  and implement it. You might have to modify \java{JavaIndex} to
  compute document frequencies; that is, the total number of times
  each term appears on all pages in the index.

\item For queries with more than one search term, the total relevance for
  each page is currently the sum of the relevance for each term. Think
  about when this simple version might not work well, and try out some
  alternatives.

\item Build a user interface that allows users to enter queries with
  boolean operators. Parse the queries, generate the results, then
  sort them by relevance and display the highest-scoring
  URLs. Consider generating ``snippets'' that show where the search
  terms appeared on the page. If you want to make a Web application
  for your user interface, consider using Heroku as a simple option
  for developing and deploying Web applications using Java.  See
  \url{http://thinkdast.com/heroku}.

\end{itemize}



\chapter{Sorting}

Computer science departments have an unhealthy obsession with sort
algorithms. Based on the amount of time CS students spend on the topic,
you would think that choosing sort algorithms is the cornerstone of
modern software engineering. Of course, the reality is that software
developers can go years, or entire careers, without thinking about how
sorting works. For almost all applications, they use whatever
general-purpose algorithm is provided by the language or libraries they
use. And usually that's just fine.

\index{sorting}

So if you skip this chapter and learn nothing about sort algorithms,
you can still be an excellent developer. But there are a few reasons
you might want to do it anyway:

\begin{enumerate}

\item
  Although there are general-purpose algorithms that work well for the
  vast majority of applications, there are two special-purpose
  algorithms you might need to know about: radix sort and bounded heap
  sort.

\item
  One sort algorithm, merge sort, makes an excellent teaching example
  because it demonstrates an important and useful strategy for
  algorithm design, called ``divide-conquer-glue''. Also, when we
  analyze its performance, you will learn about an order of growth we
  have not seen before, {\bf linearithmic}. Finally, some of the most
  widely-used algorithms are hybrids that include elements of merge
  sort.

\item
  One other reason to learn about sort algorithms is that technical
  interviewers love to ask about them. If you want to get hired, it
  helps if you can demonstrate CS cultural literacy.

\end{enumerate}

So, in this chapter we'll analyze insertion sort, you will implement merge
sort, I'll tell you about radix sort, and you will write a simple
version of a bounded heap sort.

\index{divide-conquer-glue}
\index{linearithmic time}


\section{Insertion sort}
\label{insertion-sort}

We'll start with insertion sort, mostly because it is simple to describe
and implement. It is not very efficient, but it has some redeeming
qualities, as we'll see.

\index{insertion sort}

Rather than explain the algorithm here, I suggest you read the
insertion sort Wikipedia page at
\url{http://thinkdast.com/insertsort}, which includes
pseudocode and animated examples. Come back when you get the general
idea.

Here's an implementation of insertion sort in Java:

\begin{verbatim}
public class ListSorter<T> {

    public void insertionSort(List<T> list, Comparator<T> comparator) {

        for (int i=1; i < list.size(); i++) {
            T elt_i = list.get(i);
            int j = i;
            while (j > 0) {
                T elt_j = list.get(j-1);
                if (comparator.compare(elt_i, elt_j) >= 0) {
                    break;
                }
                list.set(j, elt_j);
                j--;
            }
            list.set(j, elt_i);
        }
    }
}
\end{verbatim}

I define a class, \java{ListSorter}, as a container for sort
algorithms. By using the type parameter, \java{T}, we can write
methods that work on lists containing any object type.

\index{ListSorter}
\index{type parameter}

\java{insertionSort} takes two parameters, a \java{List} of any kind
and a \java{Comparator} that knows how to compare type \java{T}
objects. It sorts the list ``in place'', which means it modifies the
existing list and does not have to allocate any new space.

\index{List}

The following example shows how to call this method with a \java{List} of
\java{Integer} objects:

\begin{verbatim}
        List<Integer> list = new ArrayList<Integer>(
            Arrays.asList(3, 5, 1, 4, 2));

        Comparator<Integer> comparator = new Comparator<Integer>() {
            @Override
            public int compare(Integer elt1, Integer elt2) {
                return elt1.compareTo(elt2);
            }
        };

        ListSorter<Integer> sorter = new ListSorter<Integer>();
        sorter.insertionSort(list, comparator);
        System.out.println(list);
\end{verbatim}

\java{insertionSort} has two nested loops, so you might guess that
its runtime is quadratic. In this case, that turns out to be correct,
but before you jump to that conclusion, you have to check that the
number of times each loop runs is proportional to $n$, the size
of the array.

\index{linear time}

The outer loop iterates from 1 to \java{list.size()}, so it is linear
in the size of the list, $n$.
The inner loop iterates from \java{i} to 0, so it is also linear in $n$.
Therefore, the total number of times the inner loop runs is quadratic.

\index{quadratic time}

If you are not sure about that, here's the argument:

\begin{itemize}

\item
  The first time through, $i=1$ and the inner loop runs at most
  once.

\item
  The second time, $i=2$ and the inner loop runs at most twice.

\item
  The last time, $i=n-1$ and the inner loop runs at most
  $n-1$ times.

\end{itemize}

So the total number of times the inner loop runs is the sum of the
series $1, 2, \ldots , n-1$, which is $n (n-1) / 2$. And the
leading term of that expression (the one with the highest exponent) is
$n^2$.

\index{linear time}

In the worst case, insertion sort is quadratic. However:

\begin{enumerate}

\item
  If the elements are already sorted, or nearly so, insertion sort is
  linear. Specifically, if each element is no more than $k$
  locations away from where it should be, the inner loop never runs more
  than $k$ times, and the total runtime is $O(kn)$.

\item
  Because the implementation is simple, the overhead is low; that is,
  although the runtime is $a n^2$, the coefficient of the leading
  term, $a$, is probably small.

\end{enumerate}

So if we know that the array is nearly sorted, or is not very big,
insertion sort might be a good choice. But for large arrays, we can
do better. In fact, much better.


\section{Exercise 14}
\label{exercise14}

Merge sort is one of several algorithms whose runtime is better than
quadratic. Again, rather than explaining the algorithm here, I suggest
you read about it on Wikipedia at
\url{http://thinkdast.com/mergesort}.  Once you get the idea, come
back and you can test your understanding by writing an implementation.

\index{merge sort}
\index{quadratic time}

In the repository for this book, you'll find the source files for this
exercise:

\begin{itemize}

\item
  \java{ListSorter.java}

\item
  \java{ListSorterTest.java}

\end{itemize}

Run \java{ant build} to compile the source files, then run
\java{ant ListSorterTest}. As usual, it should
fail, because you have work to do.

\index{Ant}
\index{ListSorter}

In \java{ListSorter.java}, I've provided an outline of two methods,
\java{mergeSortInPlace} and \java{mergeSort}:

\begin{verbatim}
    public void mergeSortInPlace(List<T> list, Comparator<T> comparator) {
        List<T> sorted = mergeSortHelper(list, comparator);
        list.clear();
        list.addAll(sorted);
    }

    private List<T> mergeSort(List<T> list, Comparator<T> comparator) {
       // TODO: fill this in!
       return null;
    }
\end{verbatim}

These two methods do the same thing but provide different interfaces.
\java{mergeSort} takes a list and returns a new list with the same
elements sorted in ascending order. \java{mergeSortInPlace} is a
\java{void} method that modifies an existing list.

\index{mergeSort}

Your job is to fill in \java{mergeSort}. Before you write a fully
recursive version of merge sort, start with something like this:

\begin{enumerate}

\item
  Split the list in half.

\item
  Sort the halves using \java{Collections.sort} or
  \java{insertionSort}.

\item
  Merge the sorted halves into a complete sorted list.

\end{enumerate}

This will give you a chance to debug the merge code without dealing with
the complexity of a recursive method.

\index{base case}
\index{recursion}

Next, add a base case (see
\url{http://thinkdast.com/basecase}). If you are
given a list with only one element, you could return it immediately,
since it is already sorted, sort of. Or if the length of the list is
below some threshold, you could sort it using \java{Collections.sort}
or \java{insertionSort}. Test the base case before you proceed.

Finally, modify your solution so it makes two recursive calls to sort
the halves of the array. When you get it working, \java{testMergeSort}
and \java{testMergeSortInPlace} should pass.


\section{Analysis of merge sort}
\label{analysis-of-merge-sort}

\index{analysis}

To classify the runtime of merge sort, it helps to think in terms of
levels of recursion and how much work is done on each level. Suppose
we start with a list that contains $n$ elements. Here are the steps of
the algorithm:

\begin{enumerate}

\item
  Make two new arrays and copy half of the elements into each.

\item
  Sort the two halves.

\item
  Merge the halves.

\end{enumerate}

Figure~\ref{fig-sort1}
shows these steps.

\begin{figure}
\centering
\includegraphics[height=2.5in]{figs/merge_sort1.pdf}
\caption{Representation of merge sort showing one level of recursion.}
\label{fig-sort1}
\end{figure}

\index{linear time}

The first step copies each of the elements once, so it is linear. The
third step also copies each element once, so it is also linear. Now we
need to figure out the complexity of step 2. To do that, it helps to
looks at a different picture of the computation, which shows the levels
of recursion, as in Figure~\ref{fig-sort2}.

\begin{figure}
\centering
\includegraphics[height=2in]{figs/merge_sort2.pdf}
\caption{Representation of merge sort showing all levels of recursion.}
\label{fig-sort2}
\end{figure}

At the top level, we have $1$ list with $n$ elements. 
For simplicity, let's assume $n$ is a power of 2.
At the next level there are $2$ lists with $n/2$ elements.
Then $4$ lists with $n/4$ elements, and so on until we get
to $n$ lists with $1$ element.

On every level we have a total of $n$ elements. On the way down,
we have to split the arrays in half, which takes time proportional to
$n$ on every level. On the way back up, we have to merge a total
of $n$ elements, which is also linear.

If the number of levels is $h$, the total amount of work for the
algorithm is $O(nh)$. So how many levels are there? There are two
ways to think about that:

\begin{enumerate}

\item
  How many times do we have to cut $n$ in half to get to 1?

\item
   Or, how many times do we have to double $1$ before we get to $n$?

\end{enumerate}

Another way to ask the second question is ``What power of 2 is
$n$?''

$2^h = n$

Taking the $\log_2$ of both sides yields

$h = \log_2 n$

So the total time is $O(n \log n)$. I didn't bother to write the
base of the logarithm because logarithms with different bases differ by
a constant factor, so all logarithms are in the same order of growth.

\index{logarithm}
\index{linearithmic time}
\index{n log n}

Algorithms in $O(n \log n)$ are sometimes called
``linearithmic'', but most people just say ``n log n''.

\index{comparison sort}

It turns out that $O(n \log n)$ is the theoretical lower bound for
sort algorithms that work by comparing elements to each other. That
means there is no ``comparison sort'' whose order of growth is better
than $n \log n$.  See \url{http://thinkdast.com/compsort}.

But as we'll see in the next section, there are non-comparison sorts
that take linear time!

\index{linear time}


\section{Radix sort}
\label{radix-sort}

\index{radix sort}
\index{Obama, Barack}
\index{Schmidt, Eric}
\index{Google}
\index{bubble sort}

During the 2008 United States Presidential Campaign, candidate Barack
Obama was asked to perform an impromptu algorithm analysis when he
visited Google. Chief executive Eric Schmidt jokingly asked him for
``the most efficient way to sort a million 32-bit integers.'' Obama
had apparently been tipped off, because he quickly replied, ``I think
the bubble sort would be the wrong way to go.'' You can watch the
video at \url{http://thinkdast.com/obama}.

Obama was right: bubble sort is conceptually simple but its runtime is
quadratic; and even among quadratic sort algorithms, its performance
is not very good.  See \url{http://thinkdast.com/bubble}.

\index{quadratic time}

The answer Schmidt was probably looking for is ``radix sort'', which is
a {\bf non-comparison} sort algorithm that works if the size of the
elements is bounded, like a 32-bit integer or a 20-character string.

\index{non-comparison sort}

To see how this works, imagine you have a stack of index cards where
each card contains a three-letter word. Here's how you could sort the
cards:

\begin{enumerate}

\item
  Make one pass through the cards and divide them into buckets based on
  the first letter. So words starting with \java{a} should be
  in one bucket, followed by words starting with \java{b}, and so on.

\item
  Divide each bucket again based on the second letter. So words starting
  with \java{aa} should be together, followed by words starting with
  \java{ab}, and so on. Of course, not all buckets will be full, but
  that's OK.

\item
  Divide each bucket again based on the third letter.

\end{enumerate}

At this point each bucket contains one element, and the buckets are
sorted in ascending order. Figure~\ref{fig-sort3}
shows an example with
three-letter words.

\begin{figure}
\centering
\includegraphics[height=2.0in]{figs/radix_sort1.pdf}
\caption{Example of radix sort with three-letter words.}
\label{fig-sort3}
\end{figure}

The top row shows the unsorted words. The second row shows what the
buckets look like after the first pass. The words in each bucket begin
with the same letter.

After the second pass, the words in each bucket begin with the same two
letters. After the third pass, there can be only one word in each
bucket, and the buckets are in order.

During each pass, we iterate through the elements and add them to
buckets. As long as the buckets allow addition in constant time, each
pass is linear.

\index{constant time}
\index{linear time}

The number of passes, which I'll call $w$, depends on the ``width''
of the words, but it doesn't depend on the number of words, $n$.
So the order of growth is $O(wn)$, which is linear in $n$.

There are many variations on radix sort, and many ways to implement
each one. You can read more about them at
\url{http://thinkdast.com/radix}. As an optional
exercise, consider writing a version of radix sort.


\section{Heap sort}
\label{heap-sort}

\index{heap sort}
\index{bounded heap}

In addition to radix sort, which applies when the things you want to
sort are bounded in size, there is one other special-purpose sorting
algorithm you might encounter: bounded heap sort. Bounded heap sort is
useful if you are working with a very large dataset and you want to
report the ``Top 10'' or ``Top k'' for some value of $k$ much
smaller than $n$.

For example, suppose you are monitoring a Web service that handles a
billion transactions per day. At the end of each day, you want to
report the $k$ biggest transactions (or slowest, or any other
superlative). One option is to store all transactions, sort them at
the end of the day, and select the top $k$. That would take time
proportional to $n \log n$, and it would be very slow because we
probably can't fit a billion transactions in the memory of a single
program. We would have to use an ``out of core'' sort algorithm. You
can read about external sorting at \url{http://thinkdast.com/extsort}.

\index{out of core algorithm}
\index{external sorting}

Using a bounded heap, we can do much better! Here's how we will
proceed:

\begin{enumerate}

\item
  I'll explain (unbounded) heap sort.

\item
  You'll implement it.

\item
  I'll explain bounded heap sort and analyze it.

\end{enumerate}

\index{heap}
\index{binary search tree}
\index{BST}

To understand heap sort, you have to understand a heap, which is a data
structure similar to a binary search tree (BST). Here are the differences:

\begin{itemize}

\item
  In a BST, every node, \java{x}, has the ``BST property'': all nodes
  in the left subtree of \java{x} are less than \java{x} and all
  nodes in the right subtree are greater than \java{x}.

\item
  In a heap, every node, \java{x}, has the ``heap property'': all
  nodes in both subtrees of \java{x} are greater than \java{x}.

\item
  Heaps are like balanced BSTs; when you add or remove elements, they
  do some extra work to rebalance the tree.  As a result, they can
  be implemented efficiently using an array of elements.

\end{itemize}

The smallest element in a heap is always at the root, so we can find
it in constant time. Adding and removing elements from a heap takes
time proportional to the height of the tree $h$. And because the heap
is always balanced, $h$ is proportional to $\log n$.  You can read
more about heaps at \url{http://thinkdast.com/heap}.

\index{heap property}
\index{constant time}
\index{logarithmic time}
\index{PriorityQueue}
\index{offer}
\index{poll}
\index{Queue}

The Java \java{PriorityQueue} is implemented using a heap.
\java{PriorityQueue} provides the methods specified in the
\java{Queue} interface, including \java{offer} and \java{poll}:

\begin{itemize}

\item
  \java{offer}: Adds an element to the queue, updating the heap so
  that every node has the ``heap property''. Takes $\log n$ time.

\item
  \java{poll}: Removes the smallest element in the queue from the root
  and updates the heap. Takes $\log n$ time.

\end{itemize}

Given a \java{PriorityQueue}, you can easily sort of a collection of
$n$ elements like this:

\begin{enumerate}

\item
  Add all elements of the collection to a \java{PriorityQueue} using
  \java{offer}.

\item
  Remove the elements from the queue using \java{poll} and add them to
  a \java{List}.

\end{enumerate}

Because \java{poll} returns the smallest element remaining in the
queue, the elements are added to the \java{List} in ascending order.
This way of sorting is called {\bf heap sort}
(see \url{http://thinkdast.com/heapsort}).

\index{heap sort}
\index{linearithmic}
\index{n log n}

Adding $n$ elements to the queue takes $n \log n$ time. So
does removing $n$ elements. So the runtime for heap sort is
$O(n \log n)$.

\index{ListSorter}

In the repository for this book, in \java{ListSorter.java} you'll find
the outline of a method called \java{heapSort}. Fill it in and then
run \java{ant ListSorterTest} to confirm that it works.


\section{Bounded heap}
\label{bounded-heap}

\index{bounded heap}

A bounded heap is a heap that is limited to contain at most $k$
elements. If you have $n$ elements, you can keep track of the
$k$ largest elements like this:

Initially, the heap is empty.  For each element, \java{x}:

\begin{itemize}

\item
  Branch 1: If the heap is not full, add \java{x} to the heap.

\item
  Branch 2: If the heap is full, compare \java{x} to the
  \emph{smallest} element in the heap. If \java{x} is smaller, it
  cannot be one of the largest $k$ elements, so you can discard
  it.

\item
  Branch 3: If the heap is full and \java{x} is greater than the
  smallest element in the heap, remove the smallest element from the
  heap and add \java{x}.

\end{itemize}

\index{k largest elements}

Using a heap with the smallest element at the top, we can keep track of
the largest $k$ elements. Let's analyze the performance of this
algorithm. For each element, we perform one of:

\begin{itemize}

\item
  Branch 1: Adding an element to the heap is $O(\log k)$.

\item
  Branch 2: Finding the smallest element in the heap is $O(1)$.

\item
  Branch 3: Removing the smallest element is $O(\log k)$. Adding
  \java{x} is also $O(\log k)$.

\end{itemize}

In the worst case, if the elements appear in ascending order, we always
run Branch 3. In that case, the total time to process $n$
elements is $O(n \log k)$, which is linear in $n$.

\index{linear time}

In \java{ListSorter.java} you'll find the outline of a method called
\java{topK} that takes a \java{List}, a \java{Comparator}, and an
integer $k$. It should return the $k$ largest elements in the
\java{List} in ascending order. Fill it in and then run \java{ant
  ListSorterTest} to confirm that it works.

\index{Comparator}


\section{Space complexity}
\label{space-complexity}

\index{space complexity}
\index{analysis}

Until now we have talked a lot about runtime analysis, but for many
algorithms we are also concerned about space. For example, one of the
drawbacks of merge sort is that it makes copies of the data. In our
implementation, the total amount of space it allocates is
$O(n \log n)$. With a more clever implementation, you can get the
space requirement down to $O(n)$.

In contrast, insertion sort doesn't copy the data because it sorts the
elements in place. It uses temporary variables to compare two elements
at a time, and it uses a few other local variables. But its space use
doesn't depend on $n$.

Our implementation of heap sort creates a new \java{PriorityQueue} to
store the elements, so the space is $O(n)$; but if you are
allowed to sort the list in place, you can run heap sort with
$O(1)$ space.

One of the benefits of the bounded heap algorithm you just implemented
is that it only needs space proportional to $k$ (the number of
elements we want to keep), and $k$ is often much smaller than
$n$.

Software developers tend to pay more attention to runtime than space, and
for many applications, that's appropriate. But for large datasets, space
can be just as important or more so. For example:

\begin{enumerate}

\item If a dataset doesn't fit into the memory of one program, the run
  time often increases dramatically, or it might not run at all. If you
  choose an algorithm that needs less space, and that makes it possible
  to fit the computation into memory, it might run much faster. In the
  same vein, a program that uses less space might make better use of
  CPU caches and run
  faster (see \url{http://thinkdast.com/cache}).

\item On a server that runs many programs at the same time, if you can
  reduce the space needed for each program, you might be able to run
  more programs on the same server, which reduces hardware and energy
  costs.

\end{enumerate}

So those are some reasons you should know at least a little bit about
the space needs of algorithms.

\index{cache}
\index{server}


\backmatter
\printindex

%\cleardoublepage

\end{document}
